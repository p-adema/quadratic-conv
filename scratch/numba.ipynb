{
 "cells": [
  {
   "cell_type": "code",
   "id": "358f30b60cc42081",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-27T18:09:58.242199Z",
     "start_time": "2025-04-27T18:09:57.418291Z"
    }
   },
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import tqdm.auto as tqdm\n",
    "import math\n",
    "from numba import cuda"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "id": "efb24287c0ecd5bc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-27T18:09:58.273521Z",
     "start_time": "2025-04-27T18:09:58.269806Z"
    }
   },
   "source": [
    "# Move to project root\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "if not Path(\"./checkpoints\").is_dir():\n",
    "    for parent_path in Path.cwd().parents:\n",
    "        if (parent_path / \"checkpoints\").is_dir():\n",
    "            os.chdir(parent_path)\n",
    "            break\n",
    "    else:\n",
    "        raise FileNotFoundError(\"Can't find project root\")\n",
    "\n",
    "assert Path(\"./checkpoints\").is_dir()"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "id": "4dfcbb23e91bcd73",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-27T18:09:59.034390Z",
     "start_time": "2025-04-27T18:09:58.331259Z"
    }
   },
   "source": "from src import load_data, kernels",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-27T09:01:48.536248Z",
     "start_time": "2025-04-27T09:01:48.149716Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import uuid\n",
    "\n",
    "\n",
    "@torch.library.custom_op(\n",
    "    f\"tmp_testing::tmp_{uuid.uuid4().hex}\", mutates_args={}, device_types=\"cuda\", schema=\"(Tensor a, int b) -> int\"\n",
    ")\n",
    "def test_op(\n",
    "        *args\n",
    ") -> int:\n",
    "    print(args)\n",
    "    return args[0] + args[1]\n",
    "\n",
    "\n",
    "test_op(torch.ones(1, device='cuda'), 3)"
   ],
   "id": "7cc6ed6636efb0da",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([1.], device='cuda:0'), 3)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 18
  },
  {
   "cell_type": "code",
   "id": "f22c443ce5a9ab93",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-24T19:00:35.148305Z",
     "start_time": "2025-04-24T19:00:35.098491Z"
    }
   },
   "source": [
    "@cuda.jit(\"void(float32[:])\")\n",
    "def add_one(arr):\n",
    "    x = cuda.grid(1)\n",
    "    if x < arr.size:\n",
    "        arr[x] += 1"
   ],
   "outputs": [],
   "execution_count": 27
  },
  {
   "cell_type": "code",
   "id": "88c6da9a2bdcc6d1",
   "metadata": {},
   "source": [
    "a = torch.tensor([5, 4, 3, 2], dtype=torch.float32, device=\"cuda\")\n",
    "a"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "f585705f0d6f59f7",
   "metadata": {},
   "source": [
    "add_one[1, 16](a)\n",
    "a"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def run_once():\n",
    "    a.add_(1)\n",
    "    torch.cuda.synchronize()\n",
    "\n",
    "%timeit run_once()"
   ],
   "id": "4af198d7e5f4b9cc",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def run_once():\n",
    "    add_one[1, 16](a)\n",
    "    torch.cuda.synchronize()\n",
    "\n",
    "%timeit run_once()"
   ],
   "id": "8a6ffc0194b8680f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-24T18:18:28.331095Z",
     "start_time": "2025-04-24T18:18:28.321174Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "lib_path = Path(sys.exec_prefix) / \"lib\"\n",
    "site_packages = next(lib_path.glob(\"python3.*\")) / \"site-packages\"\n",
    "cudart_base = site_packages / \"torch\" / \"lib\" / \"libcudart.so\"\n",
    "cudart_user = Path(\"/usr/local/cuda/lib64/libcudart.so\")\n",
    "cudart_nv_base = site_packages / \"nvidia\" / \"cuda_runtime\" / \"lib\" / \"libcudart.so\"\n",
    "cudart_nv_versioned = next((site_packages / \"nvidia\" / \"cuda_runtime\" / \"lib\").glob(\"libcudart.so.*\"), None)\n",
    "if not cudart_base.exists():\n",
    "    if cudart_user.exists():\n",
    "        print(\"User\")\n",
    "        cudart_base.symlink_to(cudart_user)\n",
    "    elif cudart_nv_base.exists():\n",
    "        print(\"NV base\")\n",
    "        cudart_base.symlink_to(cudart_nv_base)\n",
    "    elif cudart_nv_versioned is not None:\n",
    "        print(\"NV Versioned\")\n",
    "        cudart_base.symlink_to(cudart_nv_versioned)\n",
    "    # cudart_base.symlink_to()\n",
    "\n",
    "print(cudart_base.exists(), \" : \", cudart_base)"
   ],
   "id": "4a40b346c72463ba",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User\n",
      "True  :  /home/peter/Thesis/.venv/lib/python3.12/site-packages/torch/lib/libcudart.so\n"
     ]
    }
   ],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-24T18:17:33.669705Z",
     "start_time": "2025-04-24T18:17:33.486750Z"
    }
   },
   "cell_type": "code",
   "outputs": [],
   "execution_count": 20,
   "source": "# !rm /home/peter/Thesis/.venv/lib/python3.12/site-packages/torch/lib/libcudart.so",
   "id": "870aab3bed0e90c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-24T15:21:35.249678Z",
     "start_time": "2025-04-24T15:21:35.240556Z"
    }
   },
   "cell_type": "code",
   "source": [
    "temp_root = Path(\"/home/peter/Thesis/scratch/test-extension\")\n",
    "built_module = next((temp_root / \"build\").glob(\"lib.*\")) / \"test_extension\"\n",
    "assert built_module.exists()\n",
    "built_module"
   ],
   "id": "fb3c9af327df2b4a",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/home/peter/Thesis/scratch/test-extension/build/lib.linux-x86_64-cpython-312/test_extension')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-24T18:08:01.706032Z",
     "start_time": "2025-04-24T18:08:01.697313Z"
    }
   },
   "cell_type": "code",
   "source": "list((site_packages / \"torch\" / \"lib\").glob(\"*\"))",
   "id": "31de6150c862160b",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PosixPath('/home/peter/Thesis/.venv/lib/python3.12/site-packages/torch/lib/libcudart.so'),\n",
       " PosixPath('/home/peter/Thesis/.venv/lib/python3.12/site-packages/torch/lib/libcaffe2_nvrtc.so'),\n",
       " PosixPath('/home/peter/Thesis/.venv/lib/python3.12/site-packages/torch/lib/libc10_cuda.so'),\n",
       " PosixPath('/home/peter/Thesis/.venv/lib/python3.12/site-packages/torch/lib/libtorch_cuda.so'),\n",
       " PosixPath('/home/peter/Thesis/.venv/lib/python3.12/site-packages/torch/lib/libtorch_global_deps.so'),\n",
       " PosixPath('/home/peter/Thesis/.venv/lib/python3.12/site-packages/torch/lib/libshm.so'),\n",
       " PosixPath('/home/peter/Thesis/.venv/lib/python3.12/site-packages/torch/lib/libshm_windows'),\n",
       " PosixPath('/home/peter/Thesis/.venv/lib/python3.12/site-packages/torch/lib/libgomp-870cb1d0.so.1'),\n",
       " PosixPath('/home/peter/Thesis/.venv/lib/python3.12/site-packages/torch/lib/libtorch.so'),\n",
       " PosixPath('/home/peter/Thesis/.venv/lib/python3.12/site-packages/torch/lib/libtorch_python.so'),\n",
       " PosixPath('/home/peter/Thesis/.venv/lib/python3.12/site-packages/torch/lib/libtorch_cpu.so'),\n",
       " PosixPath('/home/peter/Thesis/.venv/lib/python3.12/site-packages/torch/lib/libc10.so'),\n",
       " PosixPath('/home/peter/Thesis/.venv/lib/python3.12/site-packages/torch/lib/libshm'),\n",
       " PosixPath('/home/peter/Thesis/.venv/lib/python3.12/site-packages/torch/lib/libtorch_cuda_linalg.so')]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-24T15:25:10.968176Z",
     "start_time": "2025-04-24T15:21:37.118761Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import importlib.util\n",
    "import importlib.machinery\n",
    "import sys\n",
    "\n",
    "\n",
    "def import_from_path(module_name, file_path):\n",
    "    spec = importlib.util.spec_from_file_location(\"test_extension\", file_path / \"__init__.py\")\n",
    "    module = importlib.util.module_from_spec(spec)\n",
    "    sys.modules[module_name] = module\n",
    "    spec.loader.exec_module(module)\n",
    "    return module\n",
    "\n",
    "\n",
    "# test_ext = import_from_path(\"test_extension\", built_module)\n",
    "test_ext = import_from_path(\"test_extension\", built_module)"
   ],
   "id": "c96fc6915de52fcf",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "57e4f046852998e7"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "a = torch.ones(5, device='cuda')\n",
    "b = torch.arange(5, dtype=torch.float32, device='cuda')\n",
    "c = 5.0\n",
    "test_ext.ops.mymuladd(a, b, c)"
   ],
   "id": "5684aa58b6bcc698",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def run_one():\n",
    "    test_ext.ops.mymuladd(a, b, c)\n",
    "    torch.cuda.synchronize()\n",
    "\n",
    "%timeit run_one()"
   ],
   "id": "94538c3e5b515176",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-24T19:55:53.316430Z",
     "start_time": "2025-04-24T19:55:53.310268Z"
    }
   },
   "cell_type": "code",
   "source": [
    "a = torch.ones(5, device='cuda')\n",
    "test_add[1, 32](a)"
   ],
   "id": "7bffa95d52923f52",
   "outputs": [],
   "execution_count": 38
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-25T06:33:54.540901Z",
     "start_time": "2025-04-25T06:33:54.529003Z"
    }
   },
   "cell_type": "code",
   "source": "a",
   "id": "c269563e2ebcc7eb",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([30., 30., 30., 30.,  2.], device='cuda:0')"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 40
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-25T07:53:37.886528Z",
     "start_time": "2025-04-25T07:53:37.825165Z"
    }
   },
   "cell_type": "code",
   "source": [
    "@cuda.jit(\"void(float32[:])\")\n",
    "def test_add(arr):\n",
    "    x = cuda.grid(1)\n",
    "    if 0 < x < arr.size:\n",
    "        arr[x] = 2\n",
    "        arr[x - 1] = 30\n",
    "\n",
    "\n",
    "def simple_add(x, y):\n",
    "    return x + y\n",
    "\n",
    "\n",
    "res = []\n",
    "compilation = cuda.compile_for_current_device(\n",
    "    test_add, \"void(float32[:])\",\n",
    "    # simple_add, \"int64(int64, int64)\",\n",
    "    device=False, abi=\"numba\", lineinfo=False,\n",
    "    output='ptx', opt=True, abi_info={\"abi_name\": \"conv\"})[0]\n",
    "\n",
    "max_line = max(map(len, compilation.splitlines()))\n",
    "for line in compilation.splitlines():\n",
    "    if line.strip():\n",
    "        res.append(f'\"{line}\\n\\t\"')\n",
    "        # print(f'\"{line.ljust(max_line)}\\\\n\\\\t\"')\n",
    "# res_join = '\\n\\t'.join(res)\n",
    "print(compilation)"
   ],
   "id": "554a3f8809e67a08",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "//\n",
      "// Generated by NVIDIA NVVM Compiler\n",
      "//\n",
      "// Compiler Build ID: CL-35404655\n",
      "// Cuda compilation tools, release 12.8, V12.8.61\n",
      "// Based on NVVM 7.0.1\n",
      "//\n",
      "\n",
      ".version 8.7\n",
      ".target sm_90\n",
      ".address_size 64\n",
      "\n",
      "\t// .globl\t_ZN6cudapy8__main__8test_addB3v29B94cw51cXTLSUwv1sCUt9UwNNJRMNDUUUDyoy04_2bIChiBahtqDEBRGGpB0kAdT0AJNAcp9ttTos1NStFKChrw6UBPKMazUBE5ArrayIfLi1E1A7mutable7alignedE\n",
      ".visible .global .align 4 .u32 _ZN6cudapy8__main__8test_addB3v29B94cw51cXTLSUwv1sCUt9UwNNJRMNDUUUDyoy04_2bIChiBahtqDEBRGGpB0kAdT0AJNAcp9ttTos1NStFKChrw6UBPKMazUBE5ArrayIfLi1E1A7mutable7alignedE__errcode__;\n",
      ".visible .global .align 4 .u32 _ZN6cudapy8__main__8test_addB3v29B94cw51cXTLSUwv1sCUt9UwNNJRMNDUUUDyoy04_2bIChiBahtqDEBRGGpB0kAdT0AJNAcp9ttTos1NStFKChrw6UBPKMazUBE5ArrayIfLi1E1A7mutable7alignedE__tidx__;\n",
      ".visible .global .align 4 .u32 _ZN6cudapy8__main__8test_addB3v29B94cw51cXTLSUwv1sCUt9UwNNJRMNDUUUDyoy04_2bIChiBahtqDEBRGGpB0kAdT0AJNAcp9ttTos1NStFKChrw6UBPKMazUBE5ArrayIfLi1E1A7mutable7alignedE__ctaidx__;\n",
      ".visible .global .align 4 .u32 _ZN6cudapy8__main__8test_addB3v29B94cw51cXTLSUwv1sCUt9UwNNJRMNDUUUDyoy04_2bIChiBahtqDEBRGGpB0kAdT0AJNAcp9ttTos1NStFKChrw6UBPKMazUBE5ArrayIfLi1E1A7mutable7alignedE__tidy__;\n",
      ".visible .global .align 4 .u32 _ZN6cudapy8__main__8test_addB3v29B94cw51cXTLSUwv1sCUt9UwNNJRMNDUUUDyoy04_2bIChiBahtqDEBRGGpB0kAdT0AJNAcp9ttTos1NStFKChrw6UBPKMazUBE5ArrayIfLi1E1A7mutable7alignedE__ctaidy__;\n",
      ".visible .global .align 4 .u32 _ZN6cudapy8__main__8test_addB3v29B94cw51cXTLSUwv1sCUt9UwNNJRMNDUUUDyoy04_2bIChiBahtqDEBRGGpB0kAdT0AJNAcp9ttTos1NStFKChrw6UBPKMazUBE5ArrayIfLi1E1A7mutable7alignedE__tidz__;\n",
      ".visible .global .align 4 .u32 _ZN6cudapy8__main__8test_addB3v29B94cw51cXTLSUwv1sCUt9UwNNJRMNDUUUDyoy04_2bIChiBahtqDEBRGGpB0kAdT0AJNAcp9ttTos1NStFKChrw6UBPKMazUBE5ArrayIfLi1E1A7mutable7alignedE__ctaidz__;\n",
      ".common .global .align 8 .u64 _ZN08NumbaEnv8__main__8test_addB3v29B94cw51cXTLSUwv1sCUt9UwNNJRMNDUUUDyoy04_2bIChiBahtqDEBRGGpB0kAdT0AJNAcp9ttTos1NStFKChrw6UBPKMazUBE5ArrayIfLi1E1A7mutable7alignedE;\n",
      "\n",
      ".visible .entry _ZN6cudapy8__main__8test_addB3v29B94cw51cXTLSUwv1sCUt9UwNNJRMNDUUUDyoy04_2bIChiBahtqDEBRGGpB0kAdT0AJNAcp9ttTos1NStFKChrw6UBPKMazUBE5ArrayIfLi1E1A7mutable7alignedE(\n",
      "\t.param .u64 _ZN6cudapy8__main__8test_addB3v29B94cw51cXTLSUwv1sCUt9UwNNJRMNDUUUDyoy04_2bIChiBahtqDEBRGGpB0kAdT0AJNAcp9ttTos1NStFKChrw6UBPKMazUBE5ArrayIfLi1E1A7mutable7alignedE_param_0,\n",
      "\t.param .u64 _ZN6cudapy8__main__8test_addB3v29B94cw51cXTLSUwv1sCUt9UwNNJRMNDUUUDyoy04_2bIChiBahtqDEBRGGpB0kAdT0AJNAcp9ttTos1NStFKChrw6UBPKMazUBE5ArrayIfLi1E1A7mutable7alignedE_param_1,\n",
      "\t.param .u64 _ZN6cudapy8__main__8test_addB3v29B94cw51cXTLSUwv1sCUt9UwNNJRMNDUUUDyoy04_2bIChiBahtqDEBRGGpB0kAdT0AJNAcp9ttTos1NStFKChrw6UBPKMazUBE5ArrayIfLi1E1A7mutable7alignedE_param_2,\n",
      "\t.param .u64 _ZN6cudapy8__main__8test_addB3v29B94cw51cXTLSUwv1sCUt9UwNNJRMNDUUUDyoy04_2bIChiBahtqDEBRGGpB0kAdT0AJNAcp9ttTos1NStFKChrw6UBPKMazUBE5ArrayIfLi1E1A7mutable7alignedE_param_3,\n",
      "\t.param .u64 _ZN6cudapy8__main__8test_addB3v29B94cw51cXTLSUwv1sCUt9UwNNJRMNDUUUDyoy04_2bIChiBahtqDEBRGGpB0kAdT0AJNAcp9ttTos1NStFKChrw6UBPKMazUBE5ArrayIfLi1E1A7mutable7alignedE_param_4,\n",
      "\t.param .u64 _ZN6cudapy8__main__8test_addB3v29B94cw51cXTLSUwv1sCUt9UwNNJRMNDUUUDyoy04_2bIChiBahtqDEBRGGpB0kAdT0AJNAcp9ttTos1NStFKChrw6UBPKMazUBE5ArrayIfLi1E1A7mutable7alignedE_param_5,\n",
      "\t.param .u64 _ZN6cudapy8__main__8test_addB3v29B94cw51cXTLSUwv1sCUt9UwNNJRMNDUUUDyoy04_2bIChiBahtqDEBRGGpB0kAdT0AJNAcp9ttTos1NStFKChrw6UBPKMazUBE5ArrayIfLi1E1A7mutable7alignedE_param_6\n",
      ")\n",
      "{\n",
      "\t.reg .pred \t%p<4>;\n",
      "\t.reg .b32 \t%r<6>;\n",
      "\t.reg .b64 \t%rd<11>;\n",
      "\n",
      "\n",
      "\tld.param.u64 \t%rd4, [_ZN6cudapy8__main__8test_addB3v29B94cw51cXTLSUwv1sCUt9UwNNJRMNDUUUDyoy04_2bIChiBahtqDEBRGGpB0kAdT0AJNAcp9ttTos1NStFKChrw6UBPKMazUBE5ArrayIfLi1E1A7mutable7alignedE_param_2];\n",
      "\tld.param.u64 \t%rd2, [_ZN6cudapy8__main__8test_addB3v29B94cw51cXTLSUwv1sCUt9UwNNJRMNDUUUDyoy04_2bIChiBahtqDEBRGGpB0kAdT0AJNAcp9ttTos1NStFKChrw6UBPKMazUBE5ArrayIfLi1E1A7mutable7alignedE_param_4];\n",
      "\tld.param.u64 \t%rd3, [_ZN6cudapy8__main__8test_addB3v29B94cw51cXTLSUwv1sCUt9UwNNJRMNDUUUDyoy04_2bIChiBahtqDEBRGGpB0kAdT0AJNAcp9ttTos1NStFKChrw6UBPKMazUBE5ArrayIfLi1E1A7mutable7alignedE_param_6];\n",
      "\tmov.u32 \t%r1, %tid.x;\n",
      "\tcvt.s64.s32 \t%rd5, %r1;\n",
      "\tmov.u32 \t%r2, %ntid.x;\n",
      "\tmov.u32 \t%r3, %ctaid.x;\n",
      "\tmul.wide.s32 \t%rd6, %r2, %r3;\n",
      "\tadd.s64 \t%rd1, %rd6, %rd5;\n",
      "\tsetp.lt.s64 \t%p1, %rd1, 1;\n",
      "\tsetp.ge.s64 \t%p2, %rd1, %rd4;\n",
      "\tor.pred  \t%p3, %p1, %p2;\n",
      "\t@%p3 bra \t$L__BB0_2;\n",
      "\n",
      "\tmul.lo.s64 \t%rd7, %rd1, %rd3;\n",
      "\tadd.s64 \t%rd8, %rd7, %rd2;\n",
      "\tmov.u32 \t%r4, 1073741824;\n",
      "\tst.u32 \t[%rd8], %r4;\n",
      "\tsub.s64 \t%rd9, %rd7, %rd3;\n",
      "\tadd.s64 \t%rd10, %rd9, %rd2;\n",
      "\tmov.u32 \t%r5, 1106247680;\n",
      "\tst.u32 \t[%rd10], %r5;\n",
      "\n",
      "$L__BB0_2:\n",
      "\tret;\n",
      "\n",
      "}\n"
     ]
    }
   ],
   "execution_count": 42
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "add_one.inspect_asm()",
   "id": "edccdd23c1abe97b",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "ba4173983b788dda",
   "metadata": {},
   "source": [
    "test_con = 1\n",
    "\n",
    "\n",
    "@cuda.jit(\"void(float32[:, :, :, :], float32[:, :, :, :], int64, int64, int64, int64)\")\n",
    "def mark_channels(arr, out, bs, cs, ys, xs):\n",
    "    z, y, x = cuda.grid(3)\n",
    "    b, c = divmod(z, cs)\n",
    "    if x < xs and y < ys and b < bs:\n",
    "        out[b, c, y, x] = arr[b, c, y, x] * c + x + y + test_con"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "3e580e111d09973f",
   "metadata": {},
   "source": [
    "a = torch.randn((256, 100, 5, 5), device=\"cuda\")\n",
    "o = torch.zeros_like(a)\n",
    "o.shape"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "f939c315c1007486",
   "metadata": {},
   "source": [
    "tpb = (2, 8, 8)\n",
    "tot_tpb = np.prod(tpb)\n",
    "print(\"Total TPB:\", tot_tpb)\n",
    "assert tot_tpb < 512, tot_tpb\n",
    "nbs = (\n",
    "    math.ceil(a.shape[0] * a.shape[1] / tpb[0]),\n",
    "    math.ceil(a.shape[-2] / tpb[-2]),\n",
    "    math.ceil(a.shape[-1] / tpb[-1]),\n",
    ")\n",
    "n_threads = np.prod(tpb) * np.prod(nbs)\n",
    "print(\"NBS:\", nbs)\n",
    "print(\"N_threads\", n_threads)\n",
    "print(\"Size:\", a.nelement())\n",
    "print(f\"Thread util: {a.nelement() / n_threads:.1%}\")\n",
    "assert a.nelement() <= n_threads"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "baf43246959cf05d",
   "metadata": {},
   "source": [
    "def run_one():\n",
    "    cuda.synchronize()\n",
    "    mark_channels[nbs, tpb](a, o, *a.shape)\n",
    "    cuda.synchronize()\n",
    "\n",
    "\n",
    "run_one()\n",
    "# %timeit run_one()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "b89b2cfe6042c80c",
   "metadata": {},
   "source": [
    "test_con2 = 1\n",
    "\n",
    "\n",
    "@cuda.jit(\"void(float32[:, :, :, :], float32[:, :, :, :], int64, int64, int64, int64)\")\n",
    "def mark_channels_flat(arr, out, _bs, cs, ys, xs):\n",
    "    idx = cuda.grid(1)\n",
    "    if idx >= arr.size:\n",
    "        return\n",
    "    idx_y, x = divmod(idx, xs)\n",
    "    idx_z, y = divmod(idx_y, ys)\n",
    "    b, c = divmod(idx_z, cs)\n",
    "    # if x < xs and y < ys and b < bs:\n",
    "    out[b, c, y, x] = arr[b, c, y, x] * c + x + y + test_con2"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "4abc286efa6abc7f",
   "metadata": {},
   "source": [
    "o[:] = 0\n",
    "mark_channels_flat[math.ceil(a.nelement() / 32), 32](a, o, *a.shape)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "f8e888a29df92286",
   "metadata": {},
   "source": [
    "o[:] = 0\n",
    "mark_channels[nbs, tpb](a, o, *a.shape)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "2aa84e4f94aec842",
   "metadata": {},
   "source": [
    "def run_one():\n",
    "    cuda.synchronize()\n",
    "    mark_channels_flat[math.ceil(a.nelement() / 256), 256](a, o, *a.shape)\n",
    "    cuda.synchronize()\n",
    "\n",
    "\n",
    "run_one()\n",
    "# %timeit run_one()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "840c980c9fd946f3",
   "metadata": {},
   "source": [
    "print(o[10, 2])"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "9422f53c2b51d42f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-27T18:10:07.073566Z",
     "start_time": "2025-04-27T18:10:06.435361Z"
    }
   },
   "source": [
    "reduce_max = True\n",
    "INF = float(\"inf\")\n",
    "\n",
    "\n",
    "@cuda.jit(\n",
    "    \"void(float32[:, :, :, :],\"  # img: [Batch, Channel, Img_Y, Img_X]\n",
    "    \" float32[:, :, :],\"  # kernel: [Channel, Kernel_Y, Kernel_X\n",
    "    \" float32[:, :, :, :],\"  # out_img: [Batch, Channel, Img_Y, Img_X]\n",
    "    \" int16[:, :, :, :, :],\"  # out_prov: [Batch, Channel, Img_Y, Img_X, 2 (y, then x)]\n",
    "    \" int64,\"  # Channels\n",
    "    \" int64, int64,\"  # Img_Y, Img_X\n",
    "    \" int64, int64)\",  # Kernel_Y, Kernel_X\n",
    "    debug=True,\n",
    "    opt=False,\n",
    ")\n",
    "def dilate_flat(img, kernel, out_img, out_prov, cs, i_ys, i_xs, k_ys, k_xs):\n",
    "    idx = cuda.grid(1)\n",
    "    if idx >= img.size:\n",
    "        return\n",
    "    idx_y, centre_x = divmod(idx, i_xs)\n",
    "    idx_z, centre_y = divmod(idx_y, i_ys)\n",
    "    b, c = divmod(idx_z, cs)\n",
    "\n",
    "    top_y, left_x = centre_y - k_ys // 2, centre_x - k_xs // 2\n",
    "    best_x = best_y = -99\n",
    "    best_val = -INF if reduce_max else INF\n",
    "\n",
    "    for k_y, i_y in enumerate(range(top_y, top_y + k_ys)):\n",
    "        for k_x, i_x in enumerate(range(left_x, left_x + k_xs)):\n",
    "            if i_x < 0 or i_x > i_xs or i_y < 0 or i_y > i_ys:\n",
    "                continue\n",
    "\n",
    "            if reduce_max:\n",
    "                val = img[b, c, i_y, i_x] + kernel[c, k_y, k_x]\n",
    "                if val > best_val:\n",
    "                    best_y, best_x = i_y, i_x\n",
    "                    best_val = val\n",
    "            else:\n",
    "                val = img[b, c, i_y, i_x] - kernel[c, k_y, k_x]\n",
    "                if val < best_val:\n",
    "                    best_y, best_x = i_y, i_x\n",
    "                    best_val = val\n",
    "\n",
    "    out_img[b, c, centre_y, centre_x] = best_val\n",
    "    out_prov[b, c, centre_y, centre_x, 0] = best_y\n",
    "    out_prov[b, c, centre_y, centre_x, 1] = best_x"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peter/Thesis/.venv/lib/python3.12/site-packages/numba/core/lowering.py:116: NumbaDebugInfoWarning: Could not find source for function: <function dilate_flat at 0x73ee6bf344a0>. Debug line information may be inaccurate.\n",
      "  warnings.warn(NumbaDebugInfoWarning(msg))\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "id": "f225ff2687bf77a4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-27T18:10:08.866853Z",
     "start_time": "2025-04-27T18:10:08.701364Z"
    }
   },
   "source": [
    "mnist = load_data.mnist()"
   ],
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-27T18:10:09.372119Z",
     "start_time": "2025-04-27T18:10:09.361694Z"
    }
   },
   "cell_type": "code",
   "source": "mnist",
   "id": "352c7c50a8606ff",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset(x_train=torch.Size([60000, 1, 28, 28]), x_test=torch.Size([10000, 1, 28, 28]), y_train=torch.Size([60000]), y_test=torch.Size([10000]))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "id": "e236c5dac107bff2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-27T18:10:11.318920Z",
     "start_time": "2025-04-27T18:10:11.307832Z"
    }
   },
   "source": [
    "test_imgs = (\n",
    "    torch.asarray(mnist.x_train[:2048], device=\"cuda\").repeat((1, 6, 1, 1))\n",
    ")\n",
    "print(test_imgs.dtype)\n",
    "test_imgs.shape"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.float32\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([2048, 6, 28, 28])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "id": "479244cececf0863",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-27T18:10:11.831893Z",
     "start_time": "2025-04-27T18:10:11.788139Z"
    }
   },
   "source": [
    "test_kernels = -torch.asarray(\n",
    "    [\n",
    "        # 1: Does nothing\n",
    "        [[[INF, INF, INF], [INF, 0, INF], [INF, INF, INF]]],\n",
    "        # 2: Vertical max\n",
    "        [[[INF, 0, INF], [INF, 0, INF], [INF, 0, INF]]],\n",
    "        # 3: Horizontal max\n",
    "        [[[INF, INF, INF], [0, 0, 0], [INF, INF, INF]]],\n",
    "        # 4: 3x3 max\n",
    "        [[[0, 0, 0], [0, 0, 0], [0, 0, 0]]],\n",
    "        # 5: small quadratic max, isotropic\n",
    "        [[[0.4, 0.1, 0.4], [0.1, 0, 0.1], [0.4, 0.1, 0.4]]],\n",
    "        # 6: small quadratic max, wide horizontally\n",
    "        [[[0.5, 0.2, 0.5], [0.05, 0, 0.05], [0.5, 0.2, 0.5]]],\n",
    "    ],\n",
    "    device=\"cuda\",\n",
    ")\n",
    "print(test_kernels.dtype)\n",
    "test_kernels.shape"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.float32\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([6, 1, 3, 3])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "id": "140f9f06ff6539ca",
   "metadata": {},
   "source": [
    "o_i = torch.full_like(test_imgs, -700, device=\"cuda\")\n",
    "o_p = torch.full(test_imgs.shape + (2,), -699, dtype=torch.int16, device=\"cuda\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "cebd1b0c9b3f1aaa",
   "metadata": {},
   "source": [
    "o_i[:] = -688\n",
    "o_p[:] = -689\n",
    "dilate_flat[math.ceil(test_imgs.nelement() / 256), 256](\n",
    "    test_imgs, test_kernels, o_i, o_p, *test_imgs.shape[1:], *test_kernels.shape[1:]\n",
    ")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "c4be2342937d26f8",
   "metadata": {},
   "source": [
    "def compile_tropical_conv(\n",
    "        is_max: bool,\n",
    "        channels: int,\n",
    "        kernel_size: int,\n",
    "        block_size: int = 256,\n",
    "        debug: bool = False,\n",
    "        calculate_prov: bool = True,\n",
    "):\n",
    "    cs = channels\n",
    "    k_ys = k_xs = kernel_size\n",
    "\n",
    "    @cuda.jit(\n",
    "        \"void(float32[:, :, :, :],\"  # img: [Batch, Channel, Img_Y, Img_X]\n",
    "        \" float32[:, :, :],\"  # kernel: [Channel, Kernel_Y, Kernel_X\n",
    "        \" float32[:, :, :, :],\"  # out_img: [Batch, Channel, Img_Y, Img_X]\n",
    "        f\"{'int16[:, :, :, :, :],' if calculate_prov else 'int16,'}\"  # out_prov: [Batch, Channel, Img_Y, Img_X, 2 (y, then x)]\n",
    "        \" int64, int64)\",  # Img_Y, Img_X\n",
    "        debug=debug,\n",
    "        opt=not debug,\n",
    "    )\n",
    "    def conv_cuda(img, kernel, out_img, out_prov, i_ys, i_xs):\n",
    "        idx = cuda.grid(1)\n",
    "        if idx >= img.size:\n",
    "            return\n",
    "        idx_y, centre_x = divmod(idx, i_xs)\n",
    "        idx_z, centre_y = divmod(idx_y, i_ys)\n",
    "        b, c = divmod(idx_z, cs)\n",
    "\n",
    "        top_y, left_x = centre_y - k_ys // 2, centre_x - k_xs // 2\n",
    "        best_x = best_y = -99\n",
    "        best_val = -INF if is_max else INF\n",
    "\n",
    "        for k_y, i_y in enumerate(range(top_y, top_y + k_ys)):\n",
    "            for k_x, i_x in enumerate(range(left_x, left_x + k_xs)):\n",
    "                if i_x < 0 or i_x >= i_xs or i_y < 0 or i_y >= i_ys:\n",
    "                    continue\n",
    "\n",
    "                if is_max:\n",
    "                    val = img[b, c, i_y, i_x] + kernel[c, k_y, k_x]\n",
    "                    if val > best_val:\n",
    "                        best_val = val\n",
    "                        if calculate_prov:\n",
    "                            best_y, best_x = i_y, i_x\n",
    "                else:\n",
    "                    val = img[b, c, i_y, i_x] - kernel[c, k_y, k_x]\n",
    "                    if val < best_val:\n",
    "                        best_val = val\n",
    "                        if calculate_prov:\n",
    "                            best_y, best_x = i_y, i_x\n",
    "\n",
    "        out_img[b, c, centre_y, centre_x] = best_val\n",
    "        if calculate_prov:\n",
    "            out_prov[b, c, centre_y, centre_x, 0] = best_y\n",
    "            out_prov[b, c, centre_y, centre_x, 1] = best_x\n",
    "\n",
    "    def conv(img: torch.Tensor, kernel: torch.Tensor):\n",
    "        img, kernel = img.detach(), kernel.detach()\n",
    "        out_img = torch.empty_like(img)\n",
    "        if calculate_prov:\n",
    "            out_prov = torch.empty(\n",
    "                img.shape + (2,), device=img.compilation, dtype=torch.int16\n",
    "            )\n",
    "        else:\n",
    "            out_prov = -1\n",
    "        n_blocks = math.ceil(img.nelement() / block_size)\n",
    "        conv_cuda[n_blocks, block_size](\n",
    "            img, kernel, out_img, out_prov, img.shape[2], img.shape[3]\n",
    "        )\n",
    "        if calculate_prov:\n",
    "            return out_img, out_prov\n",
    "        return out_img\n",
    "\n",
    "    return conv"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "ed2c6f6ac813a3b3",
   "metadata": {},
   "source": [
    "max_op = compile_tropical_conv(is_max=True, channels=6, kernel_size=3)\n",
    "min_op = compile_tropical_conv(is_max=False, channels=6, kernel_size=3)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "f2b022c5791fe008",
   "metadata": {},
   "source": [
    "img_num = 1\n",
    "plt.set_cmap(\"viridis\")\n",
    "_, ((ax_original, *ax_maxs), (ax_unused, *ax_mins)) = plt.subplots(\n",
    "    2, 1 + 6, layout=\"compressed\"\n",
    ")\n",
    "ax_original.set_axis_off()\n",
    "ax_unused.set_axis_off()\n",
    "ax_original.imshow(test_imgs[img_num, 0].numpy(force=True))\n",
    "ax_original.set_title(\"Original\")\n",
    "max_imgs = max_op(test_imgs, test_kernels)[0]\n",
    "for i, (ax, img_channel) in enumerate(\n",
    "        zip(ax_maxs, max_imgs[img_num].numpy(force=True), strict=True), 1\n",
    "):\n",
    "    ax.set_axis_off()\n",
    "    ax.imshow(img_channel)\n",
    "    ax.set_title(f\"Max #{i}\")\n",
    "min_imgs = min_op(test_imgs, test_kernels)[0]\n",
    "for i, (ax, img_channel) in enumerate(\n",
    "        zip(ax_mins, min_imgs[img_num].numpy(force=True), strict=True), 1\n",
    "):\n",
    "    ax.set_axis_off()\n",
    "    ax.imshow(img_channel)\n",
    "    ax.set_title(f\"Min #{i}\")\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "9ccd732f61ff0f74",
   "metadata": {},
   "source": [
    "unfold_max = convolutions.TropicalConv2D(is_max=True)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "b8da941ff9319b7e",
   "metadata": {},
   "source": [
    "def run_one():\n",
    "    torch.cuda.synchronize()\n",
    "    arr = unfold_max(test_imgs, test_kernels.unsqueeze(1))[0]\n",
    "    del arr\n",
    "    torch.cuda.synchronize()\n",
    "\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "run_one()\n",
    "# %timeit run_one()\n",
    "torch.cuda.empty_cache()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "7453520a48ec1e66",
   "metadata": {},
   "source": [
    "per_img_shape = test_imgs.shape[2:]\n",
    "print(per_img_shape)\n",
    "np.prod(per_img_shape)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "b3486a2e95f8dba6",
   "metadata": {},
   "source": [
    "per_image_max_op = compile_tropical_conv(\n",
    "    is_max=True, channels=6, kernel_size=3, block_size=784\n",
    ")\n",
    "\n",
    "\n",
    "def run_one():\n",
    "    cuda.synchronize()\n",
    "    arr = max_op(test_imgs, test_kernels)[0]\n",
    "    del arr\n",
    "    cuda.synchronize()\n",
    "\n",
    "\n",
    "def run_one_per_image():\n",
    "    cuda.synchronize()\n",
    "    arr = per_image_max_op(test_imgs, test_kernels)[0]\n",
    "    del arr\n",
    "    cuda.synchronize()\n",
    "\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "run_one()\n",
    "# %timeit run_one()\n",
    "torch.cuda.empty_cache()\n",
    "run_one_per_image()\n",
    "# %timeit run_one_per_image()\n",
    "torch.cuda.empty_cache()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "18b8011eb69f20bf",
   "metadata": {},
   "source": [
    "plt.matshow(test_imgs[0, 0, :15, :15].numpy(force=True))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "fb4076a77a9b22ea",
   "metadata": {},
   "source": [
    "import importlib\n",
    "\n",
    "importlib.reload(convolutions)\n",
    "from src import convolutions"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "306a7b882350882d",
   "metadata": {},
   "source": [
    "channel_nr = 2\n",
    "g_imgs = test_imgs.clone()\n",
    "g_kernels = test_kernels.clone()\n",
    "# g_imgs[0, channel_nr, 7, 7] *= 100\n",
    "g_imgs.requires_grad_(True)\n",
    "g_kernels.requires_grad_(True)\n",
    "g_imgs.grad = None\n",
    "g_kernels.grad = None\n",
    "\n",
    "x_slice = slice(None, 15)\n",
    "y_slice = slice(None, 15)\n",
    "target_xs = [7, 7, 7, 8]\n",
    "target_ys = [6, 7, 8, 6]\n",
    "target_x = target_y = None\n",
    "res_imgs = convolutions.TropicalConv2D(is_max=True)(\n",
    "    g_imgs, g_kernels.unsqueeze(1), padding=1\n",
    ")\n",
    "res_imgs[0, channel_nr, target_ys, target_xs].sum().backward()\n",
    "_, axs = plt.subplots(ncols=5, layout=\"compressed\", figsize=(15, 15), dpi=300)\n",
    "\n",
    "axs[0].matshow(g_kernels[channel_nr].numpy(force=True))\n",
    "axs[0].set_title(\"Kernel\")\n",
    "axs[1].matshow(\n",
    "    g_imgs[0, channel_nr, y_slice, x_slice].numpy(force=True), vmin=0, vmax=2\n",
    ")\n",
    "axs[1].set_title(\"Original\")\n",
    "axs[2].matshow(\n",
    "    res_imgs[0, channel_nr, y_slice, x_slice].numpy(force=True), vmin=0, vmax=2\n",
    ")\n",
    "axs[2].set_title(\"Convolved\")\n",
    "g_np = g_imgs.grad[0, channel_nr, y_slice, x_slice].numpy(force=True)\n",
    "axs[3].matshow(g_np)\n",
    "axs[3].set_title(\"Image Gradient\")\n",
    "g_np_k = g_kernels.grad[channel_nr].numpy(force=True)\n",
    "axs[4].matshow(g_np_k)\n",
    "axs[4].set_title(\"Kernel Gradient\")\n",
    "for g_i, g_j in zip(*g_np.nonzero()):\n",
    "    axs[3].text(\n",
    "        g_j, g_i, g_np[g_i, g_j], color=\"black\", fontsize=5, ha=\"center\", va=\"center\"\n",
    "    )\n",
    "for g_i, g_j in zip(*g_np_k.nonzero()):\n",
    "    axs[4].text(\n",
    "        g_j, g_i, g_np_k[g_i, g_j], color=\"black\", fontsize=10, ha=\"center\", va=\"center\"\n",
    "    )\n",
    "for ax, ax_arr in zip(axs[1:4], (g_imgs, res_imgs, g_imgs.grad)):\n",
    "    for tx, ty in zip(target_xs, target_ys):\n",
    "        ax.text(\n",
    "            tx,\n",
    "            ty,\n",
    "            ax_arr[0, channel_nr, ty, tx].numpy(force=True).round(2),\n",
    "            color=\"red\",\n",
    "            fontsize=5,\n",
    "            ha=\"center\",\n",
    "            va=\"center\",\n",
    "        )\n",
    "    # ax.scatter(target_x, target_y, marker=\"x\", color='red')\n",
    "plt.suptitle(\"Unfold-max gradients\")\n",
    "print(\"Nonzero gradient in image:\", g_np.nonzero())"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "dfeff9cf197e5d0a",
   "metadata": {},
   "source": [
    "def compile_tropical_conv_backwards(\n",
    "        is_max: bool,\n",
    "        channels: int,\n",
    "        kernel_size: int,\n",
    "        block_size: int = 256,\n",
    "        debug: bool = False,\n",
    "):\n",
    "    def one(v, w):\n",
    "        return 1\n",
    "\n",
    "    def minus_one(v, w):\n",
    "        return -1\n",
    "\n",
    "    cs = channels\n",
    "    k_ys = k_xs = kernel_size\n",
    "    if is_max:\n",
    "        d_weigh_d_v = d_weigh_d_w = one\n",
    "    else:\n",
    "        d_weigh_d_v = one\n",
    "        d_weigh_d_w = minus_one\n",
    "\n",
    "    d_weigh_d_v = cuda.jit(d_weigh_d_v, device=True)\n",
    "    d_weigh_d_w = cuda.jit(d_weigh_d_w, device=True)\n",
    "\n",
    "    # noinspection PyArgumentList\n",
    "    @cuda.jit(\n",
    "        \"void(float32[:, :, :, :],\"  # img: [Batch, Channel, Img_Y, Img_X]\n",
    "        \" float32[:, :, :],\"  # kernel: [Channel, Kernel_Y, Kernel_X]\n",
    "        \" float32[:, :, :, :],\"  # res_tangent: [Batch, Channel, Img_Y, Img_X]\n",
    "        \" int16[:, :, :, :, :],\"  # res_prov: [Batch, Channel, Img_Y, Img_X, 2 (y, then x)]\n",
    "        \" float32[:, :, :, :],\"  # out_img_grad: [Batch, Channel, Img_Y, Img_X]\n",
    "        \" float32[:, :, :],\"  # out_kernel_grad: [Channel, Kernel_Y, Kernel_X]\n",
    "        \" int64, int64)\",  # Img_Y, Img_X\n",
    "        debug=debug,\n",
    "        opt=not debug,\n",
    "    )\n",
    "    def conv_backwards_cuda(\n",
    "            img, kernel, res_tangent, res_prov, out_img_grad, out_kernel_grad, i_ys, i_xs\n",
    "    ):\n",
    "        idx = cuda.grid(1)\n",
    "        if idx >= img.size:\n",
    "            return\n",
    "        idx_y, centre_x = divmod(idx, i_xs)\n",
    "        idx_z, centre_y = divmod(idx_y, i_ys)\n",
    "        b, c = divmod(idx_z, cs)\n",
    "        tangent = res_tangent[b, c, centre_y, centre_x]\n",
    "        if tangent == 0:\n",
    "            return\n",
    "\n",
    "        i_prov_x, i_prov_y = (\n",
    "            res_prov[b, c, centre_y, centre_x, 1],\n",
    "            res_prov[b, c, centre_y, centre_x, 0],\n",
    "        )\n",
    "        img_val = img[b, c, i_prov_y, i_prov_x]\n",
    "\n",
    "        rel_prov_x, rel_prov_y = i_prov_x - centre_x, i_prov_y - centre_y\n",
    "        k_prov_x, k_prov_y = rel_prov_x + k_xs // 2, rel_prov_y + k_ys // 2\n",
    "        kernel_val = kernel[c, k_prov_y, k_prov_x]\n",
    "\n",
    "        dv = d_weigh_d_v(img_val, kernel_val) * tangent\n",
    "        dw = d_weigh_d_w(img_val, kernel_val) * tangent\n",
    "\n",
    "        cuda.atomic.add(out_img_grad, (b, c, i_prov_y, i_prov_x), dv)\n",
    "        cuda.atomic.add(out_kernel_grad, (c, k_prov_y, k_prov_x), dw)\n",
    "\n",
    "    def backwards(\n",
    "            img: torch.Tensor,\n",
    "            kernel: torch.Tensor,\n",
    "            res_tangent: torch.Tensor,\n",
    "            res_prov: torch.Tensor,\n",
    "    ):\n",
    "        img, kernel = img.detach(), kernel.detach()\n",
    "        out_img_grad = torch.zeros_like(img)\n",
    "        out_kernel_grad = torch.zeros_like(kernel)\n",
    "        n_blocks = math.ceil(img.nelement() / block_size)\n",
    "        conv_backwards_cuda[n_blocks, block_size](\n",
    "            img,\n",
    "            kernel,\n",
    "            res_tangent,\n",
    "            res_prov,\n",
    "            out_img_grad,\n",
    "            out_kernel_grad,\n",
    "            img.shape[2],\n",
    "            img.shape[3],\n",
    "        )\n",
    "        return out_img_grad, out_kernel_grad\n",
    "\n",
    "    return backwards"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "68cff77db91e52d9",
   "metadata": {},
   "source": [
    "max_back_op = compile_tropical_conv_backwards(is_max=True, channels=6, kernel_size=3)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "1694a6e933b802e6",
   "metadata": {},
   "source": [
    "channel_nr = 2\n",
    "g_imgs = test_imgs.clone()\n",
    "g_kernels = test_kernels.clone()\n",
    "# g_imgs[0, channel_nr, 7, 7] *= 100\n",
    "\n",
    "x_slice = slice(None, 15)\n",
    "y_slice = slice(None, 15)\n",
    "target_xs = [7, 7, 7, 8]\n",
    "target_ys = [6, 7, 8, 6]\n",
    "target_x = target_y = None\n",
    "res_imgs, test_provs = max_op(g_imgs, g_kernels)\n",
    "test_tangent = torch.zeros_like(res_imgs)\n",
    "test_tangent[0, channel_nr, target_ys, target_xs] = 1\n",
    "test_i_grad, test_k_grad = max_back_op(g_imgs, g_kernels, test_tangent, test_provs)\n",
    "\n",
    "_, axs = plt.subplots(ncols=5, layout=\"compressed\", figsize=(15, 15), dpi=300)\n",
    "axs[0].matshow(g_kernels[channel_nr].numpy(force=True))\n",
    "axs[0].set_title(\"Kernel\")\n",
    "axs[1].matshow(\n",
    "    g_imgs[0, channel_nr, y_slice, x_slice].numpy(force=True), vmin=0, vmax=2\n",
    ")\n",
    "axs[1].set_title(\"Original\")\n",
    "axs[2].matshow(\n",
    "    res_imgs[0, channel_nr, y_slice, x_slice].numpy(force=True), vmin=0, vmax=2\n",
    ")\n",
    "axs[2].set_title(\"Convolved\")\n",
    "g_np = test_i_grad[0, channel_nr, y_slice, x_slice].numpy(force=True)\n",
    "axs[3].matshow(g_np)\n",
    "axs[3].set_title(\"Image Gradient\")\n",
    "g_np_k = test_k_grad[channel_nr].numpy(force=True)\n",
    "axs[4].matshow(g_np_k)\n",
    "axs[4].set_title(\"Kernel Gradient\")\n",
    "for g_i, g_j in zip(*g_np.nonzero()):\n",
    "    axs[3].text(\n",
    "        g_j, g_i, g_np[g_i, g_j], color=\"black\", fontsize=5, ha=\"center\", va=\"center\"\n",
    "    )\n",
    "for g_i, g_j in zip(*g_np_k.nonzero()):\n",
    "    axs[4].text(\n",
    "        g_j, g_i, g_np_k[g_i, g_j], color=\"black\", fontsize=10, ha=\"center\", va=\"center\"\n",
    "    )\n",
    "for ax, ax_arr in zip(axs[1:4], (g_imgs, res_imgs, test_i_grad)):\n",
    "    for tx, ty in zip(target_xs, target_ys):\n",
    "        ax.text(\n",
    "            tx,\n",
    "            ty,\n",
    "            ax_arr[0, channel_nr, ty, tx].numpy(force=True).round(2),\n",
    "            color=\"red\",\n",
    "            fontsize=5,\n",
    "            ha=\"center\",\n",
    "            va=\"center\",\n",
    "        )\n",
    "    # ax.scatter(target_x, target_y, marker=\"x\", color='red')\n",
    "plt.suptitle(\"Unfold-max gradients\")\n",
    "print(\"Nonzero gradient in image:\", g_np.nonzero())"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "ce0eccb406275b84",
   "metadata": {},
   "source": [
    "test_tangent_dense = torch.randn_like(test_imgs)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "e6476953f6a586cc",
   "metadata": {},
   "source": [
    "g_imgs = test_imgs.clone()\n",
    "g_kernels = test_kernels.clone()\n",
    "g_imgs.requires_grad_(True)\n",
    "g_kernels.requires_grad_(True)\n",
    "\n",
    "\n",
    "def run_one():\n",
    "    torch.cuda.synchronize()\n",
    "    arr = unfold_max(g_imgs, g_kernels.unsqueeze(1), padding=1)\n",
    "    arr.backward(test_tangent_dense)\n",
    "    del arr\n",
    "    torch.cuda.synchronize()\n",
    "\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "run_one()\n",
    "# %timeit run_one()\n",
    "torch.cuda.empty_cache()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "d23f32a3e3d9676",
   "metadata": {},
   "source": [
    "# @torch.compile\n",
    "def run_one():\n",
    "    cuda.synchronize()\n",
    "    arr, provs = max_op(test_imgs, test_kernels)\n",
    "    i_grad, k_grad = max_back_op(test_imgs, test_kernels, test_tangent_dense, provs)\n",
    "    del arr, i_grad, k_grad\n",
    "    cuda.synchronize()\n",
    "\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "run_one()\n",
    "# %timeit run_one()\n",
    "torch.cuda.empty_cache()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "5fc32d499bb1b9b9",
   "metadata": {},
   "source": [
    "plt.set_cmap(\"viridis\");"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "5391c407be3ddeec",
   "metadata": {},
   "source": [
    "@torch.library.custom_op(\"semifields::dilation\", mutates_args={}, device_types=\"cuda\")\n",
    "def lib_max_op(\n",
    "        img: torch.Tensor,\n",
    "        kernel: torch.Tensor,\n",
    "        padding: int = 1,\n",
    "        stride: int = 1,\n",
    "        dilation: int = 1,\n",
    ") -> tuple[torch.Tensor, torch.Tensor]:\n",
    "    return max_op(img, kernel)\n",
    "\n",
    "\n",
    "@lib_max_op.register_fake\n",
    "def _(img: torch.Tensor, kernel, padding: int = 1, stride: int = 1, dilation: int = 1):\n",
    "    assert img.dtype == torch.float32\n",
    "    assert kernel.dtype == torch.float32\n",
    "    assert padding == 1\n",
    "    assert stride == 1\n",
    "    assert dilation == 1\n",
    "    return torch.empty_like(img), img.new_empty(img.shape + (2,), dtype=torch.int16)\n",
    "\n",
    "\n",
    "def _back_setup(ctx, inputs, output):\n",
    "    img, kernel, padding, stride, dilation = inputs\n",
    "    _res, prov = output\n",
    "    ctx.img = img\n",
    "    ctx.kernel = kernel\n",
    "    ctx.prov = prov\n",
    "\n",
    "\n",
    "@torch.library.custom_op(\n",
    "    \"semifields::dilation_back\", mutates_args={}, device_types=\"cuda\"\n",
    ")\n",
    "def _lib_back_op(\n",
    "        img: torch.Tensor, kernel: torch.Tensor, tangent: torch.Tensor, prov: torch.Tensor\n",
    ") -> tuple[torch.Tensor, torch.Tensor]:\n",
    "    grad_img, grad_kernel = max_back_op(img, kernel, tangent, prov)\n",
    "    return grad_img, grad_kernel\n",
    "\n",
    "\n",
    "@_lib_back_op.register_fake\n",
    "def _(img, kernel, _tangent, _prov):\n",
    "    assert img.dtype == torch.float32\n",
    "    assert kernel.dtype == torch.float32\n",
    "    assert _tangent.dtype == torch.float32\n",
    "    assert _prov.dtype == torch.int16\n",
    "    return torch.empty_like(img), torch.empty_like(kernel)\n",
    "\n",
    "\n",
    "def _lib_back(ctx, grad_output, _grad_prov):\n",
    "    return _lib_back_op(ctx.img, ctx.kernel, grad_output, ctx.prov)\n",
    "\n",
    "\n",
    "lib_max_op.register_autograd(_lib_back, setup_context=_back_setup)\n",
    "\n",
    "g_kernels.grad = None\n",
    "g_kernels.requires_grad_(True)\n",
    "test_tangent = torch.zeros_like(test_imgs)\n",
    "test_tangent[0, channel_nr, target_ys, target_xs] = 1\n",
    "lib_max_op(test_imgs, g_kernels)[0].backward(test_tangent)\n",
    "# TestMaxOp.apply(test_imgs, g_kernels).backward(test_tangent)\n",
    "plt.matshow(g_kernels.grad[channel_nr].numpy(force=True))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "7331e193c34653e3",
   "metadata": {},
   "source": [
    "def numba_max(\n",
    "        img: torch.Tensor,\n",
    "        kernel: torch.Tensor,\n",
    "        padding: int = 1,\n",
    "        stride: int = 1,\n",
    "        dilation: int = 1,\n",
    "):\n",
    "    if len(kernel.shape) == 4:\n",
    "        kernel = kernel.unsqueeze(1)\n",
    "    assert img.shape[1] == kernel.shape[0]\n",
    "    return lib_max_op(img, kernel, padding, stride, dilation)[0]"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "13d3948e5c34812c",
   "metadata": {},
   "source": [
    "test_tangent.nonzero().numpy(force=True)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "bacc24d597f78726",
   "metadata": {},
   "source": [
    "lib_max_op(test_imgs, g_kernels)\n",
    "# noinspection PyTypeChecker\n",
    "torch.library.opcheck(lib_max_op, (test_imgs, g_kernels))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "81a45cc6e68e9593",
   "metadata": {},
   "source": [
    "# it doesn't pass gradcheck...\n",
    "torch.autograd.gradcheck(lib_max_op, (test_imgs[:1], g_kernels), raise_exception=False)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "65f2b0771e2a6795",
   "metadata": {},
   "source": [
    "# but I don't override any gradient calculations here, so it must be down to PyTorch messing up the max/min gradients\n",
    "torch.autograd.gradcheck(\n",
    "    convolutions.TropicalConv2D(is_max=True),\n",
    "    (test_imgs[:1], g_kernels.unsqueeze(1)),\n",
    "    raise_exception=False,\n",
    ")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "98e8019c51e30be9",
   "metadata": {},
   "source": [
    "@torch.compile(mode=\"reduce-overhead\")\n",
    "def run_one():\n",
    "    cuda.synchronize()\n",
    "    arr, provs = lib_max_op(test_imgs, g_kernels)\n",
    "    arr.backward(test_tangent_dense)\n",
    "    del arr\n",
    "    cuda.synchronize()\n",
    "\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "run_one()\n",
    "# %timeit run_one()\n",
    "torch.cuda.empty_cache()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "25276d59ace4e5f5",
   "metadata": {},
   "source": [
    "from timeit import timeit\n",
    "from tqdm.auto import tqdm, trange"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "e242d9f79a09cb4f",
   "metadata": {},
   "source": [
    "# fmt: off\n",
    "slice_sizes = [2, 3, 4, 6, 8, 12, 16, 23, 32, 46, 64, 91, 128, 182, 256, 363, 512, 725, 1024, 1449, 2048]\n",
    "unfold_timings = [0.00010274730650053243, 8.403245400040759e-05, 8.851143950232653e-05, 0.00010076602150002145,\n",
    "                  0.00012131676400167635, 0.000124929585501377, 0.00014966875500249443, 0.000199354405496706,\n",
    "                  0.00025833106350182786, 0.00035760370749994764, 0.0004823765924993495, 0.0006648011590004899,\n",
    "                  0.0009164136265026173, 0.001269442678501946, 0.0017770433570003662, 0.0025119446479984616,\n",
    "                  0.0036233893550015636, 0.0052635354004996774, 0.007498402453999006, 0.010653741374000674,\n",
    "                  0.014994164466501389]\n",
    "numba_timings = [0.00041991026799951213, 0.0004150625224974647, 0.00041995406449859727, 0.0004226304935000371,\n",
    "                 0.0004205896764979116, 0.0004200762550026411, 0.00042519056650053245, 0.00043969415899846356,\n",
    "                 0.000461269485498633, 0.0004921157089993358, 0.0005326687759988999, 0.000598328826999932,\n",
    "                 0.0006867694915017637, 0.0008550973589990463, 0.0010212399034971896, 0.0012820430794999993,\n",
    "                 0.0016308881609984381, 0.00213099660050284, 0.002836544132500421, 0.0040347791409985805,\n",
    "                 0.0056132207165028375]\n",
    "slice_sizes_detail = [70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89]\n",
    "unfold_timings_detail = [0.0005231618008999794, 0.0005300874041199859, 0.0005373257529799594, 0.000543491658839921,\n",
    "                         0.0005501257682598953, 0.0005600170065599377, 0.0005661544485400373, 0.0005724291121000715,\n",
    "                         0.0005786100002999592, 0.0005850134414200147, 0.0005919706213800236, 0.0005975213742800406,\n",
    "                         0.0006039276255598815, 0.0006115772961400217, 0.0006184966304400586, 0.000624261617519951,\n",
    "                         0.0006320271702000172, 0.0006411902578199806, 0.0006466227984400757, 0.0006526624815800461]\n",
    "numba_timings_detail = [0.0005487732924800366, 0.0005504305595999176, 0.0005602229583999724, 0.0005519845550401078,\n",
    "                        0.0005552577408599609, 0.0005599274011599482, 0.0005594913014999475, 0.000562018028760067,\n",
    "                        0.0005715560740999354, 0.000603191901879909, 0.0005728149966799538, 0.0006106505254599324,\n",
    "                        0.0005787932900199667, 0.0005814040630200179, 0.0005867868537201139, 0.0005937331920399446,\n",
    "                        0.0006245092738600214, 0.0005905518150200078, 0.000597254317360057, 0.0005953584205200604]\n",
    "# fmt: on"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "7fd2cc036d6840ec",
   "metadata": {},
   "source": [
    "run_timings = False"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "81130a52aee07483",
   "metadata": {},
   "source": [
    "if run_timings:\n",
    "    torch_code = \"\"\"\n",
    "sync()\n",
    "arr = dilate(imgs, kernels, padding=1)\n",
    "arr.backward(tangent)\n",
    "del arr\n",
    "sync()\n",
    "    \"\"\"\n",
    "    slice_sizes = []\n",
    "    unfold_timings = []\n",
    "    numba_timings = []\n",
    "    num_loops = 2_000\n",
    "    bar = trange(2, 23)\n",
    "    for size_pow in bar:\n",
    "        test_size = math.ceil(2 ** (size_pow / 2))\n",
    "        test_slice = test_imgs[:test_size]\n",
    "        slice_sizes.append(len(test_slice))\n",
    "        unfold_timings.append(\n",
    "            timeit(\n",
    "                torch_code,\n",
    "                number=num_loops,\n",
    "                globals={\n",
    "                    \"sync\": torch.cuda.synchronize,\n",
    "                    \"imgs\": test_slice.clone().requires_grad_(True),\n",
    "                    \"kernels\": test_kernels.unsqueeze(1).clone().requires_grad_(True),\n",
    "                    \"tangent\": torch.randn_like(test_slice),\n",
    "                    \"dilate\": unfold_max,\n",
    "                },\n",
    "            )\n",
    "            / num_loops\n",
    "        )\n",
    "        numba_timings.append(\n",
    "            timeit(\n",
    "                torch_code,\n",
    "                number=num_loops,\n",
    "                globals={\n",
    "                    \"sync\": cuda.synchronize,\n",
    "                    \"imgs\": test_slice.clone().requires_grad_(True),\n",
    "                    \"kernels\": test_kernels.clone().requires_grad_(True),\n",
    "                    \"tangent\": torch.randn_like(test_slice),\n",
    "                    \"dilate\": numba_max,\n",
    "                },\n",
    "            )\n",
    "            / num_loops\n",
    "        )\n",
    "        bar.set_postfix(\n",
    "            size=slice_sizes[-1],\n",
    "            faster=\"unfold\" if unfold_timings[-1] < numba_timings[-1] else \"numba\",\n",
    "        )"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "d51fa1c74253750e",
   "metadata": {},
   "source": [
    "colors = plt.rcParams[\"axes.prop_cycle\"].by_key()[\"color\"]\n",
    "\n",
    "plt.plot(slice_sizes, unfold_timings, label=\"Unfold\", color=colors[0])\n",
    "plt.scatter(slice_sizes, unfold_timings, color=colors[0])\n",
    "plt.plot(slice_sizes, numba_timings, label=\"Numba CUDA\", color=colors[1])\n",
    "plt.scatter(slice_sizes, numba_timings, color=colors[1])\n",
    "first_better = (np.subtract(unfold_timings, numba_timings) > 0).argmax()\n",
    "plt.axvline(slice_sizes[first_better], linestyle=\"dashed\", color=\"grey\")\n",
    "plt.text(slice_sizes[first_better - 1], 10 ** -3, slice_sizes[first_better], color=\"grey\")\n",
    "adjusted_numba = np.asarray(numba_timings) - numba_timings[1] + unfold_timings[1]\n",
    "plt.plot(\n",
    "    slice_sizes,\n",
    "    adjusted_numba,\n",
    "    label=\"Theoretical no-overhead Numba\",\n",
    "    linestyle=\"dashed\",\n",
    "    color=colors[1],\n",
    ")\n",
    "plt.xlabel(\"Batch size\")\n",
    "plt.ylabel(\"Time\")\n",
    "plt.title(\"Forwards- and backwards-pass with PyTorch Unfold and a Numba CUDA kernel\")\n",
    "plt.loglog()\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "93ad1e6dc98bac6d",
   "metadata": {},
   "source": [
    "if run_timings:\n",
    "    torch_code = \"\"\"\n",
    "sync()\n",
    "arr = dilate(imgs, kernels, padding=1)\n",
    "arr.backward(tangent)\n",
    "del arr\n",
    "sync()\n",
    "    \"\"\"\n",
    "    slice_sizes_detail = []\n",
    "    unfold_timings_detail = []\n",
    "    numba_timings_detail = []\n",
    "    num_loops = 50_000\n",
    "    bar = trange(70, 90)\n",
    "    test_tangent = torch.randn_like(test_imgs)\n",
    "    for test_size in bar:\n",
    "        test_slice = test_imgs[:test_size]\n",
    "        slice_sizes_detail.append(len(test_slice))\n",
    "        unfold_timings_detail.append(\n",
    "            timeit(\n",
    "                torch_code,\n",
    "                number=num_loops,\n",
    "                globals={\n",
    "                    \"sync\": torch.cuda.synchronize,\n",
    "                    \"imgs\": test_slice.clone().requires_grad_(True),\n",
    "                    \"kernels\": test_kernels.unsqueeze(1).clone().requires_grad_(True),\n",
    "                    \"tangent\": test_tangent[:test_size],\n",
    "                    \"dilate\": unfold_max,\n",
    "                },\n",
    "            )\n",
    "            / num_loops\n",
    "        )\n",
    "        numba_timings_detail.append(\n",
    "            timeit(\n",
    "                torch_code,\n",
    "                number=num_loops,\n",
    "                globals={\n",
    "                    \"sync\": cuda.synchronize,\n",
    "                    \"imgs\": test_slice.clone().requires_grad_(True),\n",
    "                    \"kernels\": test_kernels.clone().requires_grad_(True),\n",
    "                    \"tangent\": test_tangent[:test_size],\n",
    "                    \"dilate\": numba_max,\n",
    "                },\n",
    "            )\n",
    "            / num_loops\n",
    "        )\n",
    "        bar.set_postfix(\n",
    "            size=slice_sizes_detail[-1],\n",
    "            faster=\"unfold\"\n",
    "            if unfold_timings_detail[-1] < numba_timings_detail[-1]\n",
    "            else \"numba\",\n",
    "        )"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "cf0f3cc06fa26751",
   "metadata": {},
   "source": [
    "colors = plt.rcParams[\"axes.prop_cycle\"].by_key()[\"color\"]\n",
    "\n",
    "plt.plot(slice_sizes_detail, unfold_timings_detail, label=\"Unfold\", color=colors[0])\n",
    "plt.scatter(slice_sizes_detail, unfold_timings_detail, color=colors[0])\n",
    "plt.plot(slice_sizes_detail, numba_timings_detail, label=\"Numba CUDA\", color=colors[1])\n",
    "plt.scatter(slice_sizes_detail, numba_timings_detail, color=colors[1])\n",
    "first_better = (np.subtract(unfold_timings_detail, numba_timings_detail) > 0).argmax()\n",
    "plt.axvline(slice_sizes_detail[first_better], linestyle=\"dashed\", color=\"grey\")\n",
    "plt.text(\n",
    "    slice_sizes_detail[first_better - 1],\n",
    "    0.00058,\n",
    "    slice_sizes_detail[first_better],\n",
    "    color=\"grey\",\n",
    ")\n",
    "adjusted_numba = (\n",
    "        np.asarray(numba_timings_detail)\n",
    "        - numba_timings_detail[1]\n",
    "        + unfold_timings_detail[1]\n",
    ")\n",
    "plt.xlabel(\"Batch size\")\n",
    "plt.ylabel(\"Time\")\n",
    "plt.title(\"Zoomed in\")\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "b296cffbc5f63f1",
   "metadata": {},
   "source": [
    "import warnings\n",
    "import numba\n",
    "\n",
    "warnings.simplefilter(\"ignore\", numba.NumbaPerformanceWarning, 536)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "907ed55f99b66fd1",
   "metadata": {},
   "source": [
    "def _conv_output_size(\n",
    "        input_size: int, kernel_size: int, stride: int, padding: int, dilation: int\n",
    "):\n",
    "    return math.floor(\n",
    "        (input_size + 2 * padding - dilation * (kernel_size - 1) - 1) / stride + 1\n",
    "    )"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "4a85ce1b441e7919",
   "metadata": {},
   "source": [
    "import typing\n",
    "\n",
    "\n",
    "class Foo(typing.NamedTuple):\n",
    "    bar: float\n",
    "\n",
    "\n",
    "ree = Foo(279.0)\n",
    "\n",
    "\n",
    "def rawr(x):\n",
    "    return x * 2\n",
    "\n",
    "\n",
    "@cuda.jit(\"void(float32[:])\", lineinfo=False)\n",
    "def spam(arr):\n",
    "    x = cuda.grid(1)\n",
    "    if x < arr.size:\n",
    "        arr[x] += rawr(ree.bar)\n",
    "\n",
    "\n",
    "a = torch.ones(5, device=\"cuda\")\n",
    "spam[1, 32](a)\n",
    "a"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "15af25fd26630824",
   "metadata": {},
   "source": [
    "Foo(3.0) == (3,)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "452b13b5cf1f3a52",
   "metadata": {},
   "source": [
    "import uuid\n",
    "\n",
    "\n",
    "def compile_tropical_op(\n",
    "        example_imgs: torch.Tensor,\n",
    "        example_kernels: torch.Tensor,\n",
    "        *,\n",
    "        is_max: bool,\n",
    "        block_size: int = 256,\n",
    "        kernel_broadcasting: bool = False,\n",
    "        debug: bool = False,\n",
    "        fixed_stride: int = 1,\n",
    "        fixed_padding: int = 1,\n",
    "        fixed_dilation: int = 1,\n",
    "        compile_entry_point: bool = True,\n",
    "):\n",
    "    # === Check example_imgs\n",
    "    assert torch.cuda.is_available(), \"No CUDA?\"\n",
    "    assert example_imgs.dtype == torch.float32, f\"{example_imgs.dtype=}\"\n",
    "    assert example_kernels.dtype == torch.float32, f\"{example_kernels.dtype=}\"\n",
    "    assert len(example_imgs.shape) == 4\n",
    "    cs, i_ys, i_xs = example_imgs.shape[1:]\n",
    "\n",
    "    # === Check example_kernels\n",
    "    if len(example_kernels.shape) == 4:\n",
    "        example_kernels = example_kernels.squeeze(1)\n",
    "    k_cs, k_ys, k_xs = example_kernels.shape\n",
    "    if kernel_broadcasting:\n",
    "        assert k_cs == 1, f\"Asked for kernel broadcasting, but {example_kernels.shape=}\"\n",
    "        raise NotImplementedError\n",
    "    else:\n",
    "        assert cs == k_cs, f\"No kernel broadcasting, but {cs=} != {k_cs=}\"\n",
    "\n",
    "    # We reserve prov_maxval for debugging invalid provenances\n",
    "    prov_maxval = np.iinfo(np.uint8).max\n",
    "    assert k_ys < prov_maxval, f\"Provenance indices are represented as u8, but {k_ys=}\"\n",
    "    assert k_xs < prov_maxval, f\"Provenance indices are represented as u8, but {k_xs=}\"\n",
    "\n",
    "    ex_img_shape_no_b = tuple(example_imgs.shape[1:])\n",
    "    ex_kernel_shape = tuple(example_kernels.shape)\n",
    "\n",
    "    o_xs = _conv_output_size(i_xs, k_xs, fixed_stride, fixed_padding, fixed_dilation)\n",
    "    o_ys = _conv_output_size(i_ys, k_ys, fixed_stride, fixed_padding, fixed_dilation)\n",
    "    blocks_per_image = cs * o_xs * o_ys / block_size\n",
    "\n",
    "    op_id = uuid.uuid4().hex\n",
    "    # === (temporary) Forward functions ===\n",
    "    if is_max:\n",
    "\n",
    "        def weigh(v, w):\n",
    "            return v + w\n",
    "\n",
    "        neutral = -INF\n",
    "\n",
    "        def select_right(left, right):\n",
    "            return left < right\n",
    "\n",
    "    else:\n",
    "\n",
    "        def weigh(v, w):\n",
    "            return v - w\n",
    "\n",
    "        neutral = INF\n",
    "\n",
    "        def select_right(left, right):\n",
    "            return left > right\n",
    "\n",
    "    # def is_valid(val):\n",
    "    #     return val != neutral\n",
    "\n",
    "    # === (temporary) Backward functions ===\n",
    "    def one(_v, _w):\n",
    "        return 1\n",
    "\n",
    "    def minus_one(_v, _w):\n",
    "        return -1\n",
    "\n",
    "    if is_max:\n",
    "        d_weigh_d_img = d_weigh_d_kernel = one\n",
    "    else:\n",
    "        d_weigh_d_img = one\n",
    "        d_weigh_d_kernel = minus_one\n",
    "\n",
    "    # === Compile user-provided functions\n",
    "    weigh = cuda.jit(weigh, device=True, inline=True)\n",
    "    select_right = cuda.jit(select_right, device=True, inline=True)\n",
    "    d_weigh_d_img = cuda.jit(d_weigh_d_img, device=True, inline=True)\n",
    "    d_weigh_d_kernel = cuda.jit(d_weigh_d_kernel, device=True, inline=True)\n",
    "\n",
    "    # is_valid = cuda.jit(is_valid, device=True, inline=True)\n",
    "\n",
    "    # === Forwards CUDA-side ===\n",
    "    @cuda.jit(\n",
    "        \"void(float32[:, :, :, :],\"  # img: [Batch, Channel, Img_Y, Img_X]\n",
    "        \" float32[:, :, :],\"  # kernel: [Channel, Kernel_Y, Kernel_X\n",
    "        \" float32[:, :, :, :],\"  # out_img: [Batch, Channel, Img_Y, Img_X]\n",
    "        \" uint8[:, :, :, :, :])\",  # out_prov: [Batch, Channel, Img_Y, Img_X, 2 (y, then x)]\n",
    "        debug=debug,\n",
    "        opt=not debug,\n",
    "    )\n",
    "    def conv_cuda_jit(img, kernel, out_img, out_prov):\n",
    "        idx = cuda.grid(1)\n",
    "        if idx >= out_img.size:\n",
    "            return\n",
    "        rem, o_x = divmod(idx, o_xs)\n",
    "        rem, o_y = divmod(rem, o_ys)\n",
    "        b, c = divmod(rem, cs)\n",
    "\n",
    "        i_top_y = o_y * fixed_stride - fixed_padding\n",
    "        i_left_x = o_x * fixed_stride - fixed_padding\n",
    "\n",
    "        prov_x = prov_y = prov_maxval\n",
    "        selected_val = neutral\n",
    "\n",
    "        for k_y, i_y in enumerate(\n",
    "                range(i_top_y, i_top_y + k_ys * fixed_dilation, fixed_dilation)\n",
    "        ):\n",
    "            for k_x, i_x in enumerate(\n",
    "                    range(i_left_x, i_left_x + k_xs * fixed_dilation, fixed_dilation)\n",
    "            ):\n",
    "                if i_x < 0 or i_x >= i_xs or i_y < 0 or i_y >= i_ys:\n",
    "                    continue\n",
    "\n",
    "                img_val = img[b, c, i_y, i_x]\n",
    "                kernel_val = kernel[0 if kernel_broadcasting else c, k_y, k_x]\n",
    "\n",
    "                val = weigh(img_val, kernel_val)\n",
    "                if select_right(selected_val, val):\n",
    "                    selected_val = val\n",
    "                    prov_y, prov_x = k_y, k_x\n",
    "\n",
    "        out_img[b, c, o_y, o_x] = selected_val\n",
    "\n",
    "        out_prov[b, c, o_y, o_x, 0] = prov_y\n",
    "        out_prov[b, c, o_y, o_x, 1] = prov_x\n",
    "\n",
    "    # === Forwards torch-side ===\n",
    "    @torch.library.custom_op(\n",
    "        f\"semifields::tropical_op_{op_id}\", mutates_args={}, device_types=\"cuda\"\n",
    "    )\n",
    "    def conv_cuda_lib(\n",
    "            img: torch.Tensor, kernel: torch.Tensor\n",
    "    ) -> tuple[torch.Tensor, torch.Tensor]:\n",
    "        img, kernel = img.detach(), kernel.detach()\n",
    "        assert kernel.shape == ex_kernel_shape, f\"Different {kernel.shape=}\"\n",
    "        assert img.shape[1:] == ex_img_shape_no_b, f\"Different {img.shape[1:]=}\"\n",
    "        assert img.dtype == torch.float32, f\"Wrong {img.dtype=}\"\n",
    "        if debug:\n",
    "            print(\"Warning: running CUDA kernel in debug mode\")\n",
    "        batch = img.shape[0]\n",
    "        out_img = img.new_empty((batch, cs, o_ys, o_xs))\n",
    "        out_prov = img.new_empty((batch, cs, o_ys, o_xs, 2), dtype=torch.uint8)\n",
    "        n_blocks = math.ceil(batch * blocks_per_image)\n",
    "        conv_cuda_jit[n_blocks, block_size](img, kernel, out_img, out_prov)\n",
    "        return out_img, out_prov\n",
    "\n",
    "    @conv_cuda_lib.register_fake\n",
    "    def _(img, kernel):\n",
    "        batch = img.shape[0]\n",
    "        return (\n",
    "            img.new_empty((batch, cs, o_ys, o_xs)),\n",
    "            kernel.new_empty((batch, cs, o_ys, o_xs, 2), dtype=torch.uint8),\n",
    "        )\n",
    "\n",
    "    # === Backwards CUDA-side ===\n",
    "    # noinspection PyArgumentList\n",
    "    @cuda.jit(\n",
    "        \"void(float32[:, :, :, :],\"  # img: [Batch, Channel, Img_Y, Img_X]\n",
    "        \" float32[:, :, :],\"  # kernel: [Channel, Kernel_Y, Kernel_X]\n",
    "        \" float32[:, :, :, :],\"  # tangent: [Batch, Channel, Img_Y, Img_X]\n",
    "        \" uint8[:, :, :, :, :],\"  # prov: [Batch, Channel, Img_Y, Img_X, 2 (y, then x)]\n",
    "        \" float32[:, :, :, :],\"  # out_img_grad: [Batch, Channel, Img_Y, Img_X]\n",
    "        \" float32[:, :, :])\",  # out_kernel_grad: [Channel, Kernel_Y, Kernel_X]\n",
    "        debug=debug,\n",
    "        opt=not debug,\n",
    "    )\n",
    "    def conv_backwards_cuda_jit(\n",
    "            img, kernel, gradient, prov, out_img_grad, out_kernel_grad\n",
    "    ):\n",
    "        idx = cuda.grid(1)\n",
    "        if idx >= gradient.size:\n",
    "            return\n",
    "        rem, o_x = divmod(idx, o_xs)\n",
    "        rem, o_y = divmod(rem, o_ys)\n",
    "        b, c = divmod(rem, cs)\n",
    "        gradient = gradient[b, c, o_y, o_x]\n",
    "        if gradient == 0.0:\n",
    "            return\n",
    "\n",
    "        k_prov_y = prov[b, c, o_y, o_x, 0]\n",
    "        k_prov_x = prov[b, c, o_y, o_x, 1]\n",
    "        if k_prov_y == prov_maxval:\n",
    "            # We only looked at padding values,\n",
    "            # so our gradient can't be related to\n",
    "            # the image\n",
    "            return\n",
    "        kernel_val = kernel[c, k_prov_y, k_prov_x]\n",
    "\n",
    "        i_top_y = o_y * fixed_stride - fixed_padding\n",
    "        i_left_x = o_x * fixed_stride - fixed_padding\n",
    "        i_prov_y = i_top_y + fixed_dilation * k_prov_y\n",
    "        i_prov_x = i_left_x + fixed_dilation * k_prov_x\n",
    "        if i_prov_x < 0 or i_prov_x >= i_xs or i_prov_y < 0 or i_prov_y >= i_ys:\n",
    "            return\n",
    "        img_val = img[b, c, i_prov_y, i_prov_x]\n",
    "\n",
    "        dv = d_weigh_d_img(img_val, kernel_val) * gradient\n",
    "        dw = d_weigh_d_kernel(img_val, kernel_val) * gradient\n",
    "\n",
    "        cuda.atomic.add(out_img_grad, (b, c, i_prov_y, i_prov_x), dv)\n",
    "        cuda.atomic.add(out_kernel_grad, (c, k_prov_y, k_prov_x), dw)\n",
    "\n",
    "    # === Backwards torch-side ===\n",
    "    @torch.library.custom_op(\n",
    "        f\"semifields::tropical_op_back_{op_id}\", mutates_args={}, device_types=\"cuda\"\n",
    "    )\n",
    "    def conv_backwards_cuda_lib(\n",
    "            img: torch.Tensor,\n",
    "            kernel: torch.Tensor,\n",
    "            gradient: torch.Tensor,\n",
    "            prov: torch.Tensor,\n",
    "    ) -> tuple[torch.Tensor, torch.Tensor]:\n",
    "        img, kernel = img.detach(), kernel.detach()\n",
    "        out_img_grad = torch.zeros_like(img)\n",
    "        out_kernel_grad = torch.zeros_like(kernel)\n",
    "        n_blocks = math.ceil(gradient.nelement() / block_size)\n",
    "        conv_backwards_cuda_jit[n_blocks, block_size](\n",
    "            img, kernel, gradient, prov, out_img_grad, out_kernel_grad\n",
    "        )\n",
    "        return out_img_grad, out_kernel_grad\n",
    "\n",
    "    @conv_backwards_cuda_lib.register_fake\n",
    "    def _(img, kernel, _gradient, _prov):\n",
    "        return torch.empty_like(img), torch.empty_like(kernel)\n",
    "\n",
    "    def back_setup(ctx, inputs, output):\n",
    "        img, kernel = inputs\n",
    "        _out_img, prov = output\n",
    "        ctx.img = img\n",
    "        ctx.kernel = kernel\n",
    "        ctx.prov = prov\n",
    "\n",
    "    def lib_back(ctx, grad_output, _grad_prov):\n",
    "        return conv_backwards_cuda_lib(ctx.img, ctx.kernel, grad_output, ctx.prov)\n",
    "\n",
    "    conv_cuda_lib.register_autograd(lib_back, setup_context=back_setup)\n",
    "\n",
    "    if debug:\n",
    "        print(\"Calculated output shape\", cs, o_ys, o_xs)\n",
    "        with warnings.catch_warnings():\n",
    "            warnings.simplefilter(\"ignore\", UserWarning)\n",
    "            with torch.autograd.detect_anomaly():\n",
    "                # noinspection PyTypeChecker\n",
    "                torch.library.opcheck(conv_cuda_lib, (example_imgs, example_kernels))\n",
    "    del example_imgs, example_kernels\n",
    "\n",
    "    # === Entry point ===\n",
    "    @torch.compile(fullgraph=True, backend=\"inductor\", disable=not compile_entry_point)\n",
    "    def conv(\n",
    "            img: torch.Tensor,\n",
    "            kernel: torch.Tensor,\n",
    "            stride: int = fixed_stride,\n",
    "            padding: int = fixed_padding,\n",
    "            dilation: int = fixed_dilation,\n",
    "    ):\n",
    "        if len(kernel.shape) == 4:\n",
    "            kernel = kernel.squeeze(1)\n",
    "\n",
    "        if (\n",
    "                padding != fixed_padding\n",
    "                or stride != fixed_stride\n",
    "                or dilation != fixed_dilation\n",
    "        ):\n",
    "            raise ValueError(\"Cannot change stride/padding/dilation after compilation\")\n",
    "\n",
    "        out_img, _out_prov = conv_cuda_lib(img, kernel)\n",
    "        return out_img\n",
    "\n",
    "    return conv\n",
    "\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "ex_op = compile_tropical_op(g_imgs, g_kernels, is_max=True, debug=True)\n",
    "ex_op_modified = compile_tropical_op(\n",
    "    g_imgs,\n",
    "    g_kernels,\n",
    "    debug=True,\n",
    "    is_max=True,\n",
    "    fixed_stride=1,\n",
    "    fixed_padding=2,\n",
    "    fixed_dilation=2,\n",
    ")\n",
    "ex_min_op = compile_tropical_op(test_imgs, test_kernels, is_max=False, debug=True)\n",
    "ex_res = ex_op(g_imgs, g_kernels)\n",
    "ex_res_mod = ex_op_modified(g_imgs, g_kernels)\n",
    "ex_res_min = ex_min_op(g_imgs, g_kernels)\n",
    "\n",
    "ref_res = convolutions.TropicalConv2D(is_max=True)(\n",
    "    test_imgs, test_kernels.unsqueeze(1), stride=1, padding=2, dilation=2\n",
    ")\n",
    "\n",
    "_, (axs, axs_ref) = plt.subplots(nrows=2, ncols=4, figsize=(10, 5))\n",
    "axs[0].matshow(test_imgs[0, 1].numpy(force=True))\n",
    "axs[1].matshow(ex_res[0, 1].numpy(force=True))\n",
    "axs[2].matshow(ex_res_mod[0, 1].numpy(force=True))\n",
    "axs[3].matshow(ex_res_min[0, 1].numpy(force=True))\n",
    "\n",
    "axs_ref[0].axis(\"off\")\n",
    "axs_ref[1].axis(\"off\")\n",
    "axs_ref[2].matshow(ref_res[0, 1].numpy(force=True))\n",
    "axs_ref[3].axis(\"off\")\n",
    "plt.show()\n",
    "print(test_imgs.shape, ex_res.shape, ex_res_mod.shape)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "e97a54891a1b226",
   "metadata": {},
   "source": [
    "def visualise_gradient(\n",
    "        conv_op,\n",
    "        img_nr: int = 0,\n",
    "        channel: int = 4,\n",
    "        tangent_xs=(7, 7, 7, 8),\n",
    "        tangent_ys=(6, 7, 8, 6),\n",
    "        **conv_kwargs,\n",
    "):\n",
    "    imgs = test_imgs.clone()\n",
    "    kernel = test_kernels.clone()\n",
    "    imgs.requires_grad_(True)\n",
    "    kernel.requires_grad_(True)\n",
    "    imgs.grad = None\n",
    "    kernel.grad = None\n",
    "\n",
    "    convolved = conv_op(imgs, kernel.unsqueeze(1), **conv_kwargs)\n",
    "    convolved[img_nr, channel, tangent_ys, tangent_xs].sum().backward()\n",
    "    _, axs = plt.subplots(ncols=5, layout=\"compressed\", figsize=(15, 15), dpi=300)\n",
    "    axs[0].matshow(kernel[channel].numpy(force=True))\n",
    "    axs[0].set_title(\"Kernel\")\n",
    "    axs[1].matshow(\n",
    "        imgs[img_nr, channel, y_slice, x_slice].numpy(force=True), vmin=0, vmax=2\n",
    "    )\n",
    "    axs[1].set_title(\"Original\")\n",
    "    axs[2].matshow(\n",
    "        convolved[img_nr, channel, y_slice, x_slice].numpy(force=True), vmin=0, vmax=2\n",
    "    )\n",
    "    axs[2].set_title(\"Convolved\")\n",
    "    imgs_grad = imgs.grad[img_nr, channel, y_slice, x_slice].numpy(force=True)\n",
    "    axs[3].matshow(imgs_grad)\n",
    "    axs[3].set_title(\"Image Gradient\")\n",
    "    kernel_grad = kernel.grad[channel].numpy(force=True)\n",
    "    axs[4].matshow(kernel_grad)\n",
    "    axs[4].set_title(\"Kernel Gradient\")\n",
    "    for grad_y, grad_x in zip(*imgs_grad.nonzero()):\n",
    "        axs[3].text(\n",
    "            grad_x,\n",
    "            grad_y,\n",
    "            imgs_grad[grad_y, grad_x],\n",
    "            color=\"black\",\n",
    "            fontsize=5,\n",
    "            ha=\"center\",\n",
    "            va=\"center\",\n",
    "        )\n",
    "    for grad_y, grad_x in zip(*kernel_grad.nonzero()):\n",
    "        axs[4].text(\n",
    "            grad_x,\n",
    "            grad_y,\n",
    "            kernel_grad[grad_y, grad_x],\n",
    "            color=\"black\",\n",
    "            fontsize=10,\n",
    "            ha=\"center\",\n",
    "            va=\"center\",\n",
    "        )\n",
    "    for ax, values in zip(axs[1:4], (imgs, convolved, imgs.grad)):\n",
    "        for t_x, t_y in zip(tangent_xs, tangent_ys):\n",
    "            ax.text(\n",
    "                t_x,\n",
    "                t_y,\n",
    "                values[img_nr, channel, t_y, t_x].numpy(force=True).round(2),\n",
    "                color=\"red\",\n",
    "                fontsize=5,\n",
    "                ha=\"center\",\n",
    "                va=\"center\",\n",
    "            )\n",
    "        # ax.scatter(target_x, target_y, marker=\"x\", color='red')\n",
    "    plt.suptitle(\"Unfold-max gradients\")\n",
    "    print(\"Nonzero gradient in image:\", imgs_grad.nonzero())"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "36192f68b2c02499",
   "metadata": {},
   "source": [
    "visualise_gradient(ex_op)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "2e9ec961fca5d62f",
   "metadata": {},
   "source": [
    "visualise_gradient(ex_op_modified)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "8074974f33e71a0b",
   "metadata": {},
   "source": [
    "import warnings\n",
    "\n",
    "failed1 = failed2 = None\n",
    "\n",
    "\n",
    "def test_same_conv(conv1, conv2, dilation=1, padding=1, stride=1):\n",
    "    global failed1, failed2\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter(\"ignore\", UserWarning)\n",
    "        with torch.autograd.detect_anomaly():\n",
    "            imgs1, kernels1 = (\n",
    "                test_imgs.clone().requires_grad_(True),\n",
    "                test_kernels.clone().unsqueeze(1).requires_grad_(True),\n",
    "            )\n",
    "            imgs2, kernels2 = (\n",
    "                test_imgs.clone().requires_grad_(True),\n",
    "                test_kernels.clone().unsqueeze(1).requires_grad_(True),\n",
    "            )\n",
    "\n",
    "            res1 = conv1(\n",
    "                imgs1, kernels1, dilation=dilation, padding=padding, stride=stride\n",
    "            )\n",
    "            res2 = conv2(\n",
    "                imgs2, kernels2, dilation=dilation, padding=padding, stride=stride\n",
    "            )\n",
    "            failed1, failed2 = res1, res2\n",
    "            torch.testing.assert_close(\n",
    "                res1.detach(), res2.detach(), msg=\"Results are not equal\"\n",
    "            )\n",
    "\n",
    "            tangent = torch.randn_like(res1)\n",
    "            res1.backward(tangent)\n",
    "            res2.backward(tangent)\n",
    "            failed1, failed2 = imgs1, imgs2\n",
    "            torch.testing.assert_close(\n",
    "                imgs1.detach(), imgs2.detach(), msg=\"Images were mutated\"\n",
    "            )\n",
    "            failed1, failed2 = kernels1, kernels2\n",
    "\n",
    "            torch.testing.assert_close(\n",
    "                kernels1.detach(), kernels2.detach(), msg=\"Kernels were mutated\"\n",
    "            )\n",
    "            failed1, failed2 = imgs1.grad.clone(), imgs2.grad.clone()\n",
    "            torch.testing.assert_close(\n",
    "                imgs1.grad, imgs2.grad, msg=\"Image gradient differs\"\n",
    "            )\n",
    "            failed1, failed2 = kernels1.grad.clone(), kernels2.grad.clone()\n",
    "            # More generous with kernel grad, because it is the result of a large reduction (errors compound)\n",
    "            torch.testing.assert_close(\n",
    "                kernels1.grad,\n",
    "                kernels2.grad,\n",
    "                msg=\"Kernel gradient differs\",\n",
    "                atol=0.01,\n",
    "                rtol=0.01,\n",
    "            )\n",
    "            failed1 = failed2 = None\n",
    "\n",
    "\n",
    "# Simple sanity checks\n",
    "test_same_conv(convolutions.TropicalConv2D(is_max=True), ex_op)\n",
    "print(\"Unfold max same as Numba CUDA version\")\n",
    "test_same_conv(convolutions.TropicalConv2D(is_max=False), ex_min_op)\n",
    "print(\"Unfold min same as Numba CUDA version\")\n",
    "test_same_conv(\n",
    "    convolutions.TropicalConv2D(is_max=True), ex_op_modified, padding=2, dilation=2\n",
    ")\n",
    "print(\"Modified max same as Numba CUDA version\")\n",
    "print(\"OK\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "3f8022c929409a7d",
   "metadata": {},
   "source": [
    "import itertools\n",
    "\n",
    "\n",
    "def check_param_space(max_stride: int = 5, max_padding: int = 5, max_dilation: int = 5):\n",
    "    torch.manual_seed(0)\n",
    "    param_space = itertools.product(\n",
    "        (False, True),\n",
    "        range(1, max_stride + 1),\n",
    "        range(max_padding + 1),\n",
    "        range(1, max_dilation + 1),\n",
    "    )\n",
    "\n",
    "    bar = tqdm(param_space, total=2 * max_stride * (max_padding + 1) * max_dilation)\n",
    "    for is_max, stride, padding, dilation in bar:\n",
    "        bar.set_postfix(\n",
    "            is_max=is_max,\n",
    "            stride=stride,\n",
    "            padding=padding,\n",
    "            dilation=dilation,\n",
    "            refresh=True,\n",
    "        )\n",
    "        test_same_conv(\n",
    "            convolutions.TropicalConv2D(is_max=is_max),\n",
    "            compile_tropical_op(\n",
    "                test_imgs,\n",
    "                test_kernels,\n",
    "                is_max=is_max,\n",
    "                fixed_stride=stride,\n",
    "                fixed_padding=padding,\n",
    "                fixed_dilation=dilation,\n",
    "                compile_entry_point=False,\n",
    "                debug=False,\n",
    "            ),\n",
    "            stride=stride,\n",
    "            padding=padding,\n",
    "            dilation=dilation,\n",
    "        )\n",
    "    print(\"OK\")\n",
    "\n",
    "\n",
    "check_param_space()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "c4410ed0b7f7d2ea",
   "metadata": {},
   "source": [
    "if failed1 is not None:\n",
    "    _, axs = plt.subplots(ncols=4, layout=\"compressed\", figsize=(10, 6))\n",
    "    channel_nr = 0\n",
    "    img_num = 0\n",
    "    axs[0].matshow(test_kernels[channel_nr].numpy(force=True))\n",
    "    axs[0].set_title(\"Kernel\")\n",
    "    axs[1].matshow(failed1[img_num, channel_nr, -5:, -5:].numpy(force=True))\n",
    "    axs[1].set_title(\"Unpool\")\n",
    "    axs[2].matshow(failed2[img_num, channel_nr, -5:, -5:].numpy(force=True))\n",
    "    axs[2].set_title(\"Numba\")\n",
    "    diff = (failed1[:, channel_nr] - failed2[:, channel_nr]).numpy(force=True).round(2)\n",
    "    print(\"Channel failed: \", diff.any())\n",
    "    axs[3].matshow(diff[img_num, -5:, -5:])\n",
    "    axs[3].set_title(\"Unpool $-$ Numba\")\n",
    "    plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "556d1891ebc1f9c6",
   "metadata": {},
   "source": [
    "visualise_gradient(ex_op_modified, padding=2, dilation=2)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "1e058ec47f4620a3",
   "metadata": {},
   "source": [
    "g_imgs = test_imgs.clone()\n",
    "g_kernels = test_kernels.clone()\n",
    "g_imgs.requires_grad_(True)\n",
    "g_kernels.requires_grad_(True)\n",
    "timing_op = compile_tropical_op(\n",
    "    g_imgs, g_kernels, is_max=True, fixed_stride=4, compile_entry_point=False\n",
    ")\n",
    "timing_tangent = torch.randn_like(timing_op(g_imgs, g_kernels))\n",
    "\n",
    "\n",
    "def run_one():\n",
    "    torch.cuda.synchronize()\n",
    "    arr = timing_op(g_imgs, g_kernels.unsqueeze(1), padding=1)\n",
    "    arr.backward(timing_tangent)\n",
    "    del arr\n",
    "    torch.cuda.synchronize()\n",
    "\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "run_one()\n",
    "%timeit run_one()\n",
    "torch.cuda.empty_cache()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "eb57c1d060c7a04a",
   "metadata": {},
   "source": [
    "g_imgs = test_imgs.clone()\n",
    "g_kernels = test_kernels.clone()\n",
    "g_imgs.requires_grad_(True)\n",
    "g_kernels.requires_grad_(True)\n",
    "timing_op = convolutions.TropicalConv2D(is_max=True)\n",
    "timing_tangent_alt = torch.randn_like(\n",
    "    timing_op(g_imgs, g_kernels.unsqueeze(1), padding=1, stride=1)\n",
    ")\n",
    "\n",
    "\n",
    "def run_one():\n",
    "    torch.cuda.synchronize()\n",
    "    arr = timing_op(g_imgs, g_kernels.unsqueeze(1), padding=1, stride=1)\n",
    "    arr.backward(timing_tangent_alt)\n",
    "    del arr\n",
    "    torch.cuda.synchronize()\n",
    "\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "run_one()\n",
    "%timeit run_one()\n",
    "torch.cuda.empty_cache()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "d0af94d6f4b896d2",
   "metadata": {},
   "source": [
    "# fmt: off\n",
    "slice_sizes_strided = [2, 3, 4, 6, 8, 12, 16, 23, 32, 46, 64, 91, 128, 182, 256, 363, 512, 725, 1024, 1449, 2048]\n",
    "unfold_timings_strided = [8.601449850539211e-05, 8.685274399613263e-05, 8.811392699863064e-05, 9.129133899841691e-05,\n",
    "                          9.529797050345224e-05, 0.00010843907199887326, 0.0001297704460012028, 0.0001692897860048106,\n",
    "                          0.0002150408624947886, 0.0002577364699973259, 0.0003326715309958672, 0.0004528659589996096,\n",
    "                          0.0006127196800007369, 0.0008511361700002453, 0.0011737010774959345, 0.0016564025280022179,\n",
    "                          0.002323884569996153, 0.004694061680500454, 0.00660860281749774, 0.009336203852995823,\n",
    "                          0.013332939886495296]\n",
    "numba_timings_strided = [0.00041195699350646465, 0.00040493240950308974, 0.00042407115850073753, 0.0004106013964992599,\n",
    "                         0.00041579102399555266, 0.0004095743720026803, 0.0004096275139963836, 0.0004132225249995827,\n",
    "                         0.0004206770234959549, 0.000413780028000474, 0.00042235061099927406, 0.0004335881020015222,\n",
    "                         0.000461321377006243, 0.0004885255344997859, 0.0005262560795017635, 0.0005949012644996401,\n",
    "                         0.0006804647999961162, 0.0008060576959978789, 0.0009685207395014004, 0.001236962188500911,\n",
    "                         0.0017974001669936114]\n",
    "# fmt: on"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "748c2244987324c4",
   "metadata": {},
   "source": [
    "run_timings_strided = False\n",
    "time_stride_size = 2"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "418634748bc23969",
   "metadata": {},
   "source": [
    "def get_timings_comparison(\n",
    "        n_loops: int = 2_000,\n",
    "        kernel: torch.Tensor = test_kernels,\n",
    "        stride: int = 1,\n",
    "        dilation: int = 1,\n",
    "        padding: int = 0,\n",
    "):\n",
    "    code = f\"\"\"\n",
    "sync()\n",
    "arr = dilate(imgs, kernel, padding={padding}, stride={stride}, dilation={dilation})\n",
    "arr.backward(gradient)\n",
    "del arr\n",
    "sync() \"\"\"\n",
    "    sizes = []\n",
    "    unfold_times = []\n",
    "    numba_times = []\n",
    "    bar = trange(2, 23)\n",
    "    for log_size in bar:\n",
    "        size = math.ceil(2 ** (log_size / 2))\n",
    "        batch = test_imgs[:size].clone().requires_grad_(True)\n",
    "        sizes.append(len(batch))\n",
    "        if len(kernel.shape) == 3:\n",
    "            kernel = kernel.unsqueeze(1)\n",
    "        kernel = kernel.clone().requires_grad_(True)\n",
    "        op = compile_tropical_op(\n",
    "            batch,\n",
    "            kernel,\n",
    "            is_max=True,\n",
    "            fixed_stride=stride,\n",
    "            fixed_padding=padding,\n",
    "            fixed_dilation=dilation,\n",
    "            compile_entry_point=False,\n",
    "        )\n",
    "        gradient = torch.randn_like(op(batch, kernel))\n",
    "        unfold_times.append(\n",
    "            timeit(\n",
    "                code,\n",
    "                number=n_loops,\n",
    "                globals={\n",
    "                    \"sync\": torch.cuda.synchronize,\n",
    "                    \"imgs\": batch,\n",
    "                    \"kernel\": kernel,\n",
    "                    \"gradient\": gradient,\n",
    "                    \"dilate\": unfold_max,\n",
    "                },\n",
    "            )\n",
    "            / n_loops\n",
    "        )\n",
    "        numba_times.append(\n",
    "            timeit(\n",
    "                code,\n",
    "                number=n_loops,\n",
    "                globals={\n",
    "                    \"sync\": cuda.synchronize,\n",
    "                    \"imgs\": batch,\n",
    "                    \"kernel\": kernel,\n",
    "                    \"gradient\": gradient,\n",
    "                    \"dilate\": op,\n",
    "                },\n",
    "            )\n",
    "            / n_loops\n",
    "        )\n",
    "        bar.set_postfix(\n",
    "            size=sizes[-1],\n",
    "            faster=\"unfold\" if unfold_times[-1] < numba_times[-1] else \"numba\",\n",
    "        )\n",
    "    return sizes, unfold_times, numba_times"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "b2a9479062d9f5d3",
   "metadata": {},
   "source": [
    "def plot_timings_comparison(sizes, unfold_times, numba_times, title=\"\"):\n",
    "    basic_colors = plt.rcParams[\"axes.prop_cycle\"].by_key()[\"color\"]\n",
    "    plt.plot(sizes, unfold_times, label=\"Unfold\", color=basic_colors[0])\n",
    "    plt.scatter(sizes, unfold_times, color=basic_colors[0])\n",
    "    plt.plot(sizes, numba_times, label=\"Numba CUDA\", color=basic_colors[1])\n",
    "    plt.scatter(sizes, numba_times, color=basic_colors[1])\n",
    "    numba_better_from = (np.subtract(unfold_times, numba_times) > 0).argmax()\n",
    "    plt.axvline(sizes[numba_better_from], linestyle=\"dashed\", color=\"grey\")\n",
    "    plt.text(\n",
    "        sizes[numba_better_from - 1],\n",
    "        10 ** -3,\n",
    "        sizes[numba_better_from],\n",
    "        color=\"grey\",\n",
    "    )\n",
    "    adj_numba = np.asarray(numba_times) - numba_times[1] + unfold_times[1]\n",
    "    plt.plot(\n",
    "        sizes,\n",
    "        adj_numba,\n",
    "        label=\"Theoretical no-overhead Numba\",\n",
    "        linestyle=\"dashed\",\n",
    "        color=basic_colors[1],\n",
    "    )\n",
    "    plt.xlabel(\"Batch size\")\n",
    "    plt.ylabel(\"Time\")\n",
    "    plt.title(title)\n",
    "    plt.loglog()\n",
    "    plt.legend()\n",
    "    plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "cba0d338f77f7f38",
   "metadata": {},
   "source": [
    "plot_timings_comparison(\n",
    "    *get_timings_comparison(\n",
    "        kernel=torch.randn(6, 1, 5, 5, device=\"cuda\"), padding=2, stride=2\n",
    "    ),\n",
    "    title=\"Size 5 kernels\",\n",
    ")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "8c05744f2a91c927",
   "metadata": {},
   "source": [
    "plot_timings_comparison(\n",
    "    *get_timings_comparison(\n",
    "        kernel=torch.randn(6, 1, 7, 7, device=\"cuda\"), padding=2, stride=2\n",
    "    ),\n",
    "    title=\"Size 7 kernels\",\n",
    ")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "bc026f3ac831bf35",
   "metadata": {},
   "source": [
    "if run_timings_strided:\n",
    "    torch_code = f\"\"\"\n",
    "sync()\n",
    "arr = dilate(imgs, kernels, padding=1, stride={time_stride_size})\n",
    "arr.backward(tangent)\n",
    "del arr\n",
    "sync()\n",
    "    \"\"\"\n",
    "    slice_sizes_strided = []\n",
    "    unfold_timings_strided = []\n",
    "    numba_timings_strided = []\n",
    "    num_loops = 2_000\n",
    "    bar = trange(2, 23)\n",
    "    for size_pow in bar:\n",
    "        test_size = math.ceil(2 ** (size_pow / 2))\n",
    "        test_slice = test_imgs[:test_size]\n",
    "        slice_sizes_strided.append(len(test_slice))\n",
    "        timing_op = compile_tropical_op(\n",
    "            test_slice,\n",
    "            test_kernels,\n",
    "            is_max=True,\n",
    "            fixed_stride=time_stride_size,\n",
    "            compile_entry_point=False,\n",
    "        )\n",
    "        _test_out = timing_op(test_slice, test_kernels)\n",
    "        test_tangent = torch.randn_like(_test_out)\n",
    "        unfold_timings_strided.append(\n",
    "            timeit(\n",
    "                torch_code,\n",
    "                number=num_loops,\n",
    "                globals={\n",
    "                    \"sync\": torch.cuda.synchronize,\n",
    "                    \"imgs\": test_slice.clone().requires_grad_(True),\n",
    "                    \"kernels\": test_kernels.unsqueeze(1).clone().requires_grad_(True),\n",
    "                    \"tangent\": test_tangent,\n",
    "                    \"dilate\": unfold_max,\n",
    "                },\n",
    "            )\n",
    "            / num_loops\n",
    "        )\n",
    "        numba_timings_strided.append(\n",
    "            timeit(\n",
    "                torch_code,\n",
    "                number=num_loops,\n",
    "                globals={\n",
    "                    \"sync\": cuda.synchronize,\n",
    "                    \"imgs\": test_slice.clone().requires_grad_(True),\n",
    "                    \"kernels\": test_kernels.clone().requires_grad_(True),\n",
    "                    \"tangent\": test_tangent,\n",
    "                    \"dilate\": timing_op,\n",
    "                },\n",
    "            )\n",
    "            / num_loops\n",
    "        )\n",
    "        bar.set_postfix(\n",
    "            size=slice_sizes_strided[-1],\n",
    "            faster=\"unfold\"\n",
    "            if unfold_timings_strided[-1] < numba_timings_strided[-1]\n",
    "            else \"numba\",\n",
    "        )"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "6e35e0ccf9da90a3",
   "metadata": {},
   "source": [
    "colors = plt.rcParams[\"axes.prop_cycle\"].by_key()[\"color\"]\n",
    "\n",
    "plt.plot(slice_sizes_strided, unfold_timings_strided, label=\"Unfold\", color=colors[0])\n",
    "plt.scatter(slice_sizes_strided, unfold_timings_strided, color=colors[0])\n",
    "plt.plot(\n",
    "    slice_sizes_strided, numba_timings_strided, label=\"Numba CUDA\", color=colors[1]\n",
    ")\n",
    "plt.scatter(slice_sizes_strided, numba_timings_strided, color=colors[1])\n",
    "first_better = (np.subtract(unfold_timings_strided, numba_timings_strided) > 0).argmax()\n",
    "plt.axvline(slice_sizes_strided[first_better], linestyle=\"dashed\", color=\"grey\")\n",
    "plt.text(\n",
    "    slice_sizes_strided[first_better - 1],\n",
    "    10 ** -3,\n",
    "    slice_sizes_strided[first_better],\n",
    "    color=\"grey\",\n",
    ")\n",
    "adjusted_numba = (\n",
    "        np.asarray(numba_timings_strided)\n",
    "        - numba_timings_strided[1]\n",
    "        + unfold_timings_strided[1]\n",
    ")\n",
    "plt.plot(\n",
    "    slice_sizes_strided,\n",
    "    adjusted_numba,\n",
    "    label=\"Theoretical no-overhead Numba\",\n",
    "    linestyle=\"dashed\",\n",
    "    color=colors[1],\n",
    ")\n",
    "plt.xlabel(\"Batch size\")\n",
    "plt.ylabel(\"Time\")\n",
    "plt.title(f\"Forwards- and backwards-pass with stride of {time_stride_size}\")\n",
    "plt.loglog()\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "b3d30cb3de4fcfa4",
   "metadata": {},
   "source": [
    "import importlib\n",
    "from src import convolutions\n",
    "from pytorch_semifield_conv import cuda_select\n",
    "\n",
    "importlib.reload(cuda_select)\n",
    "importlib.reload(convolutions)\n",
    "from src import convolutions"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "f06db8caf40d9e30",
   "metadata": {},
   "source": [
    "test_kernels.shape"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "ef4eacee46bda3d2",
   "metadata": {},
   "source": [
    "ss_max = convolutions.SelectSemifield.tropical_max().compile(\n",
    "    test_imgs, test_kernels.unsqueeze(1), groups=6, debug=True\n",
    ")\n",
    "ss_max"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "2491eec43b0908f2",
   "metadata": {},
   "source": [
    "visualise_gradient(\n",
    "    ss_max,\n",
    ")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "d766f4f66569e7f3",
   "metadata": {},
   "source": [
    "# Alternate form: less work, but can't be traced!\n",
    "\n",
    "\n",
    "class TestMaxOp(torch.autograd.Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, img: torch.Tensor, kernel: torch.Tensor) -> torch.Tensor:\n",
    "        res, prov = max_op(img, kernel)\n",
    "        ctx.save_for_backward(img, kernel, prov)\n",
    "        return res\n",
    "\n",
    "    # noinspection PyMethodOverriding\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output: torch.Tensor) -> tuple[torch.Tensor, torch.Tensor]:\n",
    "        img, kernel, prov = ctx.saved_tensors\n",
    "        return max_back_op(img, kernel, grad_output, prov)\n",
    "\n",
    "\n",
    "g_kernels.grad = None\n",
    "g_kernels.requires_grad_(True)\n",
    "TestMaxOp.apply(test_imgs, g_kernels).backward(test_tangent)\n",
    "plt.matshow(g_kernels.grad[channel_nr].numpy(force=True))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-27T18:10:30.813234Z",
     "start_time": "2025-04-27T18:10:30.791240Z"
    }
   },
   "cell_type": "code",
   "source": "from pytorch_semifield_conv.utils import ConvMeta",
   "id": "330f73a15b228174",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-27T18:10:31.225124Z",
     "start_time": "2025-04-27T18:10:31.219151Z"
    }
   },
   "cell_type": "code",
   "source": "test_imgs.shape",
   "id": "a1a272671cd91acb",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2048, 6, 28, 28])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-27T18:10:32.403480Z",
     "start_time": "2025-04-27T18:10:32.396606Z"
    }
   },
   "cell_type": "code",
   "source": [
    "meta = ConvMeta.infer(test_imgs, test_kernels, stride=2, padding=1, groups=6, kind='conv')\n",
    "meta"
   ],
   "id": "1a10b0b0fcac772a",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ConvMeta(img_bs=2048, img_cs=6, img_ys=28, img_xs=28, krn_o_group_size=1, krn_os=6, krn_cs=1, krn_ys=3, krn_xs=3, out_cs=6, out_ys=14, out_xs=14, stride=2, padding=1, dilation=1, groups=6, group_broadcasting=False, mirror_kernel=True)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-27T18:10:32.941869Z",
     "start_time": "2025-04-27T18:10:32.815279Z"
    }
   },
   "cell_type": "code",
   "source": [
    "@cuda.jit(\n",
    "    \"void(float32[:, :, :, :],\"  # img: [Batch, Channel, Img-Y, Img-X]\n",
    "    \" float32[:, :, :, :],\"  # kernel: [Out-chan, Group-chan, Kernel-Y, Kernel-X]\n",
    "    \" float32[:, :, :, :],\"  # out_img: [Batch, Out-chan, Out-Y, Out-X]\n",
    "    # out_prov: [B, O-chan, O-Y, O-X, 2 / 3 (y, x[, gi])]\n",
    "    f\" uint8[:, :, :, :, :])\",\n",
    ")\n",
    "def fwd_inlined(img, kernel, out_img, out_prov):\n",
    "    rem, o_x = divmod(cuda.grid(1), meta.out_xs)\n",
    "    rem, o_y = divmod(rem, meta.out_ys)\n",
    "    b, o_c = divmod(rem, meta.out_cs)\n",
    "    if b >= img.shape[0]:\n",
    "        return\n",
    "\n",
    "    i_top_y = o_y * meta.stride - meta.padding\n",
    "    i_left_x = o_x * meta.stride - meta.padding\n",
    "\n",
    "    prov_x = prov_y = prov_group_idx = 255\n",
    "    selected_val = -INF\n",
    "\n",
    "    group_number = o_c // meta.krn_o_group_size\n",
    "    # If we're not broadcasting, then we have a separate kernel\n",
    "    # for every output channel. If we are broadcasting, we instead loop\n",
    "    # around the kernels every k_os (which == krn_group_size)\n",
    "    k_o = o_c if not meta.group_broadcasting else o_c % meta.krn_o_group_size\n",
    "\n",
    "    # For a pooling, we have only one input channel, so group_idx is always 0\n",
    "    for group_idx in range(meta.krn_cs):\n",
    "        for y_step, i_y in enumerate(\n",
    "                range(i_top_y, i_top_y + meta.krn_ys * meta.dilation, meta.dilation)\n",
    "        ):\n",
    "            for x_step, i_x in enumerate(\n",
    "                    range(\n",
    "                        i_left_x,\n",
    "                        i_left_x + meta.krn_xs * meta.dilation,\n",
    "                        meta.dilation,\n",
    "                    )\n",
    "            ):\n",
    "                if i_x < 0 or i_x >= meta.img_xs or i_y < 0 or i_y >= meta.img_ys:\n",
    "                    continue\n",
    "\n",
    "                # Need to explicitly use seperate variable, due to compiler error\n",
    "                k_x = meta.krn_xs - 1 - x_step if meta.mirror_kernel else x_step\n",
    "                k_y = meta.krn_ys - 1 - y_step if meta.mirror_kernel else y_step\n",
    "\n",
    "                i_c = group_number * meta.krn_cs + group_idx\n",
    "                img_val = img[b, i_c, i_y, i_x]\n",
    "                kernel_val = kernel[k_o, group_idx, k_y, k_x]\n",
    "\n",
    "                val = img_val + kernel_val\n",
    "                if selected_val < val:\n",
    "                    selected_val = val\n",
    "                    prov_y, prov_x = k_y, k_x\n",
    "                    if meta.krn_cs > 1:\n",
    "                        prov_group_idx = group_idx\n",
    "\n",
    "    out_img[b, o_c, o_y, o_x] = selected_val\n",
    "\n",
    "    out_prov[b, o_c, o_y, o_x, 0] = prov_y\n",
    "    out_prov[b, o_c, o_y, o_x, 1] = prov_x\n",
    "    if meta.krn_cs > 1:\n",
    "        # out_prov is only size 3 if we require an index within the group\n",
    "        out_prov[b, o_c, o_y, o_x, 2] = prov_group_idx"
   ],
   "id": "599e800135863236",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-27T18:15:51.944517Z",
     "start_time": "2025-04-27T18:15:41.089243Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import math\n",
    "\n",
    "o_img = torch.empty((test_imgs.shape[0], meta.out_cs, meta.out_ys, meta.out_xs), device='cuda')\n",
    "o_prov = torch.empty(test_imgs.shape + (2,), dtype=torch.uint8, device='cuda')\n",
    "n_blocks = math.ceil(o_img.numel() / 256)\n",
    "\n",
    "\n",
    "def run_one():\n",
    "    fwd_inlined[n_blocks, 256](test_imgs[:1024], test_kernels, o_img, o_prov)\n",
    "    torch.cuda.synchronize()\n",
    "    pass\n",
    "\n",
    "\n",
    "run_one()\n",
    "plt.imshow(o_img[0, -1].numpy(force=True))\n",
    "%timeit run_one()"
   ],
   "id": "40a99cec0bd32e8d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "133 s  189 ns per loop (mean  std. dev. of 7 runs, 10,000 loops each)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-27T18:11:03.356852Z",
     "start_time": "2025-04-27T18:11:03.236366Z"
    }
   },
   "cell_type": "code",
   "source": [
    "@cuda.jit(\n",
    "    \"void(float32[:, :, :, :],\"  # img: [Batch, Channel, Img-Y, Img-X]\n",
    "    \" float32[:, :, :, :],\"  # kernel: [Out-chan, Group-chan, Kernel-Y, Kernel-X]\n",
    "    \" float32[:, :, :, :],\"  # out_img: [Batch, Out-chan, Out-Y, Out-X]\n",
    "    # out_prov: [B, O-chan, O-Y, O-X, 2 / 3 (y, x[, gi])]\n",
    "    f\" uint8[:, :, :, :, :],\"\n",
    "    \"uint32, uint32, uint32,\"\n",
    "    \"uint32, uint32, uint32,\"\n",
    "    \"uint32, bool\"\n",
    "    f\")\",\n",
    ")\n",
    "def fwd_outlined(img, kernel, out_img, out_prov, out_xs, out_ys, out_cs, stride, padding, dilation, krn_o_group_size,\n",
    "                 group_broadcasting):\n",
    "    rem, o_x = divmod(cuda.grid(1), out_xs)\n",
    "    rem, o_y = divmod(rem, out_ys)\n",
    "    b, o_c = divmod(rem, out_cs)\n",
    "    if b >= img.shape[0]:\n",
    "        return\n",
    "\n",
    "    i_top_y = o_y * stride - padding\n",
    "    i_left_x = o_x * stride - padding\n",
    "\n",
    "    prov_x = prov_y = prov_group_idx = 255\n",
    "    selected_val = -INF\n",
    "\n",
    "    group_number = o_c // krn_o_group_size\n",
    "    # If we're not broadcasting, then we have a separate kernel\n",
    "    # for every output channel. If we are broadcasting, we instead loop\n",
    "    # around the kernels every k_os (which == krn_group_size)\n",
    "    k_o = o_c if not group_broadcasting else o_c % krn_o_group_size\n",
    "\n",
    "    # For a pooling, we have only one input channel, so group_idx is always 0\n",
    "    for group_idx in range(kernel.shape[1]):\n",
    "        for y_step, i_y in enumerate(\n",
    "                range(i_top_y, i_top_y + kernel.shape[2] * dilation, dilation)\n",
    "        ):\n",
    "            for x_step, i_x in enumerate(\n",
    "                    range(\n",
    "                        i_left_x,\n",
    "                        i_left_x + kernel.shape[3] * dilation,\n",
    "                        dilation,\n",
    "                    )\n",
    "            ):\n",
    "                if i_x < 0 or i_x >= img.shape[3] or i_y < 0 or i_y >= img.shape[2]:\n",
    "                    continue\n",
    "\n",
    "                # Need to explicitly use seperate variable, due to compiler error\n",
    "                k_x = kernel.shape[3] - 1 - x_step\n",
    "                k_y = kernel.shape[2] - 1 - y_step\n",
    "\n",
    "                i_c = group_number * kernel.shape[1] + group_idx\n",
    "                img_val = img[b, i_c, i_y, i_x]\n",
    "                kernel_val = kernel[k_o, group_idx, k_y, k_x]\n",
    "\n",
    "                val = img_val + kernel_val\n",
    "                if selected_val < val:\n",
    "                    selected_val = val\n",
    "                    prov_y, prov_x = k_y, k_x\n",
    "                    prov_group_idx = group_idx\n",
    "\n",
    "    out_img[b, o_c, o_y, o_x] = selected_val\n",
    "\n",
    "    out_prov[b, o_c, o_y, o_x, 0] = prov_y\n",
    "    out_prov[b, o_c, o_y, o_x, 1] = prov_x\n",
    "    if kernel.shape[1] > 1:\n",
    "        # out_prov is only size 3 if we require an index within the group\n",
    "        out_prov[b, o_c, o_y, o_x, 2] = prov_group_idx"
   ],
   "id": "307ff6786e4d7ea",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-27T18:16:14.701942Z",
     "start_time": "2025-04-27T18:16:02.299826Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import math\n",
    "\n",
    "o_img = torch.empty((test_imgs.shape[0], meta.out_cs, meta.out_ys, meta.out_xs), device='cuda')\n",
    "o_prov = torch.empty(test_imgs.shape + (2,), dtype=torch.uint8, device='cuda')\n",
    "n_blocks = math.ceil(o_img.numel() / 256)\n",
    "\n",
    "\n",
    "def run_one():\n",
    "    fwd_outlined[n_blocks, 256](test_imgs[:1024], test_kernels, o_img, o_prov, meta.out_xs, meta.out_ys, meta.out_cs,\n",
    "                                meta.stride, meta.padding, meta.dilation, meta.krn_o_group_size,\n",
    "                                meta.group_broadcasting)\n",
    "    torch.cuda.synchronize()\n",
    "    pass\n",
    "\n",
    "\n",
    "run_one()\n",
    "plt.imshow(o_img[0, -1].numpy(force=True))\n",
    "plt.show()\n",
    "%timeit run_one()"
   ],
   "id": "3ea0f0e558bf69ba",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ],
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaAAAAGdCAYAAABU0qcqAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjEsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvc2/+5QAAAAlwSFlzAAAPYQAAD2EBqD+naQAAGj9JREFUeJzt3X1QVAe65/FfC6FhCHSEjAgrRCbXW74Ro0FdxZrRKzeu1xitqcQxRSZc3UrmBUeRu44yE8wkRolmxqV8WYzencSp8i27FY3j3jjrEF/KO74TUnEng7qhlIoLTGqTbsWSkObsH7PpuUSMgqfPQ+P3U3X+4HTr83Re+lsHug4+x3EcAQDgsX7WCwAA7k4ECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmIi3XuCrOjo6dPnyZaWkpMjn81mvAwDoJsdxdOXKFWVlZalfv5tf5/S6AF2+fFnZ2dnWawAA7lBjY6MGDRp008d7XYBSUlIkSZP0D4rXPcbbAAC66wu166j+JfJ+fjO9LkBfftstXvco3keAACDm/P87jN7qxyh8CAEAYIIAAQBMECAAgAkCBAAwQYAAACYIEADARNQCtHHjRg0ePFiJiYkaP368Tp48Ga1RAIAYFJUA7dq1S2VlZXrhhRdUW1urUaNGadq0aWppaYnGOABADIpKgNauXatnn31W8+bN0/Dhw7Vp0yZ94xvf0K9//etojAMAxCDXA/T555/rzJkzKiws/OuQfv1UWFioY8eO3fD8trY2hUKhTgcAoO9zPUCffPKJwuGwMjIyOp3PyMhQU1PTDc+vrKxUIBCIHNyIFADuDuafgisvL1cwGIwcjY2N1isBADzg+s1I77//fsXFxam5ubnT+ebmZg0cOPCG5/v9fvn9frfXAAD0cq5fASUkJOiRRx5RTU1N5FxHR4dqamo0YcIEt8cBAGJUVH4dQ1lZmYqLi5Wfn69x48apqqpKra2tmjdvXjTGAQBiUFQC9L3vfU9//vOftXz5cjU1Nenhhx/W/v37b/hgAgDg7uVzHMexXuLfCoVCCgQCmqxZ/EI6AIhBXzjtOqS3FQwGlZqaetPnmX8KDgBwdyJAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADARLz1AgCiJ/j0v/ds1icPezPH8fBda8akM57Mqc9v92ROb8MVEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwITrAaqsrNTYsWOVkpKiAQMGaPbs2aqvr3d7DAAgxrkeoMOHD6ukpETHjx/XgQMH1N7erkcffVStra1ujwIAxDDX76q0f//+Tl+/8cYbGjBggM6cOaNvf/vbbo8DAMSoqN/WLxgMSpLS0tK6fLytrU1tbW2Rr0OhULRXAgD0AlH9EEJHR4dKS0tVUFCgkSNHdvmcyspKBQKByJGdnR3NlQAAvURUA1RSUqKzZ89q586dN31OeXm5gsFg5GhsbIzmSgCAXiJq34JbsGCB9u3bpyNHjmjQoEE3fZ7f75ff74/WGgCAXsr1ADmOo5/85CfavXu3Dh06pNzcXLdHAAD6ANcDVFJSou3bt+vtt99WSkqKmpqaJEmBQEBJSUlujwMAxCjXfwZUXV2tYDCoyZMnKzMzM3Ls2rXL7VEAgBgWlW/BAQBwK9wLDgBgggABAEwQIACACQIEADBBgAAAJqJ+M1L0Xen/2t+TOd9K/sSTOc+lHfNkjiTlxN/r0aQ6j+ZIl7646skc7/7ZSUeuezPnxb/7j57MiX/3jCdzbhdXQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGAi3noBuMvn93s265Xs33oyJyf+Xk/mSF7NkS59cdWTOYF+cZ7MkaSP2lM9mfPD//CEJ3MkKfzHc57MidcZT+b0NlwBAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGAi6gF65ZVX5PP5VFpaGu1RAIAYEtUAnTp1Sq+99poeeuihaI4BAMSgqAXo6tWrKioq0pYtW9S/f/9ojQEAxKioBaikpEQzZsxQYWHh1z6vra1NoVCo0wEA6PuicjPSnTt3qra2VqdOnbrlcysrK/Xiiy9GYw0AQC/m+hVQY2OjFi1apG3btikxMfGWzy8vL1cwGIwcjY2Nbq8EAOiFXL8COnPmjFpaWjRmzJjIuXA4rCNHjmjDhg1qa2tTXNxfbxHv9/vl9/BXCAAAegfXAzR16lR98MEHnc7NmzdPQ4cO1dKlSzvFBwBw93I9QCkpKRo5cmSnc8nJyUpPT7/hPADg7sWdEAAAJjz5ldyHDh3yYgwAIIZwBQQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgwpOPYcM7TlubZ7N++Pf/6MmcD5fc58mchn/4Z0/mSNITFUs8mXP/vzZ5MsdL4QvnrFeAS7gCAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABPx1gsgdoXrL3gyZ9h/Cngy59KjVz2ZI0n/fcWrnsx55geLPZkjSf53Tnk2C30DV0AAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmIhKgD7++GM9/fTTSk9PV1JSkvLy8nT69OlojAIAxCjX74Tw6aefqqCgQFOmTNE777yjb37zmzp//rz69+/v9igAQAxzPUCrV69Wdna2Xn/99ci53Nxct8cAAGKc69+C27t3r/Lz8/Xkk09qwIABGj16tLZs2XLT57e1tSkUCnU6AAB9n+sB+uijj1RdXa0hQ4bod7/7nX70ox9p4cKF2rp1a5fPr6ysVCAQiBzZ2dlurwQA6IVcD1BHR4fGjBmjVatWafTo0Xruuef07LPPatOmTV0+v7y8XMFgMHI0Nja6vRIAoBdyPUCZmZkaPnx4p3PDhg3TpUuXuny+3+9XampqpwMA0Pe5HqCCggLV19d3Onfu3Dk98MADbo8CAMQw1wO0ePFiHT9+XKtWrdKFCxe0fft2bd68WSUlJW6PAgDEMNcDNHbsWO3evVs7duzQyJEjtWLFClVVVamoqMjtUQCAGBaVX8n92GOP6bHHHovGXw0A6CO4FxwAwAQBAgCYIEAAABMECABgggABAEwQIACAiah8DBtwU/izoCdzHn1jiSdzJOl//uOrnsw59F9vfid6t/3Njh96MufBfzruyRxEH1dAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATPsdxHOsl/q1QKKRAIKDJmqV43z3W6wBR0TZjrCdzXv8v/9mTOZKUe8+9nsyZ8r9meTJHkhL+/qJns/qSL5x2HdLbCgaDSk1NvenzuAICAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYcD1A4XBYFRUVys3NVVJSkh588EGtWLFCveyGCwAAY/Fu/4WrV69WdXW1tm7dqhEjRuj06dOaN2+eAoGAFi5c6PY4AECMcj1Af/jDHzRr1izNmDFDkjR48GDt2LFDJ0+edHsUACCGuf4tuIkTJ6qmpkbnzp2TJL3//vs6evSopk+f3uXz29raFAqFOh0AgL7P9SugZcuWKRQKaejQoYqLi1M4HNbKlStVVFTU5fMrKyv14osvur0GAKCXc/0K6M0339S2bdu0fft21dbWauvWrfrlL3+prVu3dvn88vJyBYPByNHY2Oj2SgCAXsj1K6AlS5Zo2bJlmjt3riQpLy9PFy9eVGVlpYqLi294vt/vl9/vd3sNAEAv5/oV0LVr19SvX+e/Ni4uTh0dHW6PAgDEMNevgGbOnKmVK1cqJydHI0aM0Hvvvae1a9dq/vz5bo8CAMQw1wO0fv16VVRU6Mc//rFaWlqUlZWlH/zgB1q+fLnbowAAMcz1AKWkpKiqqkpVVVVu/9UAgD6Ee8EBAEwQIACACQIEADBBgAAAJggQAMAEAQIAmHD9Y9hArIof9O88m+X7p8uezInzeTLGU8Pua/Zs1v/2bNLdiSsgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAICJeOsFgFv5P3uGeTJn35gtnsyRpJz4ez2a5NUcaUnTaE/mfPj8SE/mSFKCTns2627EFRAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMBEtwN05MgRzZw5U1lZWfL5fNqzZ0+nxx3H0fLly5WZmamkpCQVFhbq/Pnzbu0LAOgjuh2g1tZWjRo1Shs3buzy8TVr1mjdunXatGmTTpw4oeTkZE2bNk3Xr1+/42UBAH1Ht+8FN336dE2fPr3LxxzHUVVVlZ5//nnNmjVLkvSb3/xGGRkZ2rNnj+bOnXtn2wIA+gxXfwbU0NCgpqYmFRYWRs4FAgGNHz9ex44d6/LPtLW1KRQKdToAAH2fqwFqamqSJGVkZHQ6n5GREXnsqyorKxUIBCJHdna2mysBAHop80/BlZeXKxgMRo7GxkbrlQAAHnA1QAMHDpQkNTc3dzrf3Nwceeyr/H6/UlNTOx0AgL7P1QDl5uZq4MCBqqmpiZwLhUI6ceKEJkyY4OYoAECM6/an4K5evaoLFy5Evm5oaFBdXZ3S0tKUk5Oj0tJSvfzyyxoyZIhyc3NVUVGhrKwszZ492829AQAxrtsBOn36tKZMmRL5uqysTJJUXFysN954Qz/96U/V2tqq5557Tp999pkmTZqk/fv3KzEx0b2tAQAxr9sBmjx5shzHuenjPp9PL730kl566aU7WgwA0LeZfwoOAHB3IkAAABMECABgggABAEwQIACACQIEADDR7Y9ho2ecgoc9mRN+8f96MkeSXv/b7Z7MyYmv82SOdK9Hc6TnW/I8mfPuKwWezJGklJ3HPZmToNOezEH0cQUEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADARb73A3eKfd2zwZE5O/L2ezJGkS194M+f5ljxP5vy3/zHJkzmSNPjnxzyZk6LjnswBeoIrIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgIluB+jIkSOaOXOmsrKy5PP5tGfPnshj7e3tWrp0qfLy8pScnKysrCw988wzunz5sps7AwD6gG4HqLW1VaNGjdLGjRtveOzatWuqra1VRUWFamtr9dZbb6m+vl6PP/64K8sCAPqObt8Lbvr06Zo+fXqXjwUCAR04cKDTuQ0bNmjcuHG6dOmScnJyerYlAKDPifrNSIPBoHw+n+67774uH29ra1NbW1vk61AoFO2VAAC9QFQ/hHD9+nUtXbpUTz31lFJTU7t8TmVlpQKBQOTIzs6O5koAgF4iagFqb2/XnDlz5DiOqqurb/q88vJyBYPByNHY2BitlQAAvUhUvgX3ZXwuXryod99996ZXP5Lk9/vl9/ujsQYAoBdzPUBfxuf8+fM6ePCg0tPT3R4BAOgDuh2gq1ev6sKFC5GvGxoaVFdXp7S0NGVmZuqJJ55QbW2t9u3bp3A4rKamJklSWlqaEhIS3NscABDTuh2g06dPa8qUKZGvy8rKJEnFxcX6xS9+ob1790qSHn744U5/7uDBg5o8eXLPNwUA9CndDtDkyZPlOM5NH/+6xwAA+BL3ggMAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwEfW7YeMvns2ZZL0CbmGwjlmvANxVuAICAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADARLz1Al/lOI4k6Qu1S47xMgCAbvtC7ZL++n5+M70uQFeuXJEkHdW/GG8CALgTV65cUSAQuOnjPudWifJYR0eHLl++rJSUFPl8vtv+c6FQSNnZ2WpsbFRqamoUN/RGX3s9Eq8pVvCaer/e/nocx9GVK1eUlZWlfv1u/pOeXncF1K9fPw0aNKjHfz41NbVX/gvpqb72eiReU6zgNfV+vfn1fN2Vz5f4EAIAwAQBAgCY6DMB8vv9euGFF+T3+61XcUVfez0SrylW8Jp6v77yenrdhxAAAHeHPnMFBACILQQIAGCCAAEATBAgAICJPhGgjRs3avDgwUpMTNT48eN18uRJ65V6rLKyUmPHjlVKSooGDBig2bNnq76+3not17zyyivy+XwqLS21XuWOffzxx3r66aeVnp6upKQk5eXl6fTp09Zr9Ug4HFZFRYVyc3OVlJSkBx98UCtWrLjlvbx6kyNHjmjmzJnKysqSz+fTnj17Oj3uOI6WL1+uzMxMJSUlqbCwUOfPn7dZ9jZ93Wtqb2/X0qVLlZeXp+TkZGVlZemZZ57R5cuX7RbuppgP0K5du1RWVqYXXnhBtbW1GjVqlKZNm6aWlhbr1Xrk8OHDKikp0fHjx3XgwAG1t7fr0UcfVWtrq/Vqd+zUqVN67bXX9NBDD1mvcsc+/fRTFRQU6J577tE777yjP/7xj/rVr36l/v37W6/WI6tXr1Z1dbU2bNigDz/8UKtXr9aaNWu0fv1669VuW2trq0aNGqWNGzd2+fiaNWu0bt06bdq0SSdOnFBycrKmTZum69eve7zp7fu613Tt2jXV1taqoqJCtbW1euutt1RfX6/HH3/cYNMecmLcuHHjnJKSksjX4XDYycrKciorKw23ck9LS4sjyTl8+LD1KnfkypUrzpAhQ5wDBw443/nOd5xFixZZr3RHli5d6kyaNMl6DdfMmDHDmT9/fqdz3/3ud52ioiKjje6MJGf37t2Rrzs6OpyBAwc6r776auTcZ5995vj9fmfHjh0GG3bfV19TV06ePOlIci5evOjNUncopq+APv/8c505c0aFhYWRc/369VNhYaGOHTtmuJl7gsGgJCktLc14kztTUlKiGTNmdPp3Fcv27t2r/Px8PfnkkxowYIBGjx6tLVu2WK/VYxMnTlRNTY3OnTsnSXr//fd19OhRTZ8+3XgzdzQ0NKipqanTf3+BQEDjx4/vM+8V0l/eL3w+n+677z7rVW5Lr7sZaXd88sknCofDysjI6HQ+IyNDf/rTn4y2ck9HR4dKS0tVUFCgkSNHWq/TYzt37lRtba1OnTplvYprPvroI1VXV6usrEw/+9nPdOrUKS1cuFAJCQkqLi62Xq/bli1bplAopKFDhyouLk7hcFgrV65UUVGR9WquaGpqkqQu3yu+fCzWXb9+XUuXLtVTTz3Va29Q+lUxHaC+rqSkRGfPntXRo0etV+mxxsZGLVq0SAcOHFBiYqL1Oq7p6OhQfn6+Vq1aJUkaPXq0zp49q02bNsVkgN58801t27ZN27dv14gRI1RXV6fS0lJlZWXF5Ou527S3t2vOnDlyHEfV1dXW69y2mP4W3P3336+4uDg1Nzd3Ot/c3KyBAwcabeWOBQsWaN++fTp48OAd/XoKa2fOnFFLS4vGjBmj+Ph4xcfH6/Dhw1q3bp3i4+MVDoetV+yRzMxMDR8+vNO5YcOG6dKlS0Yb3ZklS5Zo2bJlmjt3rvLy8vT9739fixcvVmVlpfVqrvjy/aAvvld8GZ+LFy/qwIEDMXP1I8V4gBISEvTII4+opqYmcq6jo0M1NTWaMGGC4WY95ziOFixYoN27d+vdd99Vbm6u9Up3ZOrUqfrggw9UV1cXOfLz81VUVKS6ujrFxcVZr9gjBQUFN3w8/ty5c3rggQeMNroz165du+EXh8XFxamjo8NoI3fl5uZq4MCBnd4rQqGQTpw4EbPvFdJf43P+/Hn9/ve/V3p6uvVK3RLz34IrKytTcXGx8vPzNW7cOFVVVam1tVXz5s2zXq1HSkpKtH37dr399ttKSUmJfH86EAgoKSnJeLvuS0lJueHnV8nJyUpPT4/pn2stXrxYEydO1KpVqzRnzhydPHlSmzdv1ubNm61X65GZM2dq5cqVysnJ0YgRI/Tee+9p7dq1mj9/vvVqt+3q1au6cOFC5OuGhgbV1dUpLS1NOTk5Ki0t1csvv6whQ4YoNzdXFRUVysrK0uzZs+2WvoWve02ZmZl64oknVFtbq3379ikcDkfeL9LS0pSQkGC19u2z/hieG9avX+/k5OQ4CQkJzrhx45zjx49br9Rjkro8Xn/9devVXNMXPobtOI7z29/+1hk5cqTj9/udoUOHOps3b7ZeqcdCoZCzaNEiJycnx0lMTHS+9a1vOT//+c+dtrY269Vu28GDB7v8f6e4uNhxnL98FLuiosLJyMhw/H6/M3XqVKe+vt526Vv4utfU0NBw0/eLgwcPWq9+W/h1DAAAEzH9MyAAQOwiQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEz8P3aEc7xvkMj7AAAAAElFTkSuQmCC"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "152 s  157 ns per loop (mean  std. dev. of 7 runs, 10,000 loops each)\n"
     ]
    }
   ],
   "execution_count": 27
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-27T18:11:32.127410Z",
     "start_time": "2025-04-27T18:11:31.909483Z"
    }
   },
   "cell_type": "code",
   "source": "import pytorch_numba_extension_jit as ptex",
   "id": "bcf2417a59a9e4be",
   "outputs": [],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-27T18:16:25.322163Z",
     "start_time": "2025-04-27T18:16:19.785906Z"
    }
   },
   "cell_type": "code",
   "source": [
    "@ptex.jit(\n",
    "    [\n",
    "        ptex.InputTensor(\"img\", \"f32\", (None, meta.img_cs, meta.img_ys, meta.img_xs)),\n",
    "        ptex.InputTensor(\"kernel\", \"f32\", test_kernels.shape),\n",
    "        ptex.OutputTensor(\n",
    "            \"out_img\", \"f32\", (\"img.shape[0]\", meta.out_cs, meta.out_ys, meta.out_xs)\n",
    "        ),\n",
    "        ptex.OutputTensor(\n",
    "            \"out_prov\",\n",
    "            \"f32\",\n",
    "            (\n",
    "                    \"img.shape[0]\",\n",
    "                    meta.out_cs,\n",
    "                    meta.out_ys,\n",
    "                    meta.out_xs,\n",
    "                    3 if meta.krn_cs > 1 else 2,\n",
    "            ),\n",
    "        ),\n",
    "    ],\n",
    "    n_threads=\"out_img\",\n",
    "    compile_extension=True,\n",
    "    verbose=False,\n",
    ")\n",
    "def test_dilation(img, kernel, out_img, out_prov):\n",
    "    rem, o_x = divmod(cuda.grid(1), meta.out_xs)\n",
    "    rem, o_y = divmod(rem, meta.out_ys)\n",
    "    b, o_c = divmod(rem, meta.out_cs)\n",
    "    if b >= img.shape[0]:\n",
    "        return\n",
    "\n",
    "    i_top_y = o_y * meta.stride - meta.padding\n",
    "    i_left_x = o_x * meta.stride - meta.padding\n",
    "\n",
    "    prov_x = prov_y = prov_group_idx = 255\n",
    "    selected_val = -INF\n",
    "\n",
    "    group_number = o_c // meta.krn_o_group_size\n",
    "    # If we're not broadcasting, then we have a separate kernel\n",
    "    # for every output channel. If we are broadcasting, we instead loop\n",
    "    # around the kernels every k_os (which == krn_group_size)\n",
    "    k_o = o_c if not meta.group_broadcasting else o_c % meta.krn_o_group_size\n",
    "\n",
    "    # For a pooling, we have only one input channel, so group_idx is always 0\n",
    "    for group_idx in range(meta.krn_cs):\n",
    "        for y_step, i_y in enumerate(\n",
    "                range(i_top_y, i_top_y + meta.krn_ys * meta.dilation, meta.dilation)\n",
    "        ):\n",
    "            for x_step, i_x in enumerate(\n",
    "                    range(\n",
    "                        i_left_x,\n",
    "                        i_left_x + meta.krn_xs * meta.dilation,\n",
    "                        meta.dilation,\n",
    "                    )\n",
    "            ):\n",
    "                if i_x < 0 or i_x >= meta.img_xs or i_y < 0 or i_y >= meta.img_ys:\n",
    "                    continue\n",
    "\n",
    "                # Need to explicitly use seperate variable, due to compiler error\n",
    "                k_x = meta.krn_xs - 1 - x_step if meta.mirror_kernel else x_step\n",
    "                k_y = meta.krn_ys - 1 - y_step if meta.mirror_kernel else y_step\n",
    "\n",
    "                i_c = group_number * meta.krn_cs + group_idx\n",
    "                img_val = img[b, i_c, i_y, i_x]\n",
    "                kernel_val = kernel[k_o, group_idx, k_y, k_x]\n",
    "\n",
    "                val = img_val + kernel_val\n",
    "                if selected_val < val:\n",
    "                    selected_val = val\n",
    "                    prov_y, prov_x = k_y, k_x\n",
    "                    if meta.krn_cs > 1:\n",
    "                        prov_group_idx = group_idx\n",
    "\n",
    "    out_img[b, o_c, o_y, o_x] = selected_val\n",
    "\n",
    "    out_prov[b, o_c, o_y, o_x, 0] = prov_y\n",
    "    out_prov[b, o_c, o_y, o_x, 1] = prov_x\n",
    "    if meta.krn_cs > 1:\n",
    "        # out_prov is only size 3 if we require an index within the group\n",
    "        out_prov[b, o_c, o_y, o_x, 2] = prov_group_idx\n",
    "\n",
    "\n",
    "oi, op = test_dilation(test_imgs, test_kernels)\n",
    "print(f\"{oi.shape=} {op.shape=}\")\n",
    "\n",
    "torch.library.opcheck(test_dilation, (test_imgs, test_kernels))"
   ],
   "id": "2b2e003b3c6963c3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "oi.shape=torch.Size([2048, 6, 14, 14]) op.shape=torch.Size([2048, 6, 14, 14, 2])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'test_schema': 'SUCCESS',\n",
       " 'test_autograd_registration': 'SUCCESS',\n",
       " 'test_faketensor': 'SUCCESS',\n",
       " 'test_aot_dispatch_dynamic': 'SUCCESS'}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 28
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-27T18:16:33.779443Z",
     "start_time": "2025-04-27T18:16:30.167087Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def run_one():\n",
    "    test_dilation(test_imgs[:1024], test_kernels)\n",
    "    torch.cuda.synchronize()\n",
    "\n",
    "\n",
    "oi, op = test_dilation(test_imgs, test_kernels)\n",
    "plt.imshow(oi[0, -1].numpy(force=True))\n",
    "plt.show()\n",
    "%timeit run_one()"
   ],
   "id": "b2d5336212d65ef4",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44 s  23.6 ns per loop (mean  std. dev. of 7 runs, 10,000 loops each)\n"
     ]
    }
   ],
   "execution_count": 29
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-27T18:21:39.263390Z",
     "start_time": "2025-04-27T18:21:25.130648Z"
    }
   },
   "cell_type": "code",
   "source": [
    "with torch.no_grad():\n",
    "    def run_one():\n",
    "        torch.nn.functional.max_pool2d(test_imgs[:1024], 3, stride=2, padding=1)\n",
    "        torch.cuda.synchronize()\n",
    "\n",
    "\n",
    "    oi = torch.nn.functional.max_pool2d(test_imgs, 3, stride=2, padding=1)\n",
    "    print(oi.shape)\n",
    "    plt.imshow(oi[0, -1].numpy(force=True))\n",
    "    run_one()\n",
    "    %timeit run_one()"
   ],
   "id": "d3c1a0935e3cfb77",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2048, 6, 14, 14])\n",
      "17.4 s  20.4 ns per loop (mean  std. dev. of 7 runs, 100,000 loops each)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 33
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-27T18:21:00.918820Z",
     "start_time": "2025-04-27T18:20:55.418102Z"
    }
   },
   "cell_type": "code",
   "source": [
    "@ptex.jit(\n",
    "    [\n",
    "        ptex.InputTensor(\"img\", \"f32\", (None, meta.img_cs, meta.img_ys, meta.img_xs)),\n",
    "        ptex.OutputTensor(\n",
    "            \"out_img\", \"f32\", (\"img.shape[0]\", meta.out_cs, meta.out_ys, meta.out_xs)\n",
    "        ),\n",
    "        ptex.OutputTensor(\n",
    "            \"out_prov\",\n",
    "            \"f32\",\n",
    "            (\n",
    "                    \"img.shape[0]\",\n",
    "                    meta.out_cs,\n",
    "                    meta.out_ys,\n",
    "                    meta.out_xs,\n",
    "                    3 if meta.krn_cs > 1 else 2,\n",
    "            ),\n",
    "        ),\n",
    "    ],\n",
    "    n_threads=\"out_img\",\n",
    "    compile_extension=True,\n",
    "    verbose=False,\n",
    ")\n",
    "def test_maxpool(img, out_img, out_prov):\n",
    "    rem, o_x = divmod(cuda.grid(1), meta.out_xs)\n",
    "    rem, o_y = divmod(rem, meta.out_ys)\n",
    "    b, o_c = divmod(rem, meta.out_cs)\n",
    "    if b >= img.shape[0]:\n",
    "        return\n",
    "\n",
    "    i_top_y = o_y * meta.stride - meta.padding\n",
    "    i_left_x = o_x * meta.stride - meta.padding\n",
    "\n",
    "    prov_x = prov_y = prov_group_idx = 255\n",
    "    selected_val = -INF\n",
    "\n",
    "    group_number = o_c // meta.krn_o_group_size\n",
    "\n",
    "    # For a pooling, we have only one input channel, so group_idx is always 0\n",
    "    for group_idx in range(meta.krn_cs):\n",
    "        for y_step, i_y in enumerate(\n",
    "                range(i_top_y, i_top_y + meta.krn_ys * meta.dilation, meta.dilation)\n",
    "        ):\n",
    "            for x_step, i_x in enumerate(\n",
    "                    range(\n",
    "                        i_left_x,\n",
    "                        i_left_x + meta.krn_xs * meta.dilation,\n",
    "                        meta.dilation,\n",
    "                    )\n",
    "            ):\n",
    "                if i_x < 0 or i_x >= meta.img_xs or i_y < 0 or i_y >= meta.img_ys:\n",
    "                    continue\n",
    "\n",
    "                # Need to explicitly use seperate variable, due to compiler error\n",
    "                k_x = x_step\n",
    "                k_y = y_step\n",
    "\n",
    "                i_c = group_number * meta.krn_cs + group_idx\n",
    "                img_val = img[b, i_c, i_y, i_x]\n",
    "\n",
    "                val = img_val\n",
    "                if selected_val < val:\n",
    "                    selected_val = val\n",
    "                    prov_y, prov_x = k_y, k_x\n",
    "                    if meta.krn_cs > 1:\n",
    "                        prov_group_idx = group_idx\n",
    "\n",
    "    out_img[b, o_c, o_y, o_x] = selected_val\n",
    "\n",
    "    out_prov[b, o_c, o_y, o_x, 0] = prov_y\n",
    "    out_prov[b, o_c, o_y, o_x, 1] = prov_x\n",
    "    if meta.krn_cs > 1:\n",
    "        # out_prov is only size 3 if we require an index within the group\n",
    "        out_prov[b, o_c, o_y, o_x, 2] = prov_group_idx\n",
    "\n",
    "\n",
    "oi, op = test_maxpool(test_imgs)\n",
    "print(f\"{oi.shape=} {op.shape=}\")\n",
    "\n",
    "torch.library.opcheck(test_maxpool, (test_imgs,))"
   ],
   "id": "3c59ac38c96ed577",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "oi.shape=torch.Size([2048, 6, 14, 14]) op.shape=torch.Size([2048, 6, 14, 14, 2])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'test_schema': 'SUCCESS',\n",
       " 'test_autograd_registration': 'SUCCESS',\n",
       " 'test_faketensor': 'SUCCESS',\n",
       " 'test_aot_dispatch_dynamic': 'SUCCESS'}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 32
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-27T18:22:23.026810Z",
     "start_time": "2025-04-27T18:22:19.632872Z"
    }
   },
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2048, 6, 14, 14])\n",
      "41.2 s  33.6 ns per loop (mean  std. dev. of 7 runs, 10,000 loops each)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 35,
   "source": [
    "with torch.no_grad():\n",
    "    def run_one():\n",
    "        test_maxpool(test_imgs[:1024])\n",
    "        torch.cuda.synchronize()\n",
    "\n",
    "\n",
    "    oi, _prov = test_maxpool(test_imgs)\n",
    "    print(oi.shape)\n",
    "    plt.imshow(oi[0, -1].numpy(force=True))\n",
    "    run_one()\n",
    "    %timeit run_one()"
   ],
   "id": "546f1729dd30ac09"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-27T13:25:35.927067Z",
     "start_time": "2025-04-27T13:25:35.922150Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import re\n",
    "\n",
    "_cpp_replace_shape = re.compile(r\"\\w+\\.shape\\[([^\\]]+)]\")"
   ],
   "id": "1b8dea2c027d9927",
   "outputs": [],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-27T13:26:59.596017Z",
     "start_time": "2025-04-27T13:26:59.588355Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def _replace_shape_size(match: re.Match[str]):\n",
    "    name, right = match.group().split(\".shape[\")\n",
    "\n",
    "    return f\"{name}.size({right[:-1]})\"\n",
    "\n",
    "\n",
    "_cpp_replace_shape.sub(_replace_shape_size, \"a.shape[2] + b.shape[10 - 2]\")"
   ],
   "id": "1b085b92bc1c2e8e",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'a.size(2) + b.size(10 - 2)'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 30
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-27T15:29:00.216206Z",
     "start_time": "2025-04-27T15:29:00.208749Z"
    }
   },
   "cell_type": "code",
   "source": "cuda.jit(lambda x, y: x + y, device=True).py_func(1, 2)",
   "id": "5efedd650e73d27",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 52
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-27T13:47:54.068658Z",
     "start_time": "2025-04-27T13:47:54.061604Z"
    }
   },
   "cell_type": "code",
   "source": [
    "ptx = next(iter(fwd_outlined.inspect_asm().values()))\n",
    "type(ptx)"
   ],
   "id": "e09314faa13cd3c3",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 40
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-27T13:44:30.259090Z",
     "start_time": "2025-04-27T13:44:30.252407Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from numba import cuda\n",
    "\n",
    "cuda.jit"
   ],
   "id": "ae5276a80bd10bdb",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function numba.cuda.decorators.jit.<locals>._jit(func)>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 39
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
