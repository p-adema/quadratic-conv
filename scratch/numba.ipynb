{
 "cells": [
  {
   "cell_type": "code",
   "id": "358f30b60cc42081",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-24T16:16:04.141576Z",
     "start_time": "2025-04-24T16:16:03.493524Z"
    }
   },
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import tqdm.auto as tqdm\n",
    "import math\n",
    "from numba import cuda"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "id": "efb24287c0ecd5bc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-24T16:16:04.164260Z",
     "start_time": "2025-04-24T16:16:04.162510Z"
    }
   },
   "source": [
    "# Move to project root\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "if not Path(\"./checkpoints\").is_dir():\n",
    "    for parent_path in Path.cwd().parents:\n",
    "        if (parent_path / \"checkpoints\").is_dir():\n",
    "            os.chdir(parent_path)\n",
    "            break\n",
    "    else:\n",
    "        raise FileNotFoundError(\"Can't find project root\")\n",
    "\n",
    "assert Path(\"./checkpoints\").is_dir()"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "id": "4dfcbb23e91bcd73",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-24T16:16:06.623354Z",
     "start_time": "2025-04-24T16:16:06.175465Z"
    }
   },
   "source": "from src import convolutions, load_data, kernels",
   "outputs": [],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "id": "f22c443ce5a9ab93",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-24T19:00:35.148305Z",
     "start_time": "2025-04-24T19:00:35.098491Z"
    }
   },
   "source": [
    "@cuda.jit(\"void(float32[:])\")\n",
    "def add_one(arr):\n",
    "    x = cuda.grid(1)\n",
    "    if x < arr.size:\n",
    "        arr[x] += 1"
   ],
   "outputs": [],
   "execution_count": 27
  },
  {
   "cell_type": "code",
   "id": "88c6da9a2bdcc6d1",
   "metadata": {},
   "source": [
    "a = torch.tensor([5, 4, 3, 2], dtype=torch.float32, device=\"cuda\")\n",
    "a"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "f585705f0d6f59f7",
   "metadata": {},
   "source": [
    "add_one[1, 16](a)\n",
    "a"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def run_once():\n",
    "    a.add_(1)\n",
    "    torch.cuda.synchronize()\n",
    "\n",
    "%timeit run_once()"
   ],
   "id": "4af198d7e5f4b9cc",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def run_once():\n",
    "    add_one[1, 16](a)\n",
    "    torch.cuda.synchronize()\n",
    "\n",
    "%timeit run_once()"
   ],
   "id": "8a6ffc0194b8680f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-24T18:18:28.331095Z",
     "start_time": "2025-04-24T18:18:28.321174Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "lib_path = Path(sys.exec_prefix) / \"lib\"\n",
    "site_packages = next(lib_path.glob(\"python3.*\")) / \"site-packages\"\n",
    "cudart_base = site_packages / \"torch\" / \"lib\" / \"libcudart.so\"\n",
    "cudart_user = Path(\"/usr/local/cuda/lib64/libcudart.so\")\n",
    "cudart_nv_base = site_packages / \"nvidia\" / \"cuda_runtime\" / \"lib\" / \"libcudart.so\"\n",
    "cudart_nv_versioned = next((site_packages / \"nvidia\" / \"cuda_runtime\" / \"lib\").glob(\"libcudart.so.*\"), None)\n",
    "if not cudart_base.exists():\n",
    "    if cudart_user.exists():\n",
    "        print(\"User\")\n",
    "        cudart_base.symlink_to(cudart_user)\n",
    "    elif cudart_nv_base.exists():\n",
    "        print(\"NV base\")\n",
    "        cudart_base.symlink_to(cudart_nv_base)\n",
    "    elif cudart_nv_versioned is not None:\n",
    "        print(\"NV Versioned\")\n",
    "        cudart_base.symlink_to(cudart_nv_versioned)\n",
    "    # cudart_base.symlink_to()\n",
    "\n",
    "print(cudart_base.exists(), \" : \", cudart_base)"
   ],
   "id": "4a40b346c72463ba",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User\n",
      "True  :  /home/peter/Thesis/.venv/lib/python3.12/site-packages/torch/lib/libcudart.so\n"
     ]
    }
   ],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-24T18:17:33.669705Z",
     "start_time": "2025-04-24T18:17:33.486750Z"
    }
   },
   "cell_type": "code",
   "outputs": [],
   "execution_count": 20,
   "source": "# !rm /home/peter/Thesis/.venv/lib/python3.12/site-packages/torch/lib/libcudart.so",
   "id": "870aab3bed0e90c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-24T15:21:35.249678Z",
     "start_time": "2025-04-24T15:21:35.240556Z"
    }
   },
   "cell_type": "code",
   "source": [
    "temp_root = Path(\"/home/peter/Thesis/scratch/test-extension\")\n",
    "built_module = next((temp_root / \"build\").glob(\"lib.*\")) / \"test_extension\"\n",
    "assert built_module.exists()\n",
    "built_module"
   ],
   "id": "fb3c9af327df2b4a",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/home/peter/Thesis/scratch/test-extension/build/lib.linux-x86_64-cpython-312/test_extension')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-24T18:08:01.706032Z",
     "start_time": "2025-04-24T18:08:01.697313Z"
    }
   },
   "cell_type": "code",
   "source": "list((site_packages / \"torch\" / \"lib\").glob(\"*\"))",
   "id": "31de6150c862160b",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PosixPath('/home/peter/Thesis/.venv/lib/python3.12/site-packages/torch/lib/libcudart.so'),\n",
       " PosixPath('/home/peter/Thesis/.venv/lib/python3.12/site-packages/torch/lib/libcaffe2_nvrtc.so'),\n",
       " PosixPath('/home/peter/Thesis/.venv/lib/python3.12/site-packages/torch/lib/libc10_cuda.so'),\n",
       " PosixPath('/home/peter/Thesis/.venv/lib/python3.12/site-packages/torch/lib/libtorch_cuda.so'),\n",
       " PosixPath('/home/peter/Thesis/.venv/lib/python3.12/site-packages/torch/lib/libtorch_global_deps.so'),\n",
       " PosixPath('/home/peter/Thesis/.venv/lib/python3.12/site-packages/torch/lib/libshm.so'),\n",
       " PosixPath('/home/peter/Thesis/.venv/lib/python3.12/site-packages/torch/lib/libshm_windows'),\n",
       " PosixPath('/home/peter/Thesis/.venv/lib/python3.12/site-packages/torch/lib/libgomp-870cb1d0.so.1'),\n",
       " PosixPath('/home/peter/Thesis/.venv/lib/python3.12/site-packages/torch/lib/libtorch.so'),\n",
       " PosixPath('/home/peter/Thesis/.venv/lib/python3.12/site-packages/torch/lib/libtorch_python.so'),\n",
       " PosixPath('/home/peter/Thesis/.venv/lib/python3.12/site-packages/torch/lib/libtorch_cpu.so'),\n",
       " PosixPath('/home/peter/Thesis/.venv/lib/python3.12/site-packages/torch/lib/libc10.so'),\n",
       " PosixPath('/home/peter/Thesis/.venv/lib/python3.12/site-packages/torch/lib/libshm'),\n",
       " PosixPath('/home/peter/Thesis/.venv/lib/python3.12/site-packages/torch/lib/libtorch_cuda_linalg.so')]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-24T15:25:10.968176Z",
     "start_time": "2025-04-24T15:21:37.118761Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import importlib.util\n",
    "import importlib.machinery\n",
    "import sys\n",
    "\n",
    "\n",
    "def import_from_path(module_name, file_path):\n",
    "    spec = importlib.util.spec_from_file_location(\"test_extension\", file_path / \"__init__.py\")\n",
    "    module = importlib.util.module_from_spec(spec)\n",
    "    sys.modules[module_name] = module\n",
    "    spec.loader.exec_module(module)\n",
    "    return module\n",
    "\n",
    "\n",
    "# test_ext = import_from_path(\"test_extension\", built_module)\n",
    "test_ext = import_from_path(\"test_extension\", built_module)"
   ],
   "id": "c96fc6915de52fcf",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "57e4f046852998e7"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "a = torch.ones(5, device='cuda')\n",
    "b = torch.arange(5, dtype=torch.float32, device='cuda')\n",
    "c = 5.0\n",
    "test_ext.ops.mymuladd(a, b, c)"
   ],
   "id": "5684aa58b6bcc698",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def run_one():\n",
    "    test_ext.ops.mymuladd(a, b, c)\n",
    "    torch.cuda.synchronize()\n",
    "\n",
    "%timeit run_one()"
   ],
   "id": "94538c3e5b515176",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-24T19:55:53.316430Z",
     "start_time": "2025-04-24T19:55:53.310268Z"
    }
   },
   "cell_type": "code",
   "source": [
    "a = torch.ones(5, device='cuda')\n",
    "test_add[1, 32](a)"
   ],
   "id": "7bffa95d52923f52",
   "outputs": [],
   "execution_count": 38
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-25T06:33:54.540901Z",
     "start_time": "2025-04-25T06:33:54.529003Z"
    }
   },
   "cell_type": "code",
   "source": "a",
   "id": "c269563e2ebcc7eb",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([30., 30., 30., 30.,  2.], device='cuda:0')"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 40
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-25T07:53:37.886528Z",
     "start_time": "2025-04-25T07:53:37.825165Z"
    }
   },
   "cell_type": "code",
   "source": [
    "@cuda.jit(\"void(float32[:])\")\n",
    "def test_add(arr):\n",
    "    x = cuda.grid(1)\n",
    "    if 0 < x < arr.size:\n",
    "        arr[x] = 2\n",
    "        arr[x - 1] = 30\n",
    "\n",
    "\n",
    "def simple_add(x, y):\n",
    "    return x + y\n",
    "\n",
    "\n",
    "res = []\n",
    "compilation = cuda.compile_for_current_device(\n",
    "    test_add, \"void(float32[:])\",\n",
    "    # simple_add, \"int64(int64, int64)\",\n",
    "    device=False, abi=\"numba\", lineinfo=False,\n",
    "    output='ptx', opt=True, abi_info={\"abi_name\": \"conv\"})[0]\n",
    "\n",
    "max_line = max(map(len, compilation.splitlines()))\n",
    "for line in compilation.splitlines():\n",
    "    if line.strip():\n",
    "        res.append(f'\"{line}\\n\\t\"')\n",
    "        # print(f'\"{line.ljust(max_line)}\\\\n\\\\t\"')\n",
    "# res_join = '\\n\\t'.join(res)\n",
    "print(compilation)"
   ],
   "id": "554a3f8809e67a08",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "//\n",
      "// Generated by NVIDIA NVVM Compiler\n",
      "//\n",
      "// Compiler Build ID: CL-35404655\n",
      "// Cuda compilation tools, release 12.8, V12.8.61\n",
      "// Based on NVVM 7.0.1\n",
      "//\n",
      "\n",
      ".version 8.7\n",
      ".target sm_90\n",
      ".address_size 64\n",
      "\n",
      "\t// .globl\t_ZN6cudapy8__main__8test_addB3v29B94cw51cXTLSUwv1sCUt9UwNNJRMNDUUUDyoy04_2bIChiBahtqDEBRGGpB0kAdT0AJNAcp9ttTos1NStFKChrw6UBPKMazUBE5ArrayIfLi1E1A7mutable7alignedE\n",
      ".visible .global .align 4 .u32 _ZN6cudapy8__main__8test_addB3v29B94cw51cXTLSUwv1sCUt9UwNNJRMNDUUUDyoy04_2bIChiBahtqDEBRGGpB0kAdT0AJNAcp9ttTos1NStFKChrw6UBPKMazUBE5ArrayIfLi1E1A7mutable7alignedE__errcode__;\n",
      ".visible .global .align 4 .u32 _ZN6cudapy8__main__8test_addB3v29B94cw51cXTLSUwv1sCUt9UwNNJRMNDUUUDyoy04_2bIChiBahtqDEBRGGpB0kAdT0AJNAcp9ttTos1NStFKChrw6UBPKMazUBE5ArrayIfLi1E1A7mutable7alignedE__tidx__;\n",
      ".visible .global .align 4 .u32 _ZN6cudapy8__main__8test_addB3v29B94cw51cXTLSUwv1sCUt9UwNNJRMNDUUUDyoy04_2bIChiBahtqDEBRGGpB0kAdT0AJNAcp9ttTos1NStFKChrw6UBPKMazUBE5ArrayIfLi1E1A7mutable7alignedE__ctaidx__;\n",
      ".visible .global .align 4 .u32 _ZN6cudapy8__main__8test_addB3v29B94cw51cXTLSUwv1sCUt9UwNNJRMNDUUUDyoy04_2bIChiBahtqDEBRGGpB0kAdT0AJNAcp9ttTos1NStFKChrw6UBPKMazUBE5ArrayIfLi1E1A7mutable7alignedE__tidy__;\n",
      ".visible .global .align 4 .u32 _ZN6cudapy8__main__8test_addB3v29B94cw51cXTLSUwv1sCUt9UwNNJRMNDUUUDyoy04_2bIChiBahtqDEBRGGpB0kAdT0AJNAcp9ttTos1NStFKChrw6UBPKMazUBE5ArrayIfLi1E1A7mutable7alignedE__ctaidy__;\n",
      ".visible .global .align 4 .u32 _ZN6cudapy8__main__8test_addB3v29B94cw51cXTLSUwv1sCUt9UwNNJRMNDUUUDyoy04_2bIChiBahtqDEBRGGpB0kAdT0AJNAcp9ttTos1NStFKChrw6UBPKMazUBE5ArrayIfLi1E1A7mutable7alignedE__tidz__;\n",
      ".visible .global .align 4 .u32 _ZN6cudapy8__main__8test_addB3v29B94cw51cXTLSUwv1sCUt9UwNNJRMNDUUUDyoy04_2bIChiBahtqDEBRGGpB0kAdT0AJNAcp9ttTos1NStFKChrw6UBPKMazUBE5ArrayIfLi1E1A7mutable7alignedE__ctaidz__;\n",
      ".common .global .align 8 .u64 _ZN08NumbaEnv8__main__8test_addB3v29B94cw51cXTLSUwv1sCUt9UwNNJRMNDUUUDyoy04_2bIChiBahtqDEBRGGpB0kAdT0AJNAcp9ttTos1NStFKChrw6UBPKMazUBE5ArrayIfLi1E1A7mutable7alignedE;\n",
      "\n",
      ".visible .entry _ZN6cudapy8__main__8test_addB3v29B94cw51cXTLSUwv1sCUt9UwNNJRMNDUUUDyoy04_2bIChiBahtqDEBRGGpB0kAdT0AJNAcp9ttTos1NStFKChrw6UBPKMazUBE5ArrayIfLi1E1A7mutable7alignedE(\n",
      "\t.param .u64 _ZN6cudapy8__main__8test_addB3v29B94cw51cXTLSUwv1sCUt9UwNNJRMNDUUUDyoy04_2bIChiBahtqDEBRGGpB0kAdT0AJNAcp9ttTos1NStFKChrw6UBPKMazUBE5ArrayIfLi1E1A7mutable7alignedE_param_0,\n",
      "\t.param .u64 _ZN6cudapy8__main__8test_addB3v29B94cw51cXTLSUwv1sCUt9UwNNJRMNDUUUDyoy04_2bIChiBahtqDEBRGGpB0kAdT0AJNAcp9ttTos1NStFKChrw6UBPKMazUBE5ArrayIfLi1E1A7mutable7alignedE_param_1,\n",
      "\t.param .u64 _ZN6cudapy8__main__8test_addB3v29B94cw51cXTLSUwv1sCUt9UwNNJRMNDUUUDyoy04_2bIChiBahtqDEBRGGpB0kAdT0AJNAcp9ttTos1NStFKChrw6UBPKMazUBE5ArrayIfLi1E1A7mutable7alignedE_param_2,\n",
      "\t.param .u64 _ZN6cudapy8__main__8test_addB3v29B94cw51cXTLSUwv1sCUt9UwNNJRMNDUUUDyoy04_2bIChiBahtqDEBRGGpB0kAdT0AJNAcp9ttTos1NStFKChrw6UBPKMazUBE5ArrayIfLi1E1A7mutable7alignedE_param_3,\n",
      "\t.param .u64 _ZN6cudapy8__main__8test_addB3v29B94cw51cXTLSUwv1sCUt9UwNNJRMNDUUUDyoy04_2bIChiBahtqDEBRGGpB0kAdT0AJNAcp9ttTos1NStFKChrw6UBPKMazUBE5ArrayIfLi1E1A7mutable7alignedE_param_4,\n",
      "\t.param .u64 _ZN6cudapy8__main__8test_addB3v29B94cw51cXTLSUwv1sCUt9UwNNJRMNDUUUDyoy04_2bIChiBahtqDEBRGGpB0kAdT0AJNAcp9ttTos1NStFKChrw6UBPKMazUBE5ArrayIfLi1E1A7mutable7alignedE_param_5,\n",
      "\t.param .u64 _ZN6cudapy8__main__8test_addB3v29B94cw51cXTLSUwv1sCUt9UwNNJRMNDUUUDyoy04_2bIChiBahtqDEBRGGpB0kAdT0AJNAcp9ttTos1NStFKChrw6UBPKMazUBE5ArrayIfLi1E1A7mutable7alignedE_param_6\n",
      ")\n",
      "{\n",
      "\t.reg .pred \t%p<4>;\n",
      "\t.reg .b32 \t%r<6>;\n",
      "\t.reg .b64 \t%rd<11>;\n",
      "\n",
      "\n",
      "\tld.param.u64 \t%rd4, [_ZN6cudapy8__main__8test_addB3v29B94cw51cXTLSUwv1sCUt9UwNNJRMNDUUUDyoy04_2bIChiBahtqDEBRGGpB0kAdT0AJNAcp9ttTos1NStFKChrw6UBPKMazUBE5ArrayIfLi1E1A7mutable7alignedE_param_2];\n",
      "\tld.param.u64 \t%rd2, [_ZN6cudapy8__main__8test_addB3v29B94cw51cXTLSUwv1sCUt9UwNNJRMNDUUUDyoy04_2bIChiBahtqDEBRGGpB0kAdT0AJNAcp9ttTos1NStFKChrw6UBPKMazUBE5ArrayIfLi1E1A7mutable7alignedE_param_4];\n",
      "\tld.param.u64 \t%rd3, [_ZN6cudapy8__main__8test_addB3v29B94cw51cXTLSUwv1sCUt9UwNNJRMNDUUUDyoy04_2bIChiBahtqDEBRGGpB0kAdT0AJNAcp9ttTos1NStFKChrw6UBPKMazUBE5ArrayIfLi1E1A7mutable7alignedE_param_6];\n",
      "\tmov.u32 \t%r1, %tid.x;\n",
      "\tcvt.s64.s32 \t%rd5, %r1;\n",
      "\tmov.u32 \t%r2, %ntid.x;\n",
      "\tmov.u32 \t%r3, %ctaid.x;\n",
      "\tmul.wide.s32 \t%rd6, %r2, %r3;\n",
      "\tadd.s64 \t%rd1, %rd6, %rd5;\n",
      "\tsetp.lt.s64 \t%p1, %rd1, 1;\n",
      "\tsetp.ge.s64 \t%p2, %rd1, %rd4;\n",
      "\tor.pred  \t%p3, %p1, %p2;\n",
      "\t@%p3 bra \t$L__BB0_2;\n",
      "\n",
      "\tmul.lo.s64 \t%rd7, %rd1, %rd3;\n",
      "\tadd.s64 \t%rd8, %rd7, %rd2;\n",
      "\tmov.u32 \t%r4, 1073741824;\n",
      "\tst.u32 \t[%rd8], %r4;\n",
      "\tsub.s64 \t%rd9, %rd7, %rd3;\n",
      "\tadd.s64 \t%rd10, %rd9, %rd2;\n",
      "\tmov.u32 \t%r5, 1106247680;\n",
      "\tst.u32 \t[%rd10], %r5;\n",
      "\n",
      "$L__BB0_2:\n",
      "\tret;\n",
      "\n",
      "}\n"
     ]
    }
   ],
   "execution_count": 42
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "add_one.inspect_asm()",
   "id": "edccdd23c1abe97b",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "ba4173983b788dda",
   "metadata": {},
   "source": [
    "test_con = 1\n",
    "\n",
    "\n",
    "@cuda.jit(\"void(float32[:, :, :, :], float32[:, :, :, :], int64, int64, int64, int64)\")\n",
    "def mark_channels(arr, out, bs, cs, ys, xs):\n",
    "    z, y, x = cuda.grid(3)\n",
    "    b, c = divmod(z, cs)\n",
    "    if x < xs and y < ys and b < bs:\n",
    "        out[b, c, y, x] = arr[b, c, y, x] * c + x + y + test_con"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "3e580e111d09973f",
   "metadata": {},
   "source": [
    "a = torch.randn((256, 100, 5, 5), device=\"cuda\")\n",
    "o = torch.zeros_like(a)\n",
    "o.shape"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "f939c315c1007486",
   "metadata": {},
   "source": [
    "tpb = (2, 8, 8)\n",
    "tot_tpb = np.prod(tpb)\n",
    "print(\"Total TPB:\", tot_tpb)\n",
    "assert tot_tpb < 512, tot_tpb\n",
    "nbs = (\n",
    "    math.ceil(a.shape[0] * a.shape[1] / tpb[0]),\n",
    "    math.ceil(a.shape[-2] / tpb[-2]),\n",
    "    math.ceil(a.shape[-1] / tpb[-1]),\n",
    ")\n",
    "n_threads = np.prod(tpb) * np.prod(nbs)\n",
    "print(\"NBS:\", nbs)\n",
    "print(\"N_threads\", n_threads)\n",
    "print(\"Size:\", a.nelement())\n",
    "print(f\"Thread util: {a.nelement() / n_threads:.1%}\")\n",
    "assert a.nelement() <= n_threads"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "baf43246959cf05d",
   "metadata": {},
   "source": [
    "def run_one():\n",
    "    cuda.synchronize()\n",
    "    mark_channels[nbs, tpb](a, o, *a.shape)\n",
    "    cuda.synchronize()\n",
    "\n",
    "\n",
    "run_one()\n",
    "# %timeit run_one()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "b89b2cfe6042c80c",
   "metadata": {},
   "source": [
    "test_con2 = 1\n",
    "\n",
    "\n",
    "@cuda.jit(\"void(float32[:, :, :, :], float32[:, :, :, :], int64, int64, int64, int64)\")\n",
    "def mark_channels_flat(arr, out, _bs, cs, ys, xs):\n",
    "    idx = cuda.grid(1)\n",
    "    if idx >= arr.size:\n",
    "        return\n",
    "    idx_y, x = divmod(idx, xs)\n",
    "    idx_z, y = divmod(idx_y, ys)\n",
    "    b, c = divmod(idx_z, cs)\n",
    "    # if x < xs and y < ys and b < bs:\n",
    "    out[b, c, y, x] = arr[b, c, y, x] * c + x + y + test_con2"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "4abc286efa6abc7f",
   "metadata": {},
   "source": [
    "o[:] = 0\n",
    "mark_channels_flat[math.ceil(a.nelement() / 32), 32](a, o, *a.shape)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "f8e888a29df92286",
   "metadata": {},
   "source": [
    "o[:] = 0\n",
    "mark_channels[nbs, tpb](a, o, *a.shape)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "2aa84e4f94aec842",
   "metadata": {},
   "source": [
    "def run_one():\n",
    "    cuda.synchronize()\n",
    "    mark_channels_flat[math.ceil(a.nelement() / 256), 256](a, o, *a.shape)\n",
    "    cuda.synchronize()\n",
    "\n",
    "\n",
    "run_one()\n",
    "# %timeit run_one()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "840c980c9fd946f3",
   "metadata": {},
   "source": [
    "print(o[10, 2])"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "9422f53c2b51d42f",
   "metadata": {},
   "source": [
    "reduce_max = True\n",
    "INF = float(\"inf\")\n",
    "\n",
    "\n",
    "@cuda.jit(\n",
    "    \"void(float32[:, :, :, :],\"  # img: [Batch, Channel, Img_Y, Img_X]\n",
    "    \" float32[:, :, :],\"  # kernel: [Channel, Kernel_Y, Kernel_X\n",
    "    \" float32[:, :, :, :],\"  # out_img: [Batch, Channel, Img_Y, Img_X]\n",
    "    \" int16[:, :, :, :, :],\"  # out_prov: [Batch, Channel, Img_Y, Img_X, 2 (y, then x)]\n",
    "    \" int64,\"  # Channels\n",
    "    \" int64, int64,\"  # Img_Y, Img_X\n",
    "    \" int64, int64)\",  # Kernel_Y, Kernel_X\n",
    "    debug=True,\n",
    "    opt=False,\n",
    ")\n",
    "def dilate_flat(img, kernel, out_img, out_prov, cs, i_ys, i_xs, k_ys, k_xs):\n",
    "    idx = cuda.grid(1)\n",
    "    if idx >= img.size:\n",
    "        return\n",
    "    idx_y, centre_x = divmod(idx, i_xs)\n",
    "    idx_z, centre_y = divmod(idx_y, i_ys)\n",
    "    b, c = divmod(idx_z, cs)\n",
    "\n",
    "    top_y, left_x = centre_y - k_ys // 2, centre_x - k_xs // 2\n",
    "    best_x = best_y = -99\n",
    "    best_val = -INF if reduce_max else INF\n",
    "\n",
    "    for k_y, i_y in enumerate(range(top_y, top_y + k_ys)):\n",
    "        for k_x, i_x in enumerate(range(left_x, left_x + k_xs)):\n",
    "            if i_x < 0 or i_x > i_xs or i_y < 0 or i_y > i_ys:\n",
    "                continue\n",
    "\n",
    "            if reduce_max:\n",
    "                val = img[b, c, i_y, i_x] + kernel[c, k_y, k_x]\n",
    "                if val > best_val:\n",
    "                    best_y, best_x = i_y, i_x\n",
    "                    best_val = val\n",
    "            else:\n",
    "                val = img[b, c, i_y, i_x] - kernel[c, k_y, k_x]\n",
    "                if val < best_val:\n",
    "                    best_y, best_x = i_y, i_x\n",
    "                    best_val = val\n",
    "\n",
    "    out_img[b, c, centre_y, centre_x] = best_val\n",
    "    out_prov[b, c, centre_y, centre_x, 0] = best_y\n",
    "    out_prov[b, c, centre_y, centre_x, 1] = best_x"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "f225ff2687bf77a4",
   "metadata": {},
   "source": [
    "mnist = load_data.mnist()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "e236c5dac107bff2",
   "metadata": {},
   "source": [
    "test_imgs = (\n",
    "    torch.asarray(mnist.x_train[:2048], device=\"cuda\").unsqueeze(1).repeat((1, 6, 1, 1))\n",
    ")\n",
    "print(test_imgs.dtype)\n",
    "test_imgs.shape"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "479244cececf0863",
   "metadata": {},
   "source": [
    "test_kernels = -torch.asarray(\n",
    "    [\n",
    "        # 1: Does nothing\n",
    "        [[[INF, INF, INF], [INF, 0, INF], [INF, INF, INF]]],\n",
    "        # 2: Vertical max\n",
    "        [[[INF, 0, INF], [INF, 0, INF], [INF, 0, INF]]],\n",
    "        # 3: Horizontal max\n",
    "        [[[INF, INF, INF], [0, 0, 0], [INF, INF, INF]]],\n",
    "        # 4: 3x3 max\n",
    "        [[[0, 0, 0], [0, 0, 0], [0, 0, 0]]],\n",
    "        # 5: small quadratic max, isotropic\n",
    "        [[[0.4, 0.1, 0.4], [0.1, 0, 0.1], [0.4, 0.1, 0.4]]],\n",
    "        # 6: small quadratic max, wide horizontally\n",
    "        [[[0.5, 0.2, 0.5], [0.05, 0, 0.05], [0.5, 0.2, 0.5]]],\n",
    "    ],\n",
    "    device=\"cuda\",\n",
    ").squeeze(1)\n",
    "print(test_kernels.dtype)\n",
    "test_kernels.shape"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "140f9f06ff6539ca",
   "metadata": {},
   "source": [
    "o_i = torch.full_like(test_imgs, -700, device=\"cuda\")\n",
    "o_p = torch.full(test_imgs.shape + (2,), -699, dtype=torch.int16, device=\"cuda\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "cebd1b0c9b3f1aaa",
   "metadata": {},
   "source": [
    "o_i[:] = -688\n",
    "o_p[:] = -689\n",
    "dilate_flat[math.ceil(test_imgs.nelement() / 256), 256](\n",
    "    test_imgs, test_kernels, o_i, o_p, *test_imgs.shape[1:], *test_kernels.shape[1:]\n",
    ")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "c4be2342937d26f8",
   "metadata": {},
   "source": [
    "def compile_tropical_conv(\n",
    "        is_max: bool,\n",
    "        channels: int,\n",
    "        kernel_size: int,\n",
    "        block_size: int = 256,\n",
    "        debug: bool = False,\n",
    "        calculate_prov: bool = True,\n",
    "):\n",
    "    cs = channels\n",
    "    k_ys = k_xs = kernel_size\n",
    "\n",
    "    @cuda.jit(\n",
    "        \"void(float32[:, :, :, :],\"  # img: [Batch, Channel, Img_Y, Img_X]\n",
    "        \" float32[:, :, :],\"  # kernel: [Channel, Kernel_Y, Kernel_X\n",
    "        \" float32[:, :, :, :],\"  # out_img: [Batch, Channel, Img_Y, Img_X]\n",
    "        f\"{'int16[:, :, :, :, :],' if calculate_prov else 'int16,'}\"  # out_prov: [Batch, Channel, Img_Y, Img_X, 2 (y, then x)]\n",
    "        \" int64, int64)\",  # Img_Y, Img_X\n",
    "        debug=debug,\n",
    "        opt=not debug,\n",
    "    )\n",
    "    def conv_cuda(img, kernel, out_img, out_prov, i_ys, i_xs):\n",
    "        idx = cuda.grid(1)\n",
    "        if idx >= img.size:\n",
    "            return\n",
    "        idx_y, centre_x = divmod(idx, i_xs)\n",
    "        idx_z, centre_y = divmod(idx_y, i_ys)\n",
    "        b, c = divmod(idx_z, cs)\n",
    "\n",
    "        top_y, left_x = centre_y - k_ys // 2, centre_x - k_xs // 2\n",
    "        best_x = best_y = -99\n",
    "        best_val = -INF if is_max else INF\n",
    "\n",
    "        for k_y, i_y in enumerate(range(top_y, top_y + k_ys)):\n",
    "            for k_x, i_x in enumerate(range(left_x, left_x + k_xs)):\n",
    "                if i_x < 0 or i_x >= i_xs or i_y < 0 or i_y >= i_ys:\n",
    "                    continue\n",
    "\n",
    "                if is_max:\n",
    "                    val = img[b, c, i_y, i_x] + kernel[c, k_y, k_x]\n",
    "                    if val > best_val:\n",
    "                        best_val = val\n",
    "                        if calculate_prov:\n",
    "                            best_y, best_x = i_y, i_x\n",
    "                else:\n",
    "                    val = img[b, c, i_y, i_x] - kernel[c, k_y, k_x]\n",
    "                    if val < best_val:\n",
    "                        best_val = val\n",
    "                        if calculate_prov:\n",
    "                            best_y, best_x = i_y, i_x\n",
    "\n",
    "        out_img[b, c, centre_y, centre_x] = best_val\n",
    "        if calculate_prov:\n",
    "            out_prov[b, c, centre_y, centre_x, 0] = best_y\n",
    "            out_prov[b, c, centre_y, centre_x, 1] = best_x\n",
    "\n",
    "    def conv(img: torch.Tensor, kernel: torch.Tensor):\n",
    "        img, kernel = img.detach(), kernel.detach()\n",
    "        out_img = torch.empty_like(img)\n",
    "        if calculate_prov:\n",
    "            out_prov = torch.empty(\n",
    "                img.shape + (2,), device=img.compilation, dtype=torch.int16\n",
    "            )\n",
    "        else:\n",
    "            out_prov = -1\n",
    "        n_blocks = math.ceil(img.nelement() / block_size)\n",
    "        conv_cuda[n_blocks, block_size](\n",
    "            img, kernel, out_img, out_prov, img.shape[2], img.shape[3]\n",
    "        )\n",
    "        if calculate_prov:\n",
    "            return out_img, out_prov\n",
    "        return out_img\n",
    "\n",
    "    return conv"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "ed2c6f6ac813a3b3",
   "metadata": {},
   "source": [
    "max_op = compile_tropical_conv(is_max=True, channels=6, kernel_size=3)\n",
    "min_op = compile_tropical_conv(is_max=False, channels=6, kernel_size=3)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "f2b022c5791fe008",
   "metadata": {},
   "source": [
    "img_num = 1\n",
    "plt.set_cmap(\"viridis\")\n",
    "_, ((ax_original, *ax_maxs), (ax_unused, *ax_mins)) = plt.subplots(\n",
    "    2, 1 + 6, layout=\"compressed\"\n",
    ")\n",
    "ax_original.set_axis_off()\n",
    "ax_unused.set_axis_off()\n",
    "ax_original.imshow(test_imgs[img_num, 0].numpy(force=True))\n",
    "ax_original.set_title(\"Original\")\n",
    "max_imgs = max_op(test_imgs, test_kernels)[0]\n",
    "for i, (ax, img_channel) in enumerate(\n",
    "        zip(ax_maxs, max_imgs[img_num].numpy(force=True), strict=True), 1\n",
    "):\n",
    "    ax.set_axis_off()\n",
    "    ax.imshow(img_channel)\n",
    "    ax.set_title(f\"Max #{i}\")\n",
    "min_imgs = min_op(test_imgs, test_kernels)[0]\n",
    "for i, (ax, img_channel) in enumerate(\n",
    "        zip(ax_mins, min_imgs[img_num].numpy(force=True), strict=True), 1\n",
    "):\n",
    "    ax.set_axis_off()\n",
    "    ax.imshow(img_channel)\n",
    "    ax.set_title(f\"Min #{i}\")\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "9ccd732f61ff0f74",
   "metadata": {},
   "source": [
    "unfold_max = convolutions.TropicalConv2D(is_max=True)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "b8da941ff9319b7e",
   "metadata": {},
   "source": [
    "def run_one():\n",
    "    torch.cuda.synchronize()\n",
    "    arr = unfold_max(test_imgs, test_kernels.unsqueeze(1))[0]\n",
    "    del arr\n",
    "    torch.cuda.synchronize()\n",
    "\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "run_one()\n",
    "# %timeit run_one()\n",
    "torch.cuda.empty_cache()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "7453520a48ec1e66",
   "metadata": {},
   "source": [
    "per_img_shape = test_imgs.shape[2:]\n",
    "print(per_img_shape)\n",
    "np.prod(per_img_shape)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "b3486a2e95f8dba6",
   "metadata": {},
   "source": [
    "per_image_max_op = compile_tropical_conv(\n",
    "    is_max=True, channels=6, kernel_size=3, block_size=784\n",
    ")\n",
    "\n",
    "\n",
    "def run_one():\n",
    "    cuda.synchronize()\n",
    "    arr = max_op(test_imgs, test_kernels)[0]\n",
    "    del arr\n",
    "    cuda.synchronize()\n",
    "\n",
    "\n",
    "def run_one_per_image():\n",
    "    cuda.synchronize()\n",
    "    arr = per_image_max_op(test_imgs, test_kernels)[0]\n",
    "    del arr\n",
    "    cuda.synchronize()\n",
    "\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "run_one()\n",
    "# %timeit run_one()\n",
    "torch.cuda.empty_cache()\n",
    "run_one_per_image()\n",
    "# %timeit run_one_per_image()\n",
    "torch.cuda.empty_cache()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "18b8011eb69f20bf",
   "metadata": {},
   "source": [
    "plt.matshow(test_imgs[0, 0, :15, :15].numpy(force=True))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "fb4076a77a9b22ea",
   "metadata": {},
   "source": [
    "import importlib\n",
    "\n",
    "importlib.reload(convolutions)\n",
    "from src import convolutions"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "306a7b882350882d",
   "metadata": {},
   "source": [
    "channel_nr = 2\n",
    "g_imgs = test_imgs.clone()\n",
    "g_kernels = test_kernels.clone()\n",
    "# g_imgs[0, channel_nr, 7, 7] *= 100\n",
    "g_imgs.requires_grad_(True)\n",
    "g_kernels.requires_grad_(True)\n",
    "g_imgs.grad = None\n",
    "g_kernels.grad = None\n",
    "\n",
    "x_slice = slice(None, 15)\n",
    "y_slice = slice(None, 15)\n",
    "target_xs = [7, 7, 7, 8]\n",
    "target_ys = [6, 7, 8, 6]\n",
    "target_x = target_y = None\n",
    "res_imgs = convolutions.TropicalConv2D(is_max=True)(\n",
    "    g_imgs, g_kernels.unsqueeze(1), padding=1\n",
    ")\n",
    "res_imgs[0, channel_nr, target_ys, target_xs].sum().backward()\n",
    "_, axs = plt.subplots(ncols=5, layout=\"compressed\", figsize=(15, 15), dpi=300)\n",
    "\n",
    "axs[0].matshow(g_kernels[channel_nr].numpy(force=True))\n",
    "axs[0].set_title(\"Kernel\")\n",
    "axs[1].matshow(\n",
    "    g_imgs[0, channel_nr, y_slice, x_slice].numpy(force=True), vmin=0, vmax=2\n",
    ")\n",
    "axs[1].set_title(\"Original\")\n",
    "axs[2].matshow(\n",
    "    res_imgs[0, channel_nr, y_slice, x_slice].numpy(force=True), vmin=0, vmax=2\n",
    ")\n",
    "axs[2].set_title(\"Convolved\")\n",
    "g_np = g_imgs.grad[0, channel_nr, y_slice, x_slice].numpy(force=True)\n",
    "axs[3].matshow(g_np)\n",
    "axs[3].set_title(\"Image Gradient\")\n",
    "g_np_k = g_kernels.grad[channel_nr].numpy(force=True)\n",
    "axs[4].matshow(g_np_k)\n",
    "axs[4].set_title(\"Kernel Gradient\")\n",
    "for g_i, g_j in zip(*g_np.nonzero()):\n",
    "    axs[3].text(\n",
    "        g_j, g_i, g_np[g_i, g_j], color=\"black\", fontsize=5, ha=\"center\", va=\"center\"\n",
    "    )\n",
    "for g_i, g_j in zip(*g_np_k.nonzero()):\n",
    "    axs[4].text(\n",
    "        g_j, g_i, g_np_k[g_i, g_j], color=\"black\", fontsize=10, ha=\"center\", va=\"center\"\n",
    "    )\n",
    "for ax, ax_arr in zip(axs[1:4], (g_imgs, res_imgs, g_imgs.grad)):\n",
    "    for tx, ty in zip(target_xs, target_ys):\n",
    "        ax.text(\n",
    "            tx,\n",
    "            ty,\n",
    "            ax_arr[0, channel_nr, ty, tx].numpy(force=True).round(2),\n",
    "            color=\"red\",\n",
    "            fontsize=5,\n",
    "            ha=\"center\",\n",
    "            va=\"center\",\n",
    "        )\n",
    "    # ax.scatter(target_x, target_y, marker=\"x\", color='red')\n",
    "plt.suptitle(\"Unfold-max gradients\")\n",
    "print(\"Nonzero gradient in image:\", g_np.nonzero())"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "dfeff9cf197e5d0a",
   "metadata": {},
   "source": [
    "def compile_tropical_conv_backwards(\n",
    "        is_max: bool,\n",
    "        channels: int,\n",
    "        kernel_size: int,\n",
    "        block_size: int = 256,\n",
    "        debug: bool = False,\n",
    "):\n",
    "    def one(v, w):\n",
    "        return 1\n",
    "\n",
    "    def minus_one(v, w):\n",
    "        return -1\n",
    "\n",
    "    cs = channels\n",
    "    k_ys = k_xs = kernel_size\n",
    "    if is_max:\n",
    "        d_weigh_d_v = d_weigh_d_w = one\n",
    "    else:\n",
    "        d_weigh_d_v = one\n",
    "        d_weigh_d_w = minus_one\n",
    "\n",
    "    d_weigh_d_v = cuda.jit(d_weigh_d_v, device=True)\n",
    "    d_weigh_d_w = cuda.jit(d_weigh_d_w, device=True)\n",
    "\n",
    "    # noinspection PyArgumentList\n",
    "    @cuda.jit(\n",
    "        \"void(float32[:, :, :, :],\"  # img: [Batch, Channel, Img_Y, Img_X]\n",
    "        \" float32[:, :, :],\"  # kernel: [Channel, Kernel_Y, Kernel_X]\n",
    "        \" float32[:, :, :, :],\"  # res_tangent: [Batch, Channel, Img_Y, Img_X]\n",
    "        \" int16[:, :, :, :, :],\"  # res_prov: [Batch, Channel, Img_Y, Img_X, 2 (y, then x)]\n",
    "        \" float32[:, :, :, :],\"  # out_img_grad: [Batch, Channel, Img_Y, Img_X]\n",
    "        \" float32[:, :, :],\"  # out_kernel_grad: [Channel, Kernel_Y, Kernel_X]\n",
    "        \" int64, int64)\",  # Img_Y, Img_X\n",
    "        debug=debug,\n",
    "        opt=not debug,\n",
    "    )\n",
    "    def conv_backwards_cuda(\n",
    "            img, kernel, res_tangent, res_prov, out_img_grad, out_kernel_grad, i_ys, i_xs\n",
    "    ):\n",
    "        idx = cuda.grid(1)\n",
    "        if idx >= img.size:\n",
    "            return\n",
    "        idx_y, centre_x = divmod(idx, i_xs)\n",
    "        idx_z, centre_y = divmod(idx_y, i_ys)\n",
    "        b, c = divmod(idx_z, cs)\n",
    "        tangent = res_tangent[b, c, centre_y, centre_x]\n",
    "        if tangent == 0:\n",
    "            return\n",
    "\n",
    "        i_prov_x, i_prov_y = (\n",
    "            res_prov[b, c, centre_y, centre_x, 1],\n",
    "            res_prov[b, c, centre_y, centre_x, 0],\n",
    "        )\n",
    "        img_val = img[b, c, i_prov_y, i_prov_x]\n",
    "\n",
    "        rel_prov_x, rel_prov_y = i_prov_x - centre_x, i_prov_y - centre_y\n",
    "        k_prov_x, k_prov_y = rel_prov_x + k_xs // 2, rel_prov_y + k_ys // 2\n",
    "        kernel_val = kernel[c, k_prov_y, k_prov_x]\n",
    "\n",
    "        dv = d_weigh_d_v(img_val, kernel_val) * tangent\n",
    "        dw = d_weigh_d_w(img_val, kernel_val) * tangent\n",
    "\n",
    "        cuda.atomic.add(out_img_grad, (b, c, i_prov_y, i_prov_x), dv)\n",
    "        cuda.atomic.add(out_kernel_grad, (c, k_prov_y, k_prov_x), dw)\n",
    "\n",
    "    def backwards(\n",
    "            img: torch.Tensor,\n",
    "            kernel: torch.Tensor,\n",
    "            res_tangent: torch.Tensor,\n",
    "            res_prov: torch.Tensor,\n",
    "    ):\n",
    "        img, kernel = img.detach(), kernel.detach()\n",
    "        out_img_grad = torch.zeros_like(img)\n",
    "        out_kernel_grad = torch.zeros_like(kernel)\n",
    "        n_blocks = math.ceil(img.nelement() / block_size)\n",
    "        conv_backwards_cuda[n_blocks, block_size](\n",
    "            img,\n",
    "            kernel,\n",
    "            res_tangent,\n",
    "            res_prov,\n",
    "            out_img_grad,\n",
    "            out_kernel_grad,\n",
    "            img.shape[2],\n",
    "            img.shape[3],\n",
    "        )\n",
    "        return out_img_grad, out_kernel_grad\n",
    "\n",
    "    return backwards"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "68cff77db91e52d9",
   "metadata": {},
   "source": [
    "max_back_op = compile_tropical_conv_backwards(is_max=True, channels=6, kernel_size=3)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "1694a6e933b802e6",
   "metadata": {},
   "source": [
    "channel_nr = 2\n",
    "g_imgs = test_imgs.clone()\n",
    "g_kernels = test_kernels.clone()\n",
    "# g_imgs[0, channel_nr, 7, 7] *= 100\n",
    "\n",
    "x_slice = slice(None, 15)\n",
    "y_slice = slice(None, 15)\n",
    "target_xs = [7, 7, 7, 8]\n",
    "target_ys = [6, 7, 8, 6]\n",
    "target_x = target_y = None\n",
    "res_imgs, test_provs = max_op(g_imgs, g_kernels)\n",
    "test_tangent = torch.zeros_like(res_imgs)\n",
    "test_tangent[0, channel_nr, target_ys, target_xs] = 1\n",
    "test_i_grad, test_k_grad = max_back_op(g_imgs, g_kernels, test_tangent, test_provs)\n",
    "\n",
    "_, axs = plt.subplots(ncols=5, layout=\"compressed\", figsize=(15, 15), dpi=300)\n",
    "axs[0].matshow(g_kernels[channel_nr].numpy(force=True))\n",
    "axs[0].set_title(\"Kernel\")\n",
    "axs[1].matshow(\n",
    "    g_imgs[0, channel_nr, y_slice, x_slice].numpy(force=True), vmin=0, vmax=2\n",
    ")\n",
    "axs[1].set_title(\"Original\")\n",
    "axs[2].matshow(\n",
    "    res_imgs[0, channel_nr, y_slice, x_slice].numpy(force=True), vmin=0, vmax=2\n",
    ")\n",
    "axs[2].set_title(\"Convolved\")\n",
    "g_np = test_i_grad[0, channel_nr, y_slice, x_slice].numpy(force=True)\n",
    "axs[3].matshow(g_np)\n",
    "axs[3].set_title(\"Image Gradient\")\n",
    "g_np_k = test_k_grad[channel_nr].numpy(force=True)\n",
    "axs[4].matshow(g_np_k)\n",
    "axs[4].set_title(\"Kernel Gradient\")\n",
    "for g_i, g_j in zip(*g_np.nonzero()):\n",
    "    axs[3].text(\n",
    "        g_j, g_i, g_np[g_i, g_j], color=\"black\", fontsize=5, ha=\"center\", va=\"center\"\n",
    "    )\n",
    "for g_i, g_j in zip(*g_np_k.nonzero()):\n",
    "    axs[4].text(\n",
    "        g_j, g_i, g_np_k[g_i, g_j], color=\"black\", fontsize=10, ha=\"center\", va=\"center\"\n",
    "    )\n",
    "for ax, ax_arr in zip(axs[1:4], (g_imgs, res_imgs, test_i_grad)):\n",
    "    for tx, ty in zip(target_xs, target_ys):\n",
    "        ax.text(\n",
    "            tx,\n",
    "            ty,\n",
    "            ax_arr[0, channel_nr, ty, tx].numpy(force=True).round(2),\n",
    "            color=\"red\",\n",
    "            fontsize=5,\n",
    "            ha=\"center\",\n",
    "            va=\"center\",\n",
    "        )\n",
    "    # ax.scatter(target_x, target_y, marker=\"x\", color='red')\n",
    "plt.suptitle(\"Unfold-max gradients\")\n",
    "print(\"Nonzero gradient in image:\", g_np.nonzero())"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "ce0eccb406275b84",
   "metadata": {},
   "source": [
    "test_tangent_dense = torch.randn_like(test_imgs)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "e6476953f6a586cc",
   "metadata": {},
   "source": [
    "g_imgs = test_imgs.clone()\n",
    "g_kernels = test_kernels.clone()\n",
    "g_imgs.requires_grad_(True)\n",
    "g_kernels.requires_grad_(True)\n",
    "\n",
    "\n",
    "def run_one():\n",
    "    torch.cuda.synchronize()\n",
    "    arr = unfold_max(g_imgs, g_kernels.unsqueeze(1), padding=1)\n",
    "    arr.backward(test_tangent_dense)\n",
    "    del arr\n",
    "    torch.cuda.synchronize()\n",
    "\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "run_one()\n",
    "# %timeit run_one()\n",
    "torch.cuda.empty_cache()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "d23f32a3e3d9676",
   "metadata": {},
   "source": [
    "# @torch.compile\n",
    "def run_one():\n",
    "    cuda.synchronize()\n",
    "    arr, provs = max_op(test_imgs, test_kernels)\n",
    "    i_grad, k_grad = max_back_op(test_imgs, test_kernels, test_tangent_dense, provs)\n",
    "    del arr, i_grad, k_grad\n",
    "    cuda.synchronize()\n",
    "\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "run_one()\n",
    "# %timeit run_one()\n",
    "torch.cuda.empty_cache()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "5fc32d499bb1b9b9",
   "metadata": {},
   "source": [
    "plt.set_cmap(\"viridis\");"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "5391c407be3ddeec",
   "metadata": {},
   "source": [
    "@torch.library.custom_op(\"semifields::dilation\", mutates_args={}, device_types=\"cuda\")\n",
    "def lib_max_op(\n",
    "        img: torch.Tensor,\n",
    "        kernel: torch.Tensor,\n",
    "        padding: int = 1,\n",
    "        stride: int = 1,\n",
    "        dilation: int = 1,\n",
    ") -> tuple[torch.Tensor, torch.Tensor]:\n",
    "    return max_op(img, kernel)\n",
    "\n",
    "\n",
    "@lib_max_op.register_fake\n",
    "def _(img: torch.Tensor, kernel, padding: int = 1, stride: int = 1, dilation: int = 1):\n",
    "    assert img.dtype == torch.float32\n",
    "    assert kernel.dtype == torch.float32\n",
    "    assert padding == 1\n",
    "    assert stride == 1\n",
    "    assert dilation == 1\n",
    "    return torch.empty_like(img), img.new_empty(img.shape + (2,), dtype=torch.int16)\n",
    "\n",
    "\n",
    "def _back_setup(ctx, inputs, output):\n",
    "    img, kernel, padding, stride, dilation = inputs\n",
    "    _res, prov = output\n",
    "    ctx.img = img\n",
    "    ctx.kernel = kernel\n",
    "    ctx.prov = prov\n",
    "\n",
    "\n",
    "@torch.library.custom_op(\n",
    "    \"semifields::dilation_back\", mutates_args={}, device_types=\"cuda\"\n",
    ")\n",
    "def _lib_back_op(\n",
    "        img: torch.Tensor, kernel: torch.Tensor, tangent: torch.Tensor, prov: torch.Tensor\n",
    ") -> tuple[torch.Tensor, torch.Tensor]:\n",
    "    grad_img, grad_kernel = max_back_op(img, kernel, tangent, prov)\n",
    "    return grad_img, grad_kernel\n",
    "\n",
    "\n",
    "@_lib_back_op.register_fake\n",
    "def _(img, kernel, _tangent, _prov):\n",
    "    assert img.dtype == torch.float32\n",
    "    assert kernel.dtype == torch.float32\n",
    "    assert _tangent.dtype == torch.float32\n",
    "    assert _prov.dtype == torch.int16\n",
    "    return torch.empty_like(img), torch.empty_like(kernel)\n",
    "\n",
    "\n",
    "def _lib_back(ctx, grad_output, _grad_prov):\n",
    "    return _lib_back_op(ctx.img, ctx.kernel, grad_output, ctx.prov)\n",
    "\n",
    "\n",
    "lib_max_op.register_autograd(_lib_back, setup_context=_back_setup)\n",
    "\n",
    "g_kernels.grad = None\n",
    "g_kernels.requires_grad_(True)\n",
    "test_tangent = torch.zeros_like(test_imgs)\n",
    "test_tangent[0, channel_nr, target_ys, target_xs] = 1\n",
    "lib_max_op(test_imgs, g_kernels)[0].backward(test_tangent)\n",
    "# TestMaxOp.apply(test_imgs, g_kernels).backward(test_tangent)\n",
    "plt.matshow(g_kernels.grad[channel_nr].numpy(force=True))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "7331e193c34653e3",
   "metadata": {},
   "source": [
    "def numba_max(\n",
    "        img: torch.Tensor,\n",
    "        kernel: torch.Tensor,\n",
    "        padding: int = 1,\n",
    "        stride: int = 1,\n",
    "        dilation: int = 1,\n",
    "):\n",
    "    if len(kernel.shape) == 4:\n",
    "        kernel = kernel.unsqueeze(1)\n",
    "    assert img.shape[1] == kernel.shape[0]\n",
    "    return lib_max_op(img, kernel, padding, stride, dilation)[0]"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "13d3948e5c34812c",
   "metadata": {},
   "source": [
    "test_tangent.nonzero().numpy(force=True)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "bacc24d597f78726",
   "metadata": {},
   "source": [
    "lib_max_op(test_imgs, g_kernels)\n",
    "# noinspection PyTypeChecker\n",
    "torch.library.opcheck(lib_max_op, (test_imgs, g_kernels))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "81a45cc6e68e9593",
   "metadata": {},
   "source": [
    "# it doesn't pass gradcheck...\n",
    "torch.autograd.gradcheck(lib_max_op, (test_imgs[:1], g_kernels), raise_exception=False)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "65f2b0771e2a6795",
   "metadata": {},
   "source": [
    "# but I don't override any gradient calculations here, so it must be down to PyTorch messing up the max/min gradients\n",
    "torch.autograd.gradcheck(\n",
    "    convolutions.TropicalConv2D(is_max=True),\n",
    "    (test_imgs[:1], g_kernels.unsqueeze(1)),\n",
    "    raise_exception=False,\n",
    ")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "98e8019c51e30be9",
   "metadata": {},
   "source": [
    "@torch.compile(mode=\"reduce-overhead\")\n",
    "def run_one():\n",
    "    cuda.synchronize()\n",
    "    arr, provs = lib_max_op(test_imgs, g_kernels)\n",
    "    arr.backward(test_tangent_dense)\n",
    "    del arr\n",
    "    cuda.synchronize()\n",
    "\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "run_one()\n",
    "# %timeit run_one()\n",
    "torch.cuda.empty_cache()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "25276d59ace4e5f5",
   "metadata": {},
   "source": [
    "from timeit import timeit\n",
    "from tqdm.auto import tqdm, trange"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "e242d9f79a09cb4f",
   "metadata": {},
   "source": [
    "# fmt: off\n",
    "slice_sizes = [2, 3, 4, 6, 8, 12, 16, 23, 32, 46, 64, 91, 128, 182, 256, 363, 512, 725, 1024, 1449, 2048]\n",
    "unfold_timings = [0.00010274730650053243, 8.403245400040759e-05, 8.851143950232653e-05, 0.00010076602150002145,\n",
    "                  0.00012131676400167635, 0.000124929585501377, 0.00014966875500249443, 0.000199354405496706,\n",
    "                  0.00025833106350182786, 0.00035760370749994764, 0.0004823765924993495, 0.0006648011590004899,\n",
    "                  0.0009164136265026173, 0.001269442678501946, 0.0017770433570003662, 0.0025119446479984616,\n",
    "                  0.0036233893550015636, 0.0052635354004996774, 0.007498402453999006, 0.010653741374000674,\n",
    "                  0.014994164466501389]\n",
    "numba_timings = [0.00041991026799951213, 0.0004150625224974647, 0.00041995406449859727, 0.0004226304935000371,\n",
    "                 0.0004205896764979116, 0.0004200762550026411, 0.00042519056650053245, 0.00043969415899846356,\n",
    "                 0.000461269485498633, 0.0004921157089993358, 0.0005326687759988999, 0.000598328826999932,\n",
    "                 0.0006867694915017637, 0.0008550973589990463, 0.0010212399034971896, 0.0012820430794999993,\n",
    "                 0.0016308881609984381, 0.00213099660050284, 0.002836544132500421, 0.0040347791409985805,\n",
    "                 0.0056132207165028375]\n",
    "slice_sizes_detail = [70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89]\n",
    "unfold_timings_detail = [0.0005231618008999794, 0.0005300874041199859, 0.0005373257529799594, 0.000543491658839921,\n",
    "                         0.0005501257682598953, 0.0005600170065599377, 0.0005661544485400373, 0.0005724291121000715,\n",
    "                         0.0005786100002999592, 0.0005850134414200147, 0.0005919706213800236, 0.0005975213742800406,\n",
    "                         0.0006039276255598815, 0.0006115772961400217, 0.0006184966304400586, 0.000624261617519951,\n",
    "                         0.0006320271702000172, 0.0006411902578199806, 0.0006466227984400757, 0.0006526624815800461]\n",
    "numba_timings_detail = [0.0005487732924800366, 0.0005504305595999176, 0.0005602229583999724, 0.0005519845550401078,\n",
    "                        0.0005552577408599609, 0.0005599274011599482, 0.0005594913014999475, 0.000562018028760067,\n",
    "                        0.0005715560740999354, 0.000603191901879909, 0.0005728149966799538, 0.0006106505254599324,\n",
    "                        0.0005787932900199667, 0.0005814040630200179, 0.0005867868537201139, 0.0005937331920399446,\n",
    "                        0.0006245092738600214, 0.0005905518150200078, 0.000597254317360057, 0.0005953584205200604]\n",
    "# fmt: on"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "7fd2cc036d6840ec",
   "metadata": {},
   "source": [
    "run_timings = False"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "81130a52aee07483",
   "metadata": {},
   "source": [
    "if run_timings:\n",
    "    torch_code = \"\"\"\n",
    "sync()\n",
    "arr = dilate(imgs, kernels, padding=1)\n",
    "arr.backward(tangent)\n",
    "del arr\n",
    "sync()\n",
    "    \"\"\"\n",
    "    slice_sizes = []\n",
    "    unfold_timings = []\n",
    "    numba_timings = []\n",
    "    num_loops = 2_000\n",
    "    bar = trange(2, 23)\n",
    "    for size_pow in bar:\n",
    "        test_size = math.ceil(2 ** (size_pow / 2))\n",
    "        test_slice = test_imgs[:test_size]\n",
    "        slice_sizes.append(len(test_slice))\n",
    "        unfold_timings.append(\n",
    "            timeit(\n",
    "                torch_code,\n",
    "                number=num_loops,\n",
    "                globals={\n",
    "                    \"sync\": torch.cuda.synchronize,\n",
    "                    \"imgs\": test_slice.clone().requires_grad_(True),\n",
    "                    \"kernels\": test_kernels.unsqueeze(1).clone().requires_grad_(True),\n",
    "                    \"tangent\": torch.randn_like(test_slice),\n",
    "                    \"dilate\": unfold_max,\n",
    "                },\n",
    "            )\n",
    "            / num_loops\n",
    "        )\n",
    "        numba_timings.append(\n",
    "            timeit(\n",
    "                torch_code,\n",
    "                number=num_loops,\n",
    "                globals={\n",
    "                    \"sync\": cuda.synchronize,\n",
    "                    \"imgs\": test_slice.clone().requires_grad_(True),\n",
    "                    \"kernels\": test_kernels.clone().requires_grad_(True),\n",
    "                    \"tangent\": torch.randn_like(test_slice),\n",
    "                    \"dilate\": numba_max,\n",
    "                },\n",
    "            )\n",
    "            / num_loops\n",
    "        )\n",
    "        bar.set_postfix(\n",
    "            size=slice_sizes[-1],\n",
    "            faster=\"unfold\" if unfold_timings[-1] < numba_timings[-1] else \"numba\",\n",
    "        )"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "d51fa1c74253750e",
   "metadata": {},
   "source": [
    "colors = plt.rcParams[\"axes.prop_cycle\"].by_key()[\"color\"]\n",
    "\n",
    "plt.plot(slice_sizes, unfold_timings, label=\"Unfold\", color=colors[0])\n",
    "plt.scatter(slice_sizes, unfold_timings, color=colors[0])\n",
    "plt.plot(slice_sizes, numba_timings, label=\"Numba CUDA\", color=colors[1])\n",
    "plt.scatter(slice_sizes, numba_timings, color=colors[1])\n",
    "first_better = (np.subtract(unfold_timings, numba_timings) > 0).argmax()\n",
    "plt.axvline(slice_sizes[first_better], linestyle=\"dashed\", color=\"grey\")\n",
    "plt.text(slice_sizes[first_better - 1], 10 ** -3, slice_sizes[first_better], color=\"grey\")\n",
    "adjusted_numba = np.asarray(numba_timings) - numba_timings[1] + unfold_timings[1]\n",
    "plt.plot(\n",
    "    slice_sizes,\n",
    "    adjusted_numba,\n",
    "    label=\"Theoretical no-overhead Numba\",\n",
    "    linestyle=\"dashed\",\n",
    "    color=colors[1],\n",
    ")\n",
    "plt.xlabel(\"Batch size\")\n",
    "plt.ylabel(\"Time\")\n",
    "plt.title(\"Forwards- and backwards-pass with PyTorch Unfold and a Numba CUDA kernel\")\n",
    "plt.loglog()\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "93ad1e6dc98bac6d",
   "metadata": {},
   "source": [
    "if run_timings:\n",
    "    torch_code = \"\"\"\n",
    "sync()\n",
    "arr = dilate(imgs, kernels, padding=1)\n",
    "arr.backward(tangent)\n",
    "del arr\n",
    "sync()\n",
    "    \"\"\"\n",
    "    slice_sizes_detail = []\n",
    "    unfold_timings_detail = []\n",
    "    numba_timings_detail = []\n",
    "    num_loops = 50_000\n",
    "    bar = trange(70, 90)\n",
    "    test_tangent = torch.randn_like(test_imgs)\n",
    "    for test_size in bar:\n",
    "        test_slice = test_imgs[:test_size]\n",
    "        slice_sizes_detail.append(len(test_slice))\n",
    "        unfold_timings_detail.append(\n",
    "            timeit(\n",
    "                torch_code,\n",
    "                number=num_loops,\n",
    "                globals={\n",
    "                    \"sync\": torch.cuda.synchronize,\n",
    "                    \"imgs\": test_slice.clone().requires_grad_(True),\n",
    "                    \"kernels\": test_kernels.unsqueeze(1).clone().requires_grad_(True),\n",
    "                    \"tangent\": test_tangent[:test_size],\n",
    "                    \"dilate\": unfold_max,\n",
    "                },\n",
    "            )\n",
    "            / num_loops\n",
    "        )\n",
    "        numba_timings_detail.append(\n",
    "            timeit(\n",
    "                torch_code,\n",
    "                number=num_loops,\n",
    "                globals={\n",
    "                    \"sync\": cuda.synchronize,\n",
    "                    \"imgs\": test_slice.clone().requires_grad_(True),\n",
    "                    \"kernels\": test_kernels.clone().requires_grad_(True),\n",
    "                    \"tangent\": test_tangent[:test_size],\n",
    "                    \"dilate\": numba_max,\n",
    "                },\n",
    "            )\n",
    "            / num_loops\n",
    "        )\n",
    "        bar.set_postfix(\n",
    "            size=slice_sizes_detail[-1],\n",
    "            faster=\"unfold\"\n",
    "            if unfold_timings_detail[-1] < numba_timings_detail[-1]\n",
    "            else \"numba\",\n",
    "        )"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "cf0f3cc06fa26751",
   "metadata": {},
   "source": [
    "colors = plt.rcParams[\"axes.prop_cycle\"].by_key()[\"color\"]\n",
    "\n",
    "plt.plot(slice_sizes_detail, unfold_timings_detail, label=\"Unfold\", color=colors[0])\n",
    "plt.scatter(slice_sizes_detail, unfold_timings_detail, color=colors[0])\n",
    "plt.plot(slice_sizes_detail, numba_timings_detail, label=\"Numba CUDA\", color=colors[1])\n",
    "plt.scatter(slice_sizes_detail, numba_timings_detail, color=colors[1])\n",
    "first_better = (np.subtract(unfold_timings_detail, numba_timings_detail) > 0).argmax()\n",
    "plt.axvline(slice_sizes_detail[first_better], linestyle=\"dashed\", color=\"grey\")\n",
    "plt.text(\n",
    "    slice_sizes_detail[first_better - 1],\n",
    "    0.00058,\n",
    "    slice_sizes_detail[first_better],\n",
    "    color=\"grey\",\n",
    ")\n",
    "adjusted_numba = (\n",
    "        np.asarray(numba_timings_detail)\n",
    "        - numba_timings_detail[1]\n",
    "        + unfold_timings_detail[1]\n",
    ")\n",
    "plt.xlabel(\"Batch size\")\n",
    "plt.ylabel(\"Time\")\n",
    "plt.title(\"Zoomed in\")\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "b296cffbc5f63f1",
   "metadata": {},
   "source": [
    "import warnings\n",
    "import numba\n",
    "\n",
    "warnings.simplefilter(\"ignore\", numba.NumbaPerformanceWarning, 536)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "907ed55f99b66fd1",
   "metadata": {},
   "source": [
    "def _conv_output_size(\n",
    "        input_size: int, kernel_size: int, stride: int, padding: int, dilation: int\n",
    "):\n",
    "    return math.floor(\n",
    "        (input_size + 2 * padding - dilation * (kernel_size - 1) - 1) / stride + 1\n",
    "    )"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "4a85ce1b441e7919",
   "metadata": {},
   "source": [
    "import typing\n",
    "\n",
    "\n",
    "class Foo(typing.NamedTuple):\n",
    "    bar: float\n",
    "\n",
    "\n",
    "ree = Foo(279.0)\n",
    "\n",
    "\n",
    "def rawr(x):\n",
    "    return x * 2\n",
    "\n",
    "\n",
    "@cuda.jit(\"void(float32[:])\", lineinfo=False)\n",
    "def spam(arr):\n",
    "    x = cuda.grid(1)\n",
    "    if x < arr.size:\n",
    "        arr[x] += rawr(ree.bar)\n",
    "\n",
    "\n",
    "a = torch.ones(5, device=\"cuda\")\n",
    "spam[1, 32](a)\n",
    "a"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "15af25fd26630824",
   "metadata": {},
   "source": [
    "Foo(3.0) == (3,)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "452b13b5cf1f3a52",
   "metadata": {},
   "source": [
    "import uuid\n",
    "\n",
    "\n",
    "def compile_tropical_op(\n",
    "        example_imgs: torch.Tensor,\n",
    "        example_kernels: torch.Tensor,\n",
    "        *,\n",
    "        is_max: bool,\n",
    "        block_size: int = 256,\n",
    "        kernel_broadcasting: bool = False,\n",
    "        debug: bool = False,\n",
    "        fixed_stride: int = 1,\n",
    "        fixed_padding: int = 1,\n",
    "        fixed_dilation: int = 1,\n",
    "        compile_entry_point: bool = True,\n",
    "):\n",
    "    # === Check example_imgs\n",
    "    assert torch.cuda.is_available(), \"No CUDA?\"\n",
    "    assert example_imgs.dtype == torch.float32, f\"{example_imgs.dtype=}\"\n",
    "    assert example_kernels.dtype == torch.float32, f\"{example_kernels.dtype=}\"\n",
    "    assert len(example_imgs.shape) == 4\n",
    "    cs, i_ys, i_xs = example_imgs.shape[1:]\n",
    "\n",
    "    # === Check example_kernels\n",
    "    if len(example_kernels.shape) == 4:\n",
    "        example_kernels = example_kernels.squeeze(1)\n",
    "    k_cs, k_ys, k_xs = example_kernels.shape\n",
    "    if kernel_broadcasting:\n",
    "        assert k_cs == 1, f\"Asked for kernel broadcasting, but {example_kernels.shape=}\"\n",
    "        raise NotImplementedError\n",
    "    else:\n",
    "        assert cs == k_cs, f\"No kernel broadcasting, but {cs=} != {k_cs=}\"\n",
    "\n",
    "    # We reserve prov_maxval for debugging invalid provenances\n",
    "    prov_maxval = np.iinfo(np.uint8).max\n",
    "    assert k_ys < prov_maxval, f\"Provenance indices are represented as u8, but {k_ys=}\"\n",
    "    assert k_xs < prov_maxval, f\"Provenance indices are represented as u8, but {k_xs=}\"\n",
    "\n",
    "    ex_img_shape_no_b = tuple(example_imgs.shape[1:])\n",
    "    ex_kernel_shape = tuple(example_kernels.shape)\n",
    "\n",
    "    o_xs = _conv_output_size(i_xs, k_xs, fixed_stride, fixed_padding, fixed_dilation)\n",
    "    o_ys = _conv_output_size(i_ys, k_ys, fixed_stride, fixed_padding, fixed_dilation)\n",
    "    blocks_per_image = cs * o_xs * o_ys / block_size\n",
    "\n",
    "    op_id = uuid.uuid4().hex\n",
    "    # === (temporary) Forward functions ===\n",
    "    if is_max:\n",
    "\n",
    "        def weigh(v, w):\n",
    "            return v + w\n",
    "\n",
    "        neutral = -INF\n",
    "\n",
    "        def select_right(left, right):\n",
    "            return left < right\n",
    "\n",
    "    else:\n",
    "\n",
    "        def weigh(v, w):\n",
    "            return v - w\n",
    "\n",
    "        neutral = INF\n",
    "\n",
    "        def select_right(left, right):\n",
    "            return left > right\n",
    "\n",
    "    # def is_valid(val):\n",
    "    #     return val != neutral\n",
    "\n",
    "    # === (temporary) Backward functions ===\n",
    "    def one(_v, _w):\n",
    "        return 1\n",
    "\n",
    "    def minus_one(_v, _w):\n",
    "        return -1\n",
    "\n",
    "    if is_max:\n",
    "        d_weigh_d_img = d_weigh_d_kernel = one\n",
    "    else:\n",
    "        d_weigh_d_img = one\n",
    "        d_weigh_d_kernel = minus_one\n",
    "\n",
    "    # === Compile user-provided functions\n",
    "    weigh = cuda.jit(weigh, device=True, inline=True)\n",
    "    select_right = cuda.jit(select_right, device=True, inline=True)\n",
    "    d_weigh_d_img = cuda.jit(d_weigh_d_img, device=True, inline=True)\n",
    "    d_weigh_d_kernel = cuda.jit(d_weigh_d_kernel, device=True, inline=True)\n",
    "\n",
    "    # is_valid = cuda.jit(is_valid, device=True, inline=True)\n",
    "\n",
    "    # === Forwards CUDA-side ===\n",
    "    @cuda.jit(\n",
    "        \"void(float32[:, :, :, :],\"  # img: [Batch, Channel, Img_Y, Img_X]\n",
    "        \" float32[:, :, :],\"  # kernel: [Channel, Kernel_Y, Kernel_X\n",
    "        \" float32[:, :, :, :],\"  # out_img: [Batch, Channel, Img_Y, Img_X]\n",
    "        \" uint8[:, :, :, :, :])\",  # out_prov: [Batch, Channel, Img_Y, Img_X, 2 (y, then x)]\n",
    "        debug=debug,\n",
    "        opt=not debug,\n",
    "    )\n",
    "    def conv_cuda_jit(img, kernel, out_img, out_prov):\n",
    "        idx = cuda.grid(1)\n",
    "        if idx >= out_img.size:\n",
    "            return\n",
    "        rem, o_x = divmod(idx, o_xs)\n",
    "        rem, o_y = divmod(rem, o_ys)\n",
    "        b, c = divmod(rem, cs)\n",
    "\n",
    "        i_top_y = o_y * fixed_stride - fixed_padding\n",
    "        i_left_x = o_x * fixed_stride - fixed_padding\n",
    "\n",
    "        prov_x = prov_y = prov_maxval\n",
    "        selected_val = neutral\n",
    "\n",
    "        for k_y, i_y in enumerate(\n",
    "                range(i_top_y, i_top_y + k_ys * fixed_dilation, fixed_dilation)\n",
    "        ):\n",
    "            for k_x, i_x in enumerate(\n",
    "                    range(i_left_x, i_left_x + k_xs * fixed_dilation, fixed_dilation)\n",
    "            ):\n",
    "                if i_x < 0 or i_x >= i_xs or i_y < 0 or i_y >= i_ys:\n",
    "                    continue\n",
    "\n",
    "                img_val = img[b, c, i_y, i_x]\n",
    "                kernel_val = kernel[0 if kernel_broadcasting else c, k_y, k_x]\n",
    "\n",
    "                val = weigh(img_val, kernel_val)\n",
    "                if select_right(selected_val, val):\n",
    "                    selected_val = val\n",
    "                    prov_y, prov_x = k_y, k_x\n",
    "\n",
    "        out_img[b, c, o_y, o_x] = selected_val\n",
    "\n",
    "        out_prov[b, c, o_y, o_x, 0] = prov_y\n",
    "        out_prov[b, c, o_y, o_x, 1] = prov_x\n",
    "\n",
    "    # === Forwards torch-side ===\n",
    "    @torch.library.custom_op(\n",
    "        f\"semifields::tropical_op_{op_id}\", mutates_args={}, device_types=\"cuda\"\n",
    "    )\n",
    "    def conv_cuda_lib(\n",
    "            img: torch.Tensor, kernel: torch.Tensor\n",
    "    ) -> tuple[torch.Tensor, torch.Tensor]:\n",
    "        img, kernel = img.detach(), kernel.detach()\n",
    "        assert kernel.shape == ex_kernel_shape, f\"Different {kernel.shape=}\"\n",
    "        assert img.shape[1:] == ex_img_shape_no_b, f\"Different {img.shape[1:]=}\"\n",
    "        assert img.dtype == torch.float32, f\"Wrong {img.dtype=}\"\n",
    "        if debug:\n",
    "            print(\"Warning: running CUDA kernel in debug mode\")\n",
    "        batch = img.shape[0]\n",
    "        out_img = img.new_empty((batch, cs, o_ys, o_xs))\n",
    "        out_prov = img.new_empty((batch, cs, o_ys, o_xs, 2), dtype=torch.uint8)\n",
    "        n_blocks = math.ceil(batch * blocks_per_image)\n",
    "        conv_cuda_jit[n_blocks, block_size](img, kernel, out_img, out_prov)\n",
    "        return out_img, out_prov\n",
    "\n",
    "    @conv_cuda_lib.register_fake\n",
    "    def _(img, kernel):\n",
    "        batch = img.shape[0]\n",
    "        return (\n",
    "            img.new_empty((batch, cs, o_ys, o_xs)),\n",
    "            kernel.new_empty((batch, cs, o_ys, o_xs, 2), dtype=torch.uint8),\n",
    "        )\n",
    "\n",
    "    # === Backwards CUDA-side ===\n",
    "    # noinspection PyArgumentList\n",
    "    @cuda.jit(\n",
    "        \"void(float32[:, :, :, :],\"  # img: [Batch, Channel, Img_Y, Img_X]\n",
    "        \" float32[:, :, :],\"  # kernel: [Channel, Kernel_Y, Kernel_X]\n",
    "        \" float32[:, :, :, :],\"  # tangent: [Batch, Channel, Img_Y, Img_X]\n",
    "        \" uint8[:, :, :, :, :],\"  # prov: [Batch, Channel, Img_Y, Img_X, 2 (y, then x)]\n",
    "        \" float32[:, :, :, :],\"  # out_img_grad: [Batch, Channel, Img_Y, Img_X]\n",
    "        \" float32[:, :, :])\",  # out_kernel_grad: [Channel, Kernel_Y, Kernel_X]\n",
    "        debug=debug,\n",
    "        opt=not debug,\n",
    "    )\n",
    "    def conv_backwards_cuda_jit(\n",
    "            img, kernel, gradient, prov, out_img_grad, out_kernel_grad\n",
    "    ):\n",
    "        idx = cuda.grid(1)\n",
    "        if idx >= gradient.size:\n",
    "            return\n",
    "        rem, o_x = divmod(idx, o_xs)\n",
    "        rem, o_y = divmod(rem, o_ys)\n",
    "        b, c = divmod(rem, cs)\n",
    "        gradient = gradient[b, c, o_y, o_x]\n",
    "        if gradient == 0.0:\n",
    "            return\n",
    "\n",
    "        k_prov_y = prov[b, c, o_y, o_x, 0]\n",
    "        k_prov_x = prov[b, c, o_y, o_x, 1]\n",
    "        if k_prov_y == prov_maxval:\n",
    "            # We only looked at padding values,\n",
    "            # so our gradient can't be related to\n",
    "            # the image\n",
    "            return\n",
    "        kernel_val = kernel[c, k_prov_y, k_prov_x]\n",
    "\n",
    "        i_top_y = o_y * fixed_stride - fixed_padding\n",
    "        i_left_x = o_x * fixed_stride - fixed_padding\n",
    "        i_prov_y = i_top_y + fixed_dilation * k_prov_y\n",
    "        i_prov_x = i_left_x + fixed_dilation * k_prov_x\n",
    "        if i_prov_x < 0 or i_prov_x >= i_xs or i_prov_y < 0 or i_prov_y >= i_ys:\n",
    "            return\n",
    "        img_val = img[b, c, i_prov_y, i_prov_x]\n",
    "\n",
    "        dv = d_weigh_d_img(img_val, kernel_val) * gradient\n",
    "        dw = d_weigh_d_kernel(img_val, kernel_val) * gradient\n",
    "\n",
    "        cuda.atomic.add(out_img_grad, (b, c, i_prov_y, i_prov_x), dv)\n",
    "        cuda.atomic.add(out_kernel_grad, (c, k_prov_y, k_prov_x), dw)\n",
    "\n",
    "    # === Backwards torch-side ===\n",
    "    @torch.library.custom_op(\n",
    "        f\"semifields::tropical_op_back_{op_id}\", mutates_args={}, device_types=\"cuda\"\n",
    "    )\n",
    "    def conv_backwards_cuda_lib(\n",
    "            img: torch.Tensor,\n",
    "            kernel: torch.Tensor,\n",
    "            gradient: torch.Tensor,\n",
    "            prov: torch.Tensor,\n",
    "    ) -> tuple[torch.Tensor, torch.Tensor]:\n",
    "        img, kernel = img.detach(), kernel.detach()\n",
    "        out_img_grad = torch.zeros_like(img)\n",
    "        out_kernel_grad = torch.zeros_like(kernel)\n",
    "        n_blocks = math.ceil(gradient.nelement() / block_size)\n",
    "        conv_backwards_cuda_jit[n_blocks, block_size](\n",
    "            img, kernel, gradient, prov, out_img_grad, out_kernel_grad\n",
    "        )\n",
    "        return out_img_grad, out_kernel_grad\n",
    "\n",
    "    @conv_backwards_cuda_lib.register_fake\n",
    "    def _(img, kernel, _gradient, _prov):\n",
    "        return torch.empty_like(img), torch.empty_like(kernel)\n",
    "\n",
    "    def back_setup(ctx, inputs, output):\n",
    "        img, kernel = inputs\n",
    "        _out_img, prov = output\n",
    "        ctx.img = img\n",
    "        ctx.kernel = kernel\n",
    "        ctx.prov = prov\n",
    "\n",
    "    def lib_back(ctx, grad_output, _grad_prov):\n",
    "        return conv_backwards_cuda_lib(ctx.img, ctx.kernel, grad_output, ctx.prov)\n",
    "\n",
    "    conv_cuda_lib.register_autograd(lib_back, setup_context=back_setup)\n",
    "\n",
    "    if debug:\n",
    "        print(\"Calculated output shape\", cs, o_ys, o_xs)\n",
    "        with warnings.catch_warnings():\n",
    "            warnings.simplefilter(\"ignore\", UserWarning)\n",
    "            with torch.autograd.detect_anomaly():\n",
    "                # noinspection PyTypeChecker\n",
    "                torch.library.opcheck(conv_cuda_lib, (example_imgs, example_kernels))\n",
    "    del example_imgs, example_kernels\n",
    "\n",
    "    # === Entry point ===\n",
    "    @torch.compile(fullgraph=True, backend=\"inductor\", disable=not compile_entry_point)\n",
    "    def conv(\n",
    "            img: torch.Tensor,\n",
    "            kernel: torch.Tensor,\n",
    "            stride: int = fixed_stride,\n",
    "            padding: int = fixed_padding,\n",
    "            dilation: int = fixed_dilation,\n",
    "    ):\n",
    "        if len(kernel.shape) == 4:\n",
    "            kernel = kernel.squeeze(1)\n",
    "\n",
    "        if (\n",
    "                padding != fixed_padding\n",
    "                or stride != fixed_stride\n",
    "                or dilation != fixed_dilation\n",
    "        ):\n",
    "            raise ValueError(\"Cannot change stride/padding/dilation after compilation\")\n",
    "\n",
    "        out_img, _out_prov = conv_cuda_lib(img, kernel)\n",
    "        return out_img\n",
    "\n",
    "    return conv\n",
    "\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "ex_op = compile_tropical_op(g_imgs, g_kernels, is_max=True, debug=True)\n",
    "ex_op_modified = compile_tropical_op(\n",
    "    g_imgs,\n",
    "    g_kernels,\n",
    "    debug=True,\n",
    "    is_max=True,\n",
    "    fixed_stride=1,\n",
    "    fixed_padding=2,\n",
    "    fixed_dilation=2,\n",
    ")\n",
    "ex_min_op = compile_tropical_op(test_imgs, test_kernels, is_max=False, debug=True)\n",
    "ex_res = ex_op(g_imgs, g_kernels)\n",
    "ex_res_mod = ex_op_modified(g_imgs, g_kernels)\n",
    "ex_res_min = ex_min_op(g_imgs, g_kernels)\n",
    "\n",
    "ref_res = convolutions.TropicalConv2D(is_max=True)(\n",
    "    test_imgs, test_kernels.unsqueeze(1), stride=1, padding=2, dilation=2\n",
    ")\n",
    "\n",
    "_, (axs, axs_ref) = plt.subplots(nrows=2, ncols=4, figsize=(10, 5))\n",
    "axs[0].matshow(test_imgs[0, 1].numpy(force=True))\n",
    "axs[1].matshow(ex_res[0, 1].numpy(force=True))\n",
    "axs[2].matshow(ex_res_mod[0, 1].numpy(force=True))\n",
    "axs[3].matshow(ex_res_min[0, 1].numpy(force=True))\n",
    "\n",
    "axs_ref[0].axis(\"off\")\n",
    "axs_ref[1].axis(\"off\")\n",
    "axs_ref[2].matshow(ref_res[0, 1].numpy(force=True))\n",
    "axs_ref[3].axis(\"off\")\n",
    "plt.show()\n",
    "print(test_imgs.shape, ex_res.shape, ex_res_mod.shape)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "e97a54891a1b226",
   "metadata": {},
   "source": [
    "def visualise_gradient(\n",
    "        conv_op,\n",
    "        img_nr: int = 0,\n",
    "        channel: int = 4,\n",
    "        tangent_xs=(7, 7, 7, 8),\n",
    "        tangent_ys=(6, 7, 8, 6),\n",
    "        **conv_kwargs,\n",
    "):\n",
    "    imgs = test_imgs.clone()\n",
    "    kernel = test_kernels.clone()\n",
    "    imgs.requires_grad_(True)\n",
    "    kernel.requires_grad_(True)\n",
    "    imgs.grad = None\n",
    "    kernel.grad = None\n",
    "\n",
    "    convolved = conv_op(imgs, kernel.unsqueeze(1), **conv_kwargs)\n",
    "    convolved[img_nr, channel, tangent_ys, tangent_xs].sum().backward()\n",
    "    _, axs = plt.subplots(ncols=5, layout=\"compressed\", figsize=(15, 15), dpi=300)\n",
    "    axs[0].matshow(kernel[channel].numpy(force=True))\n",
    "    axs[0].set_title(\"Kernel\")\n",
    "    axs[1].matshow(\n",
    "        imgs[img_nr, channel, y_slice, x_slice].numpy(force=True), vmin=0, vmax=2\n",
    "    )\n",
    "    axs[1].set_title(\"Original\")\n",
    "    axs[2].matshow(\n",
    "        convolved[img_nr, channel, y_slice, x_slice].numpy(force=True), vmin=0, vmax=2\n",
    "    )\n",
    "    axs[2].set_title(\"Convolved\")\n",
    "    imgs_grad = imgs.grad[img_nr, channel, y_slice, x_slice].numpy(force=True)\n",
    "    axs[3].matshow(imgs_grad)\n",
    "    axs[3].set_title(\"Image Gradient\")\n",
    "    kernel_grad = kernel.grad[channel].numpy(force=True)\n",
    "    axs[4].matshow(kernel_grad)\n",
    "    axs[4].set_title(\"Kernel Gradient\")\n",
    "    for grad_y, grad_x in zip(*imgs_grad.nonzero()):\n",
    "        axs[3].text(\n",
    "            grad_x,\n",
    "            grad_y,\n",
    "            imgs_grad[grad_y, grad_x],\n",
    "            color=\"black\",\n",
    "            fontsize=5,\n",
    "            ha=\"center\",\n",
    "            va=\"center\",\n",
    "        )\n",
    "    for grad_y, grad_x in zip(*kernel_grad.nonzero()):\n",
    "        axs[4].text(\n",
    "            grad_x,\n",
    "            grad_y,\n",
    "            kernel_grad[grad_y, grad_x],\n",
    "            color=\"black\",\n",
    "            fontsize=10,\n",
    "            ha=\"center\",\n",
    "            va=\"center\",\n",
    "        )\n",
    "    for ax, values in zip(axs[1:4], (imgs, convolved, imgs.grad)):\n",
    "        for t_x, t_y in zip(tangent_xs, tangent_ys):\n",
    "            ax.text(\n",
    "                t_x,\n",
    "                t_y,\n",
    "                values[img_nr, channel, t_y, t_x].numpy(force=True).round(2),\n",
    "                color=\"red\",\n",
    "                fontsize=5,\n",
    "                ha=\"center\",\n",
    "                va=\"center\",\n",
    "            )\n",
    "        # ax.scatter(target_x, target_y, marker=\"x\", color='red')\n",
    "    plt.suptitle(\"Unfold-max gradients\")\n",
    "    print(\"Nonzero gradient in image:\", imgs_grad.nonzero())"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "36192f68b2c02499",
   "metadata": {},
   "source": [
    "visualise_gradient(ex_op)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "2e9ec961fca5d62f",
   "metadata": {},
   "source": [
    "visualise_gradient(ex_op_modified)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "8074974f33e71a0b",
   "metadata": {},
   "source": [
    "import warnings\n",
    "\n",
    "failed1 = failed2 = None\n",
    "\n",
    "\n",
    "def test_same_conv(conv1, conv2, dilation=1, padding=1, stride=1):\n",
    "    global failed1, failed2\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter(\"ignore\", UserWarning)\n",
    "        with torch.autograd.detect_anomaly():\n",
    "            imgs1, kernels1 = (\n",
    "                test_imgs.clone().requires_grad_(True),\n",
    "                test_kernels.clone().unsqueeze(1).requires_grad_(True),\n",
    "            )\n",
    "            imgs2, kernels2 = (\n",
    "                test_imgs.clone().requires_grad_(True),\n",
    "                test_kernels.clone().unsqueeze(1).requires_grad_(True),\n",
    "            )\n",
    "\n",
    "            res1 = conv1(\n",
    "                imgs1, kernels1, dilation=dilation, padding=padding, stride=stride\n",
    "            )\n",
    "            res2 = conv2(\n",
    "                imgs2, kernels2, dilation=dilation, padding=padding, stride=stride\n",
    "            )\n",
    "            failed1, failed2 = res1, res2\n",
    "            torch.testing.assert_close(\n",
    "                res1.detach(), res2.detach(), msg=\"Results are not equal\"\n",
    "            )\n",
    "\n",
    "            tangent = torch.randn_like(res1)\n",
    "            res1.backward(tangent)\n",
    "            res2.backward(tangent)\n",
    "            failed1, failed2 = imgs1, imgs2\n",
    "            torch.testing.assert_close(\n",
    "                imgs1.detach(), imgs2.detach(), msg=\"Images were mutated\"\n",
    "            )\n",
    "            failed1, failed2 = kernels1, kernels2\n",
    "\n",
    "            torch.testing.assert_close(\n",
    "                kernels1.detach(), kernels2.detach(), msg=\"Kernels were mutated\"\n",
    "            )\n",
    "            failed1, failed2 = imgs1.grad.clone(), imgs2.grad.clone()\n",
    "            torch.testing.assert_close(\n",
    "                imgs1.grad, imgs2.grad, msg=\"Image gradient differs\"\n",
    "            )\n",
    "            failed1, failed2 = kernels1.grad.clone(), kernels2.grad.clone()\n",
    "            # More generous with kernel grad, because it is the result of a large reduction (errors compound)\n",
    "            torch.testing.assert_close(\n",
    "                kernels1.grad,\n",
    "                kernels2.grad,\n",
    "                msg=\"Kernel gradient differs\",\n",
    "                atol=0.01,\n",
    "                rtol=0.01,\n",
    "            )\n",
    "            failed1 = failed2 = None\n",
    "\n",
    "\n",
    "# Simple sanity checks\n",
    "test_same_conv(convolutions.TropicalConv2D(is_max=True), ex_op)\n",
    "print(\"Unfold max same as Numba CUDA version\")\n",
    "test_same_conv(convolutions.TropicalConv2D(is_max=False), ex_min_op)\n",
    "print(\"Unfold min same as Numba CUDA version\")\n",
    "test_same_conv(\n",
    "    convolutions.TropicalConv2D(is_max=True), ex_op_modified, padding=2, dilation=2\n",
    ")\n",
    "print(\"Modified max same as Numba CUDA version\")\n",
    "print(\"OK\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "3f8022c929409a7d",
   "metadata": {},
   "source": [
    "import itertools\n",
    "\n",
    "\n",
    "def check_param_space(max_stride: int = 5, max_padding: int = 5, max_dilation: int = 5):\n",
    "    torch.manual_seed(0)\n",
    "    param_space = itertools.product(\n",
    "        (False, True),\n",
    "        range(1, max_stride + 1),\n",
    "        range(max_padding + 1),\n",
    "        range(1, max_dilation + 1),\n",
    "    )\n",
    "\n",
    "    bar = tqdm(param_space, total=2 * max_stride * (max_padding + 1) * max_dilation)\n",
    "    for is_max, stride, padding, dilation in bar:\n",
    "        bar.set_postfix(\n",
    "            is_max=is_max,\n",
    "            stride=stride,\n",
    "            padding=padding,\n",
    "            dilation=dilation,\n",
    "            refresh=True,\n",
    "        )\n",
    "        test_same_conv(\n",
    "            convolutions.TropicalConv2D(is_max=is_max),\n",
    "            compile_tropical_op(\n",
    "                test_imgs,\n",
    "                test_kernels,\n",
    "                is_max=is_max,\n",
    "                fixed_stride=stride,\n",
    "                fixed_padding=padding,\n",
    "                fixed_dilation=dilation,\n",
    "                compile_entry_point=False,\n",
    "                debug=False,\n",
    "            ),\n",
    "            stride=stride,\n",
    "            padding=padding,\n",
    "            dilation=dilation,\n",
    "        )\n",
    "    print(\"OK\")\n",
    "\n",
    "\n",
    "check_param_space()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "c4410ed0b7f7d2ea",
   "metadata": {},
   "source": [
    "if failed1 is not None:\n",
    "    _, axs = plt.subplots(ncols=4, layout=\"compressed\", figsize=(10, 6))\n",
    "    channel_nr = 0\n",
    "    img_num = 0\n",
    "    axs[0].matshow(test_kernels[channel_nr].numpy(force=True))\n",
    "    axs[0].set_title(\"Kernel\")\n",
    "    axs[1].matshow(failed1[img_num, channel_nr, -5:, -5:].numpy(force=True))\n",
    "    axs[1].set_title(\"Unpool\")\n",
    "    axs[2].matshow(failed2[img_num, channel_nr, -5:, -5:].numpy(force=True))\n",
    "    axs[2].set_title(\"Numba\")\n",
    "    diff = (failed1[:, channel_nr] - failed2[:, channel_nr]).numpy(force=True).round(2)\n",
    "    print(\"Channel failed: \", diff.any())\n",
    "    axs[3].matshow(diff[img_num, -5:, -5:])\n",
    "    axs[3].set_title(\"Unpool $-$ Numba\")\n",
    "    plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "556d1891ebc1f9c6",
   "metadata": {},
   "source": [
    "visualise_gradient(ex_op_modified, padding=2, dilation=2)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "1e058ec47f4620a3",
   "metadata": {},
   "source": [
    "g_imgs = test_imgs.clone()\n",
    "g_kernels = test_kernels.clone()\n",
    "g_imgs.requires_grad_(True)\n",
    "g_kernels.requires_grad_(True)\n",
    "timing_op = compile_tropical_op(\n",
    "    g_imgs, g_kernels, is_max=True, fixed_stride=4, compile_entry_point=False\n",
    ")\n",
    "timing_tangent = torch.randn_like(timing_op(g_imgs, g_kernels))\n",
    "\n",
    "\n",
    "def run_one():\n",
    "    torch.cuda.synchronize()\n",
    "    arr = timing_op(g_imgs, g_kernels.unsqueeze(1), padding=1)\n",
    "    arr.backward(timing_tangent)\n",
    "    del arr\n",
    "    torch.cuda.synchronize()\n",
    "\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "run_one()\n",
    "%timeit run_one()\n",
    "torch.cuda.empty_cache()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "eb57c1d060c7a04a",
   "metadata": {},
   "source": [
    "g_imgs = test_imgs.clone()\n",
    "g_kernels = test_kernels.clone()\n",
    "g_imgs.requires_grad_(True)\n",
    "g_kernels.requires_grad_(True)\n",
    "timing_op = convolutions.TropicalConv2D(is_max=True)\n",
    "timing_tangent_alt = torch.randn_like(\n",
    "    timing_op(g_imgs, g_kernels.unsqueeze(1), padding=1, stride=1)\n",
    ")\n",
    "\n",
    "\n",
    "def run_one():\n",
    "    torch.cuda.synchronize()\n",
    "    arr = timing_op(g_imgs, g_kernels.unsqueeze(1), padding=1, stride=1)\n",
    "    arr.backward(timing_tangent_alt)\n",
    "    del arr\n",
    "    torch.cuda.synchronize()\n",
    "\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "run_one()\n",
    "%timeit run_one()\n",
    "torch.cuda.empty_cache()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "d0af94d6f4b896d2",
   "metadata": {},
   "source": [
    "# fmt: off\n",
    "slice_sizes_strided = [2, 3, 4, 6, 8, 12, 16, 23, 32, 46, 64, 91, 128, 182, 256, 363, 512, 725, 1024, 1449, 2048]\n",
    "unfold_timings_strided = [8.601449850539211e-05, 8.685274399613263e-05, 8.811392699863064e-05, 9.129133899841691e-05,\n",
    "                          9.529797050345224e-05, 0.00010843907199887326, 0.0001297704460012028, 0.0001692897860048106,\n",
    "                          0.0002150408624947886, 0.0002577364699973259, 0.0003326715309958672, 0.0004528659589996096,\n",
    "                          0.0006127196800007369, 0.0008511361700002453, 0.0011737010774959345, 0.0016564025280022179,\n",
    "                          0.002323884569996153, 0.004694061680500454, 0.00660860281749774, 0.009336203852995823,\n",
    "                          0.013332939886495296]\n",
    "numba_timings_strided = [0.00041195699350646465, 0.00040493240950308974, 0.00042407115850073753, 0.0004106013964992599,\n",
    "                         0.00041579102399555266, 0.0004095743720026803, 0.0004096275139963836, 0.0004132225249995827,\n",
    "                         0.0004206770234959549, 0.000413780028000474, 0.00042235061099927406, 0.0004335881020015222,\n",
    "                         0.000461321377006243, 0.0004885255344997859, 0.0005262560795017635, 0.0005949012644996401,\n",
    "                         0.0006804647999961162, 0.0008060576959978789, 0.0009685207395014004, 0.001236962188500911,\n",
    "                         0.0017974001669936114]\n",
    "# fmt: on"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "748c2244987324c4",
   "metadata": {},
   "source": [
    "run_timings_strided = False\n",
    "time_stride_size = 2"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "418634748bc23969",
   "metadata": {},
   "source": [
    "def get_timings_comparison(\n",
    "        n_loops: int = 2_000,\n",
    "        kernel: torch.Tensor = test_kernels,\n",
    "        stride: int = 1,\n",
    "        dilation: int = 1,\n",
    "        padding: int = 0,\n",
    "):\n",
    "    code = f\"\"\"\n",
    "sync()\n",
    "arr = dilate(imgs, kernel, padding={padding}, stride={stride}, dilation={dilation})\n",
    "arr.backward(gradient)\n",
    "del arr\n",
    "sync() \"\"\"\n",
    "    sizes = []\n",
    "    unfold_times = []\n",
    "    numba_times = []\n",
    "    bar = trange(2, 23)\n",
    "    for log_size in bar:\n",
    "        size = math.ceil(2 ** (log_size / 2))\n",
    "        batch = test_imgs[:size].clone().requires_grad_(True)\n",
    "        sizes.append(len(batch))\n",
    "        if len(kernel.shape) == 3:\n",
    "            kernel = kernel.unsqueeze(1)\n",
    "        kernel = kernel.clone().requires_grad_(True)\n",
    "        op = compile_tropical_op(\n",
    "            batch,\n",
    "            kernel,\n",
    "            is_max=True,\n",
    "            fixed_stride=stride,\n",
    "            fixed_padding=padding,\n",
    "            fixed_dilation=dilation,\n",
    "            compile_entry_point=False,\n",
    "        )\n",
    "        gradient = torch.randn_like(op(batch, kernel))\n",
    "        unfold_times.append(\n",
    "            timeit(\n",
    "                code,\n",
    "                number=n_loops,\n",
    "                globals={\n",
    "                    \"sync\": torch.cuda.synchronize,\n",
    "                    \"imgs\": batch,\n",
    "                    \"kernel\": kernel,\n",
    "                    \"gradient\": gradient,\n",
    "                    \"dilate\": unfold_max,\n",
    "                },\n",
    "            )\n",
    "            / n_loops\n",
    "        )\n",
    "        numba_times.append(\n",
    "            timeit(\n",
    "                code,\n",
    "                number=n_loops,\n",
    "                globals={\n",
    "                    \"sync\": cuda.synchronize,\n",
    "                    \"imgs\": batch,\n",
    "                    \"kernel\": kernel,\n",
    "                    \"gradient\": gradient,\n",
    "                    \"dilate\": op,\n",
    "                },\n",
    "            )\n",
    "            / n_loops\n",
    "        )\n",
    "        bar.set_postfix(\n",
    "            size=sizes[-1],\n",
    "            faster=\"unfold\" if unfold_times[-1] < numba_times[-1] else \"numba\",\n",
    "        )\n",
    "    return sizes, unfold_times, numba_times"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "b2a9479062d9f5d3",
   "metadata": {},
   "source": [
    "def plot_timings_comparison(sizes, unfold_times, numba_times, title=\"\"):\n",
    "    basic_colors = plt.rcParams[\"axes.prop_cycle\"].by_key()[\"color\"]\n",
    "    plt.plot(sizes, unfold_times, label=\"Unfold\", color=basic_colors[0])\n",
    "    plt.scatter(sizes, unfold_times, color=basic_colors[0])\n",
    "    plt.plot(sizes, numba_times, label=\"Numba CUDA\", color=basic_colors[1])\n",
    "    plt.scatter(sizes, numba_times, color=basic_colors[1])\n",
    "    numba_better_from = (np.subtract(unfold_times, numba_times) > 0).argmax()\n",
    "    plt.axvline(sizes[numba_better_from], linestyle=\"dashed\", color=\"grey\")\n",
    "    plt.text(\n",
    "        sizes[numba_better_from - 1],\n",
    "        10 ** -3,\n",
    "        sizes[numba_better_from],\n",
    "        color=\"grey\",\n",
    "    )\n",
    "    adj_numba = np.asarray(numba_times) - numba_times[1] + unfold_times[1]\n",
    "    plt.plot(\n",
    "        sizes,\n",
    "        adj_numba,\n",
    "        label=\"Theoretical no-overhead Numba\",\n",
    "        linestyle=\"dashed\",\n",
    "        color=basic_colors[1],\n",
    "    )\n",
    "    plt.xlabel(\"Batch size\")\n",
    "    plt.ylabel(\"Time\")\n",
    "    plt.title(title)\n",
    "    plt.loglog()\n",
    "    plt.legend()\n",
    "    plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "cba0d338f77f7f38",
   "metadata": {},
   "source": [
    "plot_timings_comparison(\n",
    "    *get_timings_comparison(\n",
    "        kernel=torch.randn(6, 1, 5, 5, device=\"cuda\"), padding=2, stride=2\n",
    "    ),\n",
    "    title=\"Size 5 kernels\",\n",
    ")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "8c05744f2a91c927",
   "metadata": {},
   "source": [
    "plot_timings_comparison(\n",
    "    *get_timings_comparison(\n",
    "        kernel=torch.randn(6, 1, 7, 7, device=\"cuda\"), padding=2, stride=2\n",
    "    ),\n",
    "    title=\"Size 7 kernels\",\n",
    ")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "bc026f3ac831bf35",
   "metadata": {},
   "source": [
    "if run_timings_strided:\n",
    "    torch_code = f\"\"\"\n",
    "sync()\n",
    "arr = dilate(imgs, kernels, padding=1, stride={time_stride_size})\n",
    "arr.backward(tangent)\n",
    "del arr\n",
    "sync()\n",
    "    \"\"\"\n",
    "    slice_sizes_strided = []\n",
    "    unfold_timings_strided = []\n",
    "    numba_timings_strided = []\n",
    "    num_loops = 2_000\n",
    "    bar = trange(2, 23)\n",
    "    for size_pow in bar:\n",
    "        test_size = math.ceil(2 ** (size_pow / 2))\n",
    "        test_slice = test_imgs[:test_size]\n",
    "        slice_sizes_strided.append(len(test_slice))\n",
    "        timing_op = compile_tropical_op(\n",
    "            test_slice,\n",
    "            test_kernels,\n",
    "            is_max=True,\n",
    "            fixed_stride=time_stride_size,\n",
    "            compile_entry_point=False,\n",
    "        )\n",
    "        _test_out = timing_op(test_slice, test_kernels)\n",
    "        test_tangent = torch.randn_like(_test_out)\n",
    "        unfold_timings_strided.append(\n",
    "            timeit(\n",
    "                torch_code,\n",
    "                number=num_loops,\n",
    "                globals={\n",
    "                    \"sync\": torch.cuda.synchronize,\n",
    "                    \"imgs\": test_slice.clone().requires_grad_(True),\n",
    "                    \"kernels\": test_kernels.unsqueeze(1).clone().requires_grad_(True),\n",
    "                    \"tangent\": test_tangent,\n",
    "                    \"dilate\": unfold_max,\n",
    "                },\n",
    "            )\n",
    "            / num_loops\n",
    "        )\n",
    "        numba_timings_strided.append(\n",
    "            timeit(\n",
    "                torch_code,\n",
    "                number=num_loops,\n",
    "                globals={\n",
    "                    \"sync\": cuda.synchronize,\n",
    "                    \"imgs\": test_slice.clone().requires_grad_(True),\n",
    "                    \"kernels\": test_kernels.clone().requires_grad_(True),\n",
    "                    \"tangent\": test_tangent,\n",
    "                    \"dilate\": timing_op,\n",
    "                },\n",
    "            )\n",
    "            / num_loops\n",
    "        )\n",
    "        bar.set_postfix(\n",
    "            size=slice_sizes_strided[-1],\n",
    "            faster=\"unfold\"\n",
    "            if unfold_timings_strided[-1] < numba_timings_strided[-1]\n",
    "            else \"numba\",\n",
    "        )"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "6e35e0ccf9da90a3",
   "metadata": {},
   "source": [
    "colors = plt.rcParams[\"axes.prop_cycle\"].by_key()[\"color\"]\n",
    "\n",
    "plt.plot(slice_sizes_strided, unfold_timings_strided, label=\"Unfold\", color=colors[0])\n",
    "plt.scatter(slice_sizes_strided, unfold_timings_strided, color=colors[0])\n",
    "plt.plot(\n",
    "    slice_sizes_strided, numba_timings_strided, label=\"Numba CUDA\", color=colors[1]\n",
    ")\n",
    "plt.scatter(slice_sizes_strided, numba_timings_strided, color=colors[1])\n",
    "first_better = (np.subtract(unfold_timings_strided, numba_timings_strided) > 0).argmax()\n",
    "plt.axvline(slice_sizes_strided[first_better], linestyle=\"dashed\", color=\"grey\")\n",
    "plt.text(\n",
    "    slice_sizes_strided[first_better - 1],\n",
    "    10 ** -3,\n",
    "    slice_sizes_strided[first_better],\n",
    "    color=\"grey\",\n",
    ")\n",
    "adjusted_numba = (\n",
    "        np.asarray(numba_timings_strided)\n",
    "        - numba_timings_strided[1]\n",
    "        + unfold_timings_strided[1]\n",
    ")\n",
    "plt.plot(\n",
    "    slice_sizes_strided,\n",
    "    adjusted_numba,\n",
    "    label=\"Theoretical no-overhead Numba\",\n",
    "    linestyle=\"dashed\",\n",
    "    color=colors[1],\n",
    ")\n",
    "plt.xlabel(\"Batch size\")\n",
    "plt.ylabel(\"Time\")\n",
    "plt.title(f\"Forwards- and backwards-pass with stride of {time_stride_size}\")\n",
    "plt.loglog()\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "b3d30cb3de4fcfa4",
   "metadata": {},
   "source": [
    "import importlib\n",
    "from src import convolutions\n",
    "from pytorch_semifield_conv import cuda_select\n",
    "\n",
    "importlib.reload(cuda_select)\n",
    "importlib.reload(convolutions)\n",
    "from src import convolutions"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "f06db8caf40d9e30",
   "metadata": {},
   "source": [
    "test_kernels.shape"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "ef4eacee46bda3d2",
   "metadata": {},
   "source": [
    "ss_max = convolutions.SelectSemifield.tropical_max().compile(\n",
    "    test_imgs, test_kernels.unsqueeze(1), groups=6, debug=True\n",
    ")\n",
    "ss_max"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "2491eec43b0908f2",
   "metadata": {},
   "source": [
    "visualise_gradient(\n",
    "    ss_max,\n",
    ")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "d766f4f66569e7f3",
   "metadata": {},
   "source": [
    "# Alternate form: less work, but can't be traced!\n",
    "\n",
    "\n",
    "class TestMaxOp(torch.autograd.Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, img: torch.Tensor, kernel: torch.Tensor) -> torch.Tensor:\n",
    "        res, prov = max_op(img, kernel)\n",
    "        ctx.save_for_backward(img, kernel, prov)\n",
    "        return res\n",
    "\n",
    "    # noinspection PyMethodOverriding\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output: torch.Tensor) -> tuple[torch.Tensor, torch.Tensor]:\n",
    "        img, kernel, prov = ctx.saved_tensors\n",
    "        return max_back_op(img, kernel, grad_output, prov)\n",
    "\n",
    "\n",
    "g_kernels.grad = None\n",
    "g_kernels.requires_grad_(True)\n",
    "TestMaxOp.apply(test_imgs, g_kernels).backward(test_tangent)\n",
    "plt.matshow(g_kernels.grad[channel_nr].numpy(force=True))"
   ],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
